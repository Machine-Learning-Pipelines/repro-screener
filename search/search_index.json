{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to repro-screener's documentation! ReproScreener aims to address challenges in robustness, transparency and interpretability of ML models by automating verification of machine learning models at scale. Note This project is under active development.","title":"Home"},{"location":"#welcome-to-repro-screeners-documentation","text":"ReproScreener aims to address challenges in robustness, transparency and interpretability of ML models by automating verification of machine learning models at scale. Note This project is under active development.","title":"Welcome to repro-screener's documentation!"},{"location":"case-studies/","text":"Case studies mine50 contains the 50 most recent articles from arxiv.org in both the cs.LG and stat.ML categories , between the dates 2022-10-24 and 2022-10-25 and contained 570 search results at the time of the dataset creation. The search result is sorted by date in descending order Note The date being queried for is the last updated date and not the date of paper submission mine50-csLG contains the results using the same method as mine50 but without looking for articles in both cs.LG and stat.ML.","title":"Case studies"},{"location":"case-studies/#case-studies","text":"mine50 contains the 50 most recent articles from arxiv.org in both the cs.LG and stat.ML categories , between the dates 2022-10-24 and 2022-10-25 and contained 570 search results at the time of the dataset creation. The search result is sorted by date in descending order Note The date being queried for is the last updated date and not the date of paper submission mine50-csLG contains the results using the same method as mine50 but without looking for articles in both cs.LG and stat.ML.","title":"Case studies"},{"location":"docstrings/","text":"Docstrings Documentation of keywords.py find_affiliation ( soup ) Find the affiliation of the article using emails in the header (Gunderson et al. 2018). Parameters: Name Type Description Default soup soup Beautiful soup object of the TEI file required Returns: Name Type Description int Affiliation value of the article -1: If no affiliation is found 0 Academia 1 Industry 2 Both Source code in src/keywords.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def find_affiliation ( soup ): \"\"\"Find the affiliation of the article using emails in the header (Gunderson et al. 2018). Args: soup (soup): Beautiful soup object of the TEI file Returns: int: Affiliation value of the article -1: If no affiliation is found 0: Academia 1: Industry 2: Both \"\"\" ## ? Condsider merging into find_vars emails = [ t . getText ( separator = \" \" , strip = True ) for t in soup . find_all ( \"email\" )] keys_affiliation = list ( exrex . generate ( \"edu\" )) keyword_dict = { \"affiliation\" : keys_affiliation } keyword_processor = KeywordProcessor ( case_sensitive = True ) keyword_processor . add_keywords_from_dict ( keyword_dict ) edu_ind_emails = [ 0 , 0 ] # edu count, industry count for i in range ( len ( emails )): edu = keyword_processor . extract_keywords ( emails [ i ], span_info = True ) if len ( edu ) > 0 : edu_ind_emails [ 0 ] += 1 elif len ( edu ) == 0 : edu_ind_emails [ 1 ] += 1 affiliation = - 1 if edu_ind_emails [ 0 ] > 0 and edu_ind_emails [ 1 ] > 0 : # both affiliation = 2 elif edu_ind_emails [ 0 ] == 0 and edu_ind_emails [ 1 ] > 0 : # industry affiliation = 1 elif edu_ind_emails [ 0 ] > 0 and edu_ind_emails [ 1 ] == 0 : # academia affiliation = 0 return affiliation find_vars ( soup ) Find all variables per (Gunderson) metrics Parameters: Name Type Description Default soup _type_ Beautiful soup object of the TEI file required Returns: Name Type Description _type_ Set of variables found in the article Source code in src/keywords.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def find_vars ( soup ): \"\"\"Find all variables per (Gunderson) metrics Args: soup (_type_): Beautiful soup object of the TEI file Returns: _type_: Set of variables found in the article \"\"\" paras = [ t . getText ( separator = \" \" , strip = True ) for t in soup . find_all ( \"p\" )] keyword_dict = generate_gunderson_dict () keyword_processor = KeywordProcessor ( case_sensitive = True ) keyword_processor . add_keywords_from_dict ( keyword_dict ) all_found_paras = [] for i in range ( len ( paras )): all_found_paras . append ( keyword_processor . extract_keywords ( paras [ i ], span_info = True ) ) non_empty_found_paras = [ x for x in all_found_paras if x != []] found_vars = set () for i in non_empty_found_paras : for j in i : found_vars . add ( j [ 0 ]) return found_vars generate_gunderson_dict () Generate a dictionary of Gunderson variables with regex patterns. Returns: Name Type Description _type_ A dictionary of keywords and regex patterns. Source code in src/keywords.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def generate_gunderson_dict (): \"\"\"Generate a dictionary of Gunderson variables with regex patterns. Returns: _type_: A dictionary of keywords and regex patterns. \"\"\" keys_problem = list ( exrex . generate ( \"((((P|p)roblem) ((S|s)tatement)))|((((R|r)esearch) ((P|p)roblem)))|((P|p)roblems?)\" ) ) keys_objective = list ( exrex . generate ( \"((((O|o)bjective)))|((((G|g)oal)|((((R|r)esearch) ((O|o)bjective))))|((((R|r)esearch) ((G|g)oal))))\" ) ) keys_research_method = list ( exrex . generate ( \"((R|r)esearch (M|m)ethods?)|\" \"(M|m)ethods?\" ) ) keys_research_questions = list ( exrex . generate ( \"((((R|r)esearch)))|((((Q|q)uestions?)|\" \"((((R|r)esearch) ((O|o)bjective))))|\" \"((((R|r)esearch) ((G|g)oal))))\" ) ) keys_pseudocode = list ( exrex . generate ( \"((P|p)seudo-?code)|(Algorithm [1-9])\" )) keys_training_data = list ( exrex . generate ( \"(T|t)raining (D|d)ata\" )) keys_validation_data = list ( exrex . generate ( \"(V|v)alidation (D|d)ata\" )) keys_test_data = list ( exrex . generate ( \"(T|t)est (D|d)ata\" )) keys_experiment_setup = list ( exrex . generate ( \"(E|e)xperimental( |-)(S|s)etup|\" \"((H|h)yper( |-)(P|p)arameters)\" ) ) keys_hypothesis = list ( exrex . generate ( \"(H|h)ypothes(i|e)s\" )) keys_prediction = list ( exrex . generate ( \"(P|p)redictions?\" )) keys_hardware_specifications = list ( exrex . generate ( \"(H|h)ardware (S|s)pecification(s)\" ) ) keys_software_dependencies = list ( exrex . generate ( \"(S|s)oftware (D|d)ependencies\" )) keys_method_source_code = list ( exrex . generate ( \"(G|g)it( )?(H|h)ub|\" \"(B|b)it(B|b)ucket|\" \"(G|g)it( )?(L|l)ab\" ) ) keyword_dict = { \"problem\" : keys_problem , \"objective\" : keys_objective , \"research_method\" : keys_research_method , \"research_questions\" : keys_research_questions , \"pseudocode\" : keys_pseudocode , \"training_data\" : keys_training_data , \"validation_data\" : keys_validation_data , \"test_data\" : keys_test_data , \"hypothesis\" : keys_hypothesis , \"prediction\" : keys_prediction , \"method_source_code\" : keys_method_source_code , \"hardware_specifications\" : keys_hardware_specifications , \"software_dependencies\" : keys_software_dependencies , \"experiment_setup\" : keys_experiment_setup , } return keyword_dict read_tei ( tei_file ) Read a TEI file and return a beautiful soup object. Parameters: Name Type Description Default tei_file _type_ Path to TEI file required Returns: Name Type Description _type_ Beautiful soup object Source code in src/keywords.py 6 7 8 9 10 11 12 13 14 15 16 17 def read_tei ( tei_file ): \"\"\"Read a TEI file and return a beautiful soup object. Args: tei_file (_type_): Path to TEI file Returns: _type_: Beautiful soup object \"\"\" with open ( tei_file , \"r\" ) as tei : soup = BeautifulSoup ( tei , features = \"xml\" ) return soup Documentation of evaluate_guidance.py Documentation of scrape_arxiv.py Documentation of main.py run_reproscreener () summary fall subfunctions to run processing steps Source code in src/main.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def run_reproscreener (): \"\"\"_summary_ fall subfunctions to run processing steps \"\"\" gunderson_vars = [ \"problem\" , \"objective\" , \"research_method\" , \"research_questions\" , \"pseudocode\" , \"training_data\" , \"validation_data\" , \"test_data\" , \"results\" , \"hypothesis\" , \"prediction\" , \"method_source_code\" , \"hardware_specifications\" , \"software_dependencies\" , \"experiment_setup\" , \"experiment_source_code\" , \"affiliation\" , ] num_articles = 50 path_corpus = eg . init_paths ( num_articles = 50 , folder_name = \"mine50-csLG/\" ) repro_eval = eg . init_repro_eval ( path_corpus , num_articles ) found_vars_pdf = eg . get_found_vars ( path_corpus , repro_eval ) found_vars_tex = read_tex . get_found_vars_tex ( path_corpus , repro_eval ) repro_eval_filled_pdf = eg . set_repro_eval_scores ( concat ([ repro_eval , found_vars_pdf ], axis = 0 , join = \"inner\" ), gunderson_vars ) repro_eval_filled_tex = eg . set_repro_eval_scores ( concat ([ repro_eval , found_vars_tex ], axis = 0 , join = \"inner\" ), gunderson_vars , skip_affiliation = True , ) output_repro_eval_pdf = merge ( found_vars_pdf [[ \"id\" , \"title\" ]], repro_eval_filled_pdf , left_index = True , right_index = True , ) . drop_duplicates ( subset = [ \"id\" ]) output_repro_eval_tex = merge ( found_vars_tex [[ \"id\" , \"title\" ]], repro_eval_filled_tex , left_index = True , right_index = True , ) . drop_duplicates ( subset = [ \"id\" ]) # print(output_repro_eval_tex) # print(eg.get_manual_eval(path_corpus)) output_repro_eval_pdf . to_csv ( path_corpus + \"output/repro_eval.csv\" , index_label = \"index\" ) output_repro_eval_tex . to_csv ( path_corpus + \"output/repro_eval_tex.csv\" , index_label = \"index\" ) eg . compare_available_manual ( output_repro_eval_pdf , output_repro_eval_tex , eg . get_manual_eval ( path_corpus ), gunderson_vars , ) # eg.compare_available_manual(output_repro_eval_tex, eg.get_manual_eval(path_corpus), gunderson_vars) return output_repro_eval_pdf","title":"Docstrings"},{"location":"docstrings/#docstrings","text":"","title":"Docstrings"},{"location":"docstrings/#documentation-of-keywordspy","text":"","title":"Documentation of keywords.py"},{"location":"docstrings/#src.keywords.find_affiliation","text":"Find the affiliation of the article using emails in the header (Gunderson et al. 2018). Parameters: Name Type Description Default soup soup Beautiful soup object of the TEI file required Returns: Name Type Description int Affiliation value of the article -1: If no affiliation is found 0 Academia 1 Industry 2 Both Source code in src/keywords.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def find_affiliation ( soup ): \"\"\"Find the affiliation of the article using emails in the header (Gunderson et al. 2018). Args: soup (soup): Beautiful soup object of the TEI file Returns: int: Affiliation value of the article -1: If no affiliation is found 0: Academia 1: Industry 2: Both \"\"\" ## ? Condsider merging into find_vars emails = [ t . getText ( separator = \" \" , strip = True ) for t in soup . find_all ( \"email\" )] keys_affiliation = list ( exrex . generate ( \"edu\" )) keyword_dict = { \"affiliation\" : keys_affiliation } keyword_processor = KeywordProcessor ( case_sensitive = True ) keyword_processor . add_keywords_from_dict ( keyword_dict ) edu_ind_emails = [ 0 , 0 ] # edu count, industry count for i in range ( len ( emails )): edu = keyword_processor . extract_keywords ( emails [ i ], span_info = True ) if len ( edu ) > 0 : edu_ind_emails [ 0 ] += 1 elif len ( edu ) == 0 : edu_ind_emails [ 1 ] += 1 affiliation = - 1 if edu_ind_emails [ 0 ] > 0 and edu_ind_emails [ 1 ] > 0 : # both affiliation = 2 elif edu_ind_emails [ 0 ] == 0 and edu_ind_emails [ 1 ] > 0 : # industry affiliation = 1 elif edu_ind_emails [ 0 ] > 0 and edu_ind_emails [ 1 ] == 0 : # academia affiliation = 0 return affiliation","title":"find_affiliation()"},{"location":"docstrings/#src.keywords.find_vars","text":"Find all variables per (Gunderson) metrics Parameters: Name Type Description Default soup _type_ Beautiful soup object of the TEI file required Returns: Name Type Description _type_ Set of variables found in the article Source code in src/keywords.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def find_vars ( soup ): \"\"\"Find all variables per (Gunderson) metrics Args: soup (_type_): Beautiful soup object of the TEI file Returns: _type_: Set of variables found in the article \"\"\" paras = [ t . getText ( separator = \" \" , strip = True ) for t in soup . find_all ( \"p\" )] keyword_dict = generate_gunderson_dict () keyword_processor = KeywordProcessor ( case_sensitive = True ) keyword_processor . add_keywords_from_dict ( keyword_dict ) all_found_paras = [] for i in range ( len ( paras )): all_found_paras . append ( keyword_processor . extract_keywords ( paras [ i ], span_info = True ) ) non_empty_found_paras = [ x for x in all_found_paras if x != []] found_vars = set () for i in non_empty_found_paras : for j in i : found_vars . add ( j [ 0 ]) return found_vars","title":"find_vars()"},{"location":"docstrings/#src.keywords.generate_gunderson_dict","text":"Generate a dictionary of Gunderson variables with regex patterns. Returns: Name Type Description _type_ A dictionary of keywords and regex patterns. Source code in src/keywords.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def generate_gunderson_dict (): \"\"\"Generate a dictionary of Gunderson variables with regex patterns. Returns: _type_: A dictionary of keywords and regex patterns. \"\"\" keys_problem = list ( exrex . generate ( \"((((P|p)roblem) ((S|s)tatement)))|((((R|r)esearch) ((P|p)roblem)))|((P|p)roblems?)\" ) ) keys_objective = list ( exrex . generate ( \"((((O|o)bjective)))|((((G|g)oal)|((((R|r)esearch) ((O|o)bjective))))|((((R|r)esearch) ((G|g)oal))))\" ) ) keys_research_method = list ( exrex . generate ( \"((R|r)esearch (M|m)ethods?)|\" \"(M|m)ethods?\" ) ) keys_research_questions = list ( exrex . generate ( \"((((R|r)esearch)))|((((Q|q)uestions?)|\" \"((((R|r)esearch) ((O|o)bjective))))|\" \"((((R|r)esearch) ((G|g)oal))))\" ) ) keys_pseudocode = list ( exrex . generate ( \"((P|p)seudo-?code)|(Algorithm [1-9])\" )) keys_training_data = list ( exrex . generate ( \"(T|t)raining (D|d)ata\" )) keys_validation_data = list ( exrex . generate ( \"(V|v)alidation (D|d)ata\" )) keys_test_data = list ( exrex . generate ( \"(T|t)est (D|d)ata\" )) keys_experiment_setup = list ( exrex . generate ( \"(E|e)xperimental( |-)(S|s)etup|\" \"((H|h)yper( |-)(P|p)arameters)\" ) ) keys_hypothesis = list ( exrex . generate ( \"(H|h)ypothes(i|e)s\" )) keys_prediction = list ( exrex . generate ( \"(P|p)redictions?\" )) keys_hardware_specifications = list ( exrex . generate ( \"(H|h)ardware (S|s)pecification(s)\" ) ) keys_software_dependencies = list ( exrex . generate ( \"(S|s)oftware (D|d)ependencies\" )) keys_method_source_code = list ( exrex . generate ( \"(G|g)it( )?(H|h)ub|\" \"(B|b)it(B|b)ucket|\" \"(G|g)it( )?(L|l)ab\" ) ) keyword_dict = { \"problem\" : keys_problem , \"objective\" : keys_objective , \"research_method\" : keys_research_method , \"research_questions\" : keys_research_questions , \"pseudocode\" : keys_pseudocode , \"training_data\" : keys_training_data , \"validation_data\" : keys_validation_data , \"test_data\" : keys_test_data , \"hypothesis\" : keys_hypothesis , \"prediction\" : keys_prediction , \"method_source_code\" : keys_method_source_code , \"hardware_specifications\" : keys_hardware_specifications , \"software_dependencies\" : keys_software_dependencies , \"experiment_setup\" : keys_experiment_setup , } return keyword_dict","title":"generate_gunderson_dict()"},{"location":"docstrings/#src.keywords.read_tei","text":"Read a TEI file and return a beautiful soup object. Parameters: Name Type Description Default tei_file _type_ Path to TEI file required Returns: Name Type Description _type_ Beautiful soup object Source code in src/keywords.py 6 7 8 9 10 11 12 13 14 15 16 17 def read_tei ( tei_file ): \"\"\"Read a TEI file and return a beautiful soup object. Args: tei_file (_type_): Path to TEI file Returns: _type_: Beautiful soup object \"\"\" with open ( tei_file , \"r\" ) as tei : soup = BeautifulSoup ( tei , features = \"xml\" ) return soup","title":"read_tei()"},{"location":"docstrings/#documentation-of-evaluate_guidancepy","text":"","title":"Documentation of evaluate_guidance.py"},{"location":"docstrings/#documentation-of-scrape_arxivpy","text":"","title":"Documentation of scrape_arxiv.py"},{"location":"docstrings/#documentation-of-mainpy","text":"","title":"Documentation of main.py"},{"location":"docstrings/#src.main.run_reproscreener","text":"summary fall subfunctions to run processing steps Source code in src/main.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def run_reproscreener (): \"\"\"_summary_ fall subfunctions to run processing steps \"\"\" gunderson_vars = [ \"problem\" , \"objective\" , \"research_method\" , \"research_questions\" , \"pseudocode\" , \"training_data\" , \"validation_data\" , \"test_data\" , \"results\" , \"hypothesis\" , \"prediction\" , \"method_source_code\" , \"hardware_specifications\" , \"software_dependencies\" , \"experiment_setup\" , \"experiment_source_code\" , \"affiliation\" , ] num_articles = 50 path_corpus = eg . init_paths ( num_articles = 50 , folder_name = \"mine50-csLG/\" ) repro_eval = eg . init_repro_eval ( path_corpus , num_articles ) found_vars_pdf = eg . get_found_vars ( path_corpus , repro_eval ) found_vars_tex = read_tex . get_found_vars_tex ( path_corpus , repro_eval ) repro_eval_filled_pdf = eg . set_repro_eval_scores ( concat ([ repro_eval , found_vars_pdf ], axis = 0 , join = \"inner\" ), gunderson_vars ) repro_eval_filled_tex = eg . set_repro_eval_scores ( concat ([ repro_eval , found_vars_tex ], axis = 0 , join = \"inner\" ), gunderson_vars , skip_affiliation = True , ) output_repro_eval_pdf = merge ( found_vars_pdf [[ \"id\" , \"title\" ]], repro_eval_filled_pdf , left_index = True , right_index = True , ) . drop_duplicates ( subset = [ \"id\" ]) output_repro_eval_tex = merge ( found_vars_tex [[ \"id\" , \"title\" ]], repro_eval_filled_tex , left_index = True , right_index = True , ) . drop_duplicates ( subset = [ \"id\" ]) # print(output_repro_eval_tex) # print(eg.get_manual_eval(path_corpus)) output_repro_eval_pdf . to_csv ( path_corpus + \"output/repro_eval.csv\" , index_label = \"index\" ) output_repro_eval_tex . to_csv ( path_corpus + \"output/repro_eval_tex.csv\" , index_label = \"index\" ) eg . compare_available_manual ( output_repro_eval_pdf , output_repro_eval_tex , eg . get_manual_eval ( path_corpus ), gunderson_vars , ) # eg.compare_available_manual(output_repro_eval_tex, eg.get_manual_eval(path_corpus), gunderson_vars) return output_repro_eval_pdf","title":"run_reproscreener()"},{"location":"todo/","text":"Todo Features [x] In Progress: Automatically check specific guidances to improve correctness of ML models [] Predict, capture and identify differences in model output at scale (due to architecture, non-determinism, etc.) [] Enable comparison of model code through Checks for modularity, file structure, dependencies Checks for steps/scripts to create figures & visualizations Track model benchmarks and provenance [] Progress bar (scrape): ( https://rich.readthedocs.io/en/latest/progress.html ) Development notes Non binary values in JSON guidance format would require custom keyword seach functions Include a way to add keywords to JSON and have it assigned to keywordparser Refactor so keywords functions are independent of guidance type MKDocs over Sphinx? Using shutil.copyfileobj to merge all tex files in an article's source folder into 1 file and then running keyword search on it. Would likely be more efficient than search over each file and combining the scores.","title":"Todo"},{"location":"todo/#todo","text":"","title":"Todo"},{"location":"todo/#features","text":"[x] In Progress: Automatically check specific guidances to improve correctness of ML models [] Predict, capture and identify differences in model output at scale (due to architecture, non-determinism, etc.) [] Enable comparison of model code through Checks for modularity, file structure, dependencies Checks for steps/scripts to create figures & visualizations Track model benchmarks and provenance [] Progress bar (scrape): ( https://rich.readthedocs.io/en/latest/progress.html )","title":"Features"},{"location":"todo/#development-notes","text":"Non binary values in JSON guidance format would require custom keyword seach functions Include a way to add keywords to JSON and have it assigned to keywordparser Refactor so keywords functions are independent of guidance type MKDocs over Sphinx? Using shutil.copyfileobj to merge all tex files in an article's source folder into 1 file and then running keyword search on it. Would likely be more efficient than search over each file and combining the scores.","title":"Development notes"},{"location":"usage/","text":"Usage Installation To use repro-screener, first clone the repository: ( .venv ) $ git clone git@github.com:Machine-Learning-Pipelines/repro-screener.git 1 Install the python package manager poetry . Install pyenv and pyenv-virtualenv Create a virtual environment with the correct python version (3.9.13): ( .venv ) $ pyenv install 3 .9.13 ( .venv ) $ pyenv virtualenv 3 .9.13 repro-screener ( .venv ) $ pyenv local repro-screener Install dependencies using poetry: ( .venv ) $ poetry install Install grobid, grobid-service and grobid-python-client: https://grobid.readthedocs.io/en/latest/Install-Grobid/ https://grobid.readthedocs.io/en/latest/Grobid-service/ https://github.com/kermitt2/grobid_client_python Run the run.sh bash script: ( .venv ) $ ./run.sh Project structure run.sh is the script used to run ReproScreener case-studies contains the papers that ReproScreener is developed and tested on guidance contains the set of metrics that ReproScreener will check for tests contains scripts and notebooks used during development src contains the main python scripts [1] Bhaskar, A. and Stodden, V. 2022. ReproScreen: Enabling Robustness in Machine Learning at Scale via Automated Knowledge Verification. (2022). DOI: https://doi.org/10.5281/ZENODO.6601019 . \u21a9","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#installation","text":"To use repro-screener, first clone the repository: ( .venv ) $ git clone git@github.com:Machine-Learning-Pipelines/repro-screener.git 1 Install the python package manager poetry . Install pyenv and pyenv-virtualenv Create a virtual environment with the correct python version (3.9.13): ( .venv ) $ pyenv install 3 .9.13 ( .venv ) $ pyenv virtualenv 3 .9.13 repro-screener ( .venv ) $ pyenv local repro-screener Install dependencies using poetry: ( .venv ) $ poetry install Install grobid, grobid-service and grobid-python-client: https://grobid.readthedocs.io/en/latest/Install-Grobid/ https://grobid.readthedocs.io/en/latest/Grobid-service/ https://github.com/kermitt2/grobid_client_python Run the run.sh bash script: ( .venv ) $ ./run.sh","title":"Installation"},{"location":"usage/#project-structure","text":"run.sh is the script used to run ReproScreener case-studies contains the papers that ReproScreener is developed and tested on guidance contains the set of metrics that ReproScreener will check for tests contains scripts and notebooks used during development src contains the main python scripts [1] Bhaskar, A. and Stodden, V. 2022. ReproScreen: Enabling Robustness in Machine Learning at Scale via Automated Knowledge Verification. (2022). DOI: https://doi.org/10.5281/ZENODO.6601019 . \u21a9","title":"Project structure"},{"location":"z_references/","text":"Bibliography [1] Bhaskar, A. and Stodden, V. 2022. ReproScreen: Enabling Robustness in Machine Learning at Scale via Automated Knowledge Verification. (2022). DOI: https://doi.org/10.5281/ZENODO.6601019 . \u21a9","title":"References"},{"location":"z_references/#bibliography","text":"[1] Bhaskar, A. and Stodden, V. 2022. ReproScreen: Enabling Robustness in Machine Learning at Scale via Automated Knowledge Verification. (2022). DOI: https://doi.org/10.5281/ZENODO.6601019 . \u21a9","title":"Bibliography"}]}