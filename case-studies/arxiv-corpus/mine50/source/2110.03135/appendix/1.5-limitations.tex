\section{Limitations}
\label{sect:limitation}
We note that alternative labeling of adversarial examples proposed in this paper is based on the fact that the predictive distribution of a classifier trained with empirical risk minimization can approximate the true label distribution of training examples. However, such approximation may not be accurate especially if the classifier is not carefully regularized during training. Post-training confidence calibration techniques such as temperature scaling and interpolation can only improve the approximation in terms of the entire training set, but cannot improve it in a sample-wise manner. How to learn the true label distribution of adversarial training examples during adversarial training more accurately remains an open problem.

Also, such alternative labeling also requires to train another independent classifier beforehand, which induces additional training cost. 