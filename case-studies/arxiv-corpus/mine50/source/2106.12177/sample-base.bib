
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@Article{Abril07,
  author        = "Patricia S. Abril and Robert Plant",
  title         = "The patent holder's dilemma: Buy, sell, or troll?",
  journal       = "Communications of the ACM",
  volume        = "50",
  number        = "1",
  month         = jan,
  year          = "2007",
  pages         = "36--44",
  doi           = "10.1145/1188913.1188915",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  note          = "",
}

@Article{Cohen07,
  author        = "Sarah Cohen and Werner Nutt and Yehoshua Sagic",
  title         = "Deciding equivalances among conjunctive aggregate queries",
  journal       = JACM,
  articleno     = 5,
  numpages      = 50,
  volume        = 54,
  number        = 2,
  month         = apr,
  year          = 2007,
  doi           = "10.1145/1219092.1219093",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  acmid         = 1219093,
}


@periodical{JCohen96,
  key =          "Cohen",
  editor =       "Jacques Cohen",
  title =        "Special issue: Digital Libraries",
  journal =      CACM,
  volume =       "39",
  number =       "11",
  month =        nov,
  year =         "1996",
}


@Book{Kosiur01,
  author =       "David Kosiur",
  title =        "Understanding Policy-Based Networking",
  publisher =    "Wiley",
  year =         "2001",
  address =      "New York, NY",
  edition =      "2nd.",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Harel79,
  author =       "David Harel",
  year =         "1979",
  title =        "First-Order Dynamic Logic",
  series =       "Lecture Notes in Computer Science",
  volume =       "68",
  address =      "New York, NY",
  publisher =    "Springer-Verlag",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09237-4",
  editor =       "",
  number =       "",
  month =        "",
  note =         "",
}


@Inbook{Editor00,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book one",
  subtitle =     "The book subtitle",
  series =       "The name of the series one",
  year =         "2007",
  volume =       "9",
  address =      "Chicago",
  edition =      "1st.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  chapter =      "",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}

%
@InBook{Editor00a,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book two",
  subtitle =     "The book subtitle",
  series =       "The name of the series two",
  year =         "2008",
  address =      "Chicago",
  edition =      "2nd.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  volume =       "",
  chapter =      "100",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Spector90,
  author =       "Asad Z. Spector",
  title =        "Achieving application requirements",
  booktitle =    "Distributed Systems",
  publisher =    "ACM Press",
  address =      "New York, NY",
  year =         "1990",
  edition =      "2nd.",
  chapter =      "",
  editor =       "Sape Mullender",
  pages =        "19--33",
  doi =          "10.1145/90417.90738",
  url =          "http://doi.acm.org/10.1145/90417.90738",
  volume =       "",
  number =       "",
  series =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Douglass98,
  author =       "Bruce P. Douglass and David Harel and Mark B. Trakhtenbrot",
  title =        "Statecarts in use: structured analysis and object-orientation",
  series =       "Lecture Notes in Computer Science",
  booktitle =    "Lectures on Embedded Systems",
  publisher =    "Springer-Verlag",
  address =      "London",
  volume =       "1494",
  year =         "1998",
  chapter =      "",
  editor =       "Grzegorz Rozenberg and Frits W. Vaandrager",
  pages =        "368--394",
  doi =          "10.1007/3-540-65193-4_29",
  url =          "http://dx.doi.org/10.1007/3-540-65193-4_29",
  edition =      "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


@Book{Knuth97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.)",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  year =         "1997",
  address =      "",
  edition =      "",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Knuth98,
  author =       "Donald E. Knuth",
  year =         "1998",
  title =        "The Art of Computer Programming",
  series =       "Fundamental Algorithms",
  volume =       "1",
  edition =      "3rd",
  address =      "",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  doi =          "",
  url =          "",
  editor =       "",
  number =       "",
  month =        "",
  note =         "(book)",
}

%Inbook{Knuth97,
%  author =       "Donald E. Knuth",
%  title =        "The Art of Computer Programming",
%  booktitle =    "the booktitle",
%  edition =      "3",
%  volume =       "1",
%  year =         "1997",
%  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
%  editor =       "",
%  number =       "",
%  series =       "Fundamental Algorithms",
%  type =         "",
%  chapter =      "",
%  pages =        "",
%  address =      "",
%  month =        "",
%  note =         "(inbook)",
%}

%INBOOK{DK:73-inbook-full,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (inbook w series)",
%   volume = 1,
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   edition = "Second",
%   month = "10~" # jan,
%   year = "1973",
%   type = "Section",
%   chapter = "1.2",
%   pages = "10--119",
%   note = "Full INBOOK entry (w series)",
%}

%INcollection{DK:74-incoll,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1974",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor",
%}

%INcollection{DK:75-incollws,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll w series)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1975",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor and series",
%}


@incollection{GM05,
Author= "Dan Geiger and Christopher Meek",
Title= "Structured Variational Inference Procedures and their Realizations (as incol)",
Year= 2005,
Booktitle="Proceedings of Tenth International Workshop on Artificial Intelligence and Statistics, {\rm The Barbados}",
Publisher="The Society for Artificial Intelligence and Statistics",
Month= jan,
Editors= "Z. Ghahramani and R. Cowell"
}

@Inproceedings{Smith10,
  author =       "Stan W. Smith",
  title =        "An experiment in bibliographic mark-up: Parsing metadata for XML export",
  booktitle =    "Proceedings of the 3rd. annual workshop on Librarians and Computers",
  series =       "LAC '10",
  editor =       "Reginald N. Smythe and Alexander Noble",
  volume =       "3",
  year =         "2010",
  publisher =    "Paparazzi Press",
  address =      "Milan Italy",
  pages =        "422--431",
  doi =          "99.9999/woot07-S422",
  url =          "http://dx.doi.org/99.0000/woot07-S422",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy07,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2007,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '07",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    {Paper 7},
  numpages =     9,
}

@Inproceedings{VanGundy08,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2008,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '08",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    7,
  numpages =     2,
  pages =        "99-100",
}

@Inproceedings{VanGundy09,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2009,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '09",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  pages =        "90--100",
}

@Inproceedings{Andler79,
  author =       "Sten Andler",
  title =        "Predicate Path expressions",
  booktitle =    "Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages",
  series =       "POPL '79",
  year =         "1979",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "226--236",
  doi =          "10.1145/567752.567774",
  url =          "http://doi.acm.org/10.1145/567752.567774",
  editor =       "",
  volume =       "",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Techreport{Harel78,
  author =       "David Harel",
  year =         "1978",
  title =        "LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         "",
}

@MASTERSTHESIS{anisi03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}


@Phdthesis{Clarkson85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        "",
}


@online{Thornburg01,
  author =       "Harry Thornburg",
  year =         "2001",
  title =        "Introduction to Bayesian Statistics",
  url =          "http://ccrma.stanford.edu/~jos/bayes/bayes.html",
  month =        mar,
  lastaccessed = "March 2, 2005",
}


@online{Ablamowicz07,
  author =       "Rafal Ablamowicz and Bertfried Fauser",
  year =         "2007",
  title =        "CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11",
  url =          "http://math.tntech.edu/rafal/cliff11/index.html",
  lastaccessed = "February 28, 2008",
}


@misc{Poker06,
  author =       "Poker-Edge.Com",
  year =         "2006",
  month =        mar,
  title =        "Stats and Analysis",
  lastaccessed = "June 7, 2006",
  url =          "http://www.poker-edge.com/stats.php",
}

@misc{Obama08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A more perfect union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  "",
}

@misc{JoeScientist001,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = "",
}


@Inproceedings{Novak03,
  author =       "Dave Novak",
  title =        "Solder man",
  booktitle =    "ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27--27, 2003)",
  year =         "2003",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "4",
  month =        "March 21, 2008",
  doi =          "99.9999/woot07-S422",
  url =          "http://video.google.com/videoplay?docid=6528042696351994555",
  note =         "",
  howpublished = "Video",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  organization = "",
}


@article{Lee05,
  author =       "Newton Lee",
  year =         "2005",
  title =        "Interview with Bill Kinder: January 13, 2005",
  journal =      "Comput. Entertain.",
  eid =          "4",
  volume =       "3",
  number =       "1",
  month =        "Jan.-March",
  doi =          "10.1145/1057270.1057278",
  url =          "http://doi.acm.org/10.1145/1057270.1057278",
  howpublished = "Video",
  note =         "",
}

@article{rous08,
  author =       "Bernard Rous",
  year =         "2008",
  title =        "The Enabling of Digital Libraries",
  journal =      "Digital Libraries",
  volume =       "12",
  number =       "3",
  month =        jul,
  articleno =    "Article~5",
  doi =          "",
  url =          "",
  howpublished = "",
  note =         "To appear",
}

@article{384253,
 author = {Werneck,, Renato and Setubal,, Jo\~{a}o and da Conceic\~{a}o,, Arlindo},
 title = {(old) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 year = {2000},
 issn = {1084-6654},
 pages = {11},
 doi = {http://doi.acm.org/10.1145/351827.384253},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@article{Werneck:2000:FMC:351827.384253,
 author = {Werneck, Renato and Setubal, Jo\~{a}o and da Conceic\~{a}o, Arlindo},
 title = {(new) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = 5,
 month = dec,
 year = 2000,
 issn = {1084-6654},
 articleno = 11,
 url = {http://portal.acm.org/citation.cfm?id=351827.384253},
 doi = {10.1145/351827.384253},
 acmid = 384253,
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(old) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 doi = {http://dx.doi.org/10.1016/j.inffus.2009.01.002},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Conti:2009:DDS:1555009.1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(new) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 month = oct,
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 numpages = {12},
 url = {http://portal.acm.org/citation.cfm?id=1555009.1555162},
 doi = {10.1016/j.inffus.2009.01.002},
 acmid = {1555162},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Clone detection, Distributed protocol, Securing data fusion, Wireless sensor networks},
}

@inproceedings{Li:2008:PUC:1358628.1358946,
 author = {Li, Cheng-Lun and Buyuktur, Ayse G. and Hutchful, David K. and Sant, Natasha B. and Nainwal, Satyendra K.},
 title = {Portalis: using competitive online interactions to support aid initiatives for the homeless},
 booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 pages = {3873--3878},
 numpages = {6},
 url = {http://portal.acm.org/citation.cfm?id=1358628.1358946},
 doi = {10.1145/1358628.1358946},
 acmid = {1358946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cscw, distributed knowledge acquisition, incentive design, online games, recommender systems, reputation systems, user studies, virtual community},
}

@book{Hollis:1999:VBD:519964,
 author = {Hollis, Billy S.},
 title = {Visual Basic 6: Design, Specification, and Objects with Other},
 year = {1999},
 isbn = {0130850845},
 edition = {1st},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
 }


@book{Goossens:1999:LWC:553897,
 author = {Goossens, Michel and Rahtz, S. P. and Moore, Ross and Sutor, Robert S.},
 title = {The  Latex Web Companion: Integrating TEX, HTML, and XML},
 year = {1999},
 isbn = {0201433117},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

% need to test genres for errant isbn output

% techreport
@techreport{897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

@techreport{Buss:1987:VTB:897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

% whole proceedings

@proceedings{Czerwinski:2008:1358628,
 author = {},
 note = {General Chair-Czerwinski, Mary and General Chair-Lund, Arnie and Program Chair-Tan, Desney},
 title = {CHI '08: CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 order_no = {608085},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

% phdthesis

@phdthesis{Clarkson:1985:ACP:911891,
 author = {Clarkson, Kenneth Lee},
 advisor = {Yao, Andrew C.},
 title = {Algorithms for Closest-Point Problems (Computational Geometry)},
 year = {1985},
 note = {AAT 8506171},
 school = {Stanford University},
 address = {Stanford, CA, USA},
 }
% school is being picked up -- but not publisher (which is OK)
% Also -- the title is NOT being output in italics !!! Arrrrgh! - I fixed it. :-)


%%% compare with 'old'
%%% atsign-Phdthesis{Clarkson85,
%%%  author =       "Kenneth L. Clarkson",
%%%  year =         "1985",
%%%  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
%%%  school =       "Stanford University",
%%%  address =      "Palo Alto, CA",
%%%  note =         "UMI Order Number: AAT 8506171",
%%%  type =         "",
%%%  month =        "",
%%%}

% A bibliography
@Article{1984:1040142,
 key = {{$\!\!$}},
 journal = {SIGCOMM Comput. Commun. Rev.},
 year = {1984},
 issn = {0146-4833},
 volume = {13-14},
 number = {5-1},
 issue_date = {January/April 1984},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


% grinder
@inproceedings{2004:ITE:1009386.1010128,
 key = {IEEE},
 title = {IEEE TCSC Executive Committee},
 booktitle = {Proceedings of the IEEE International Conference on Web Services},
 series = {ICWS '04},
 year = {2004},
 isbn = {0-7695-2167-3},
 pages = {21--22},
 url = {http://dx.doi.org/10.1109/ICWS.2004.64},
 doi = {http://dx.doi.org/10.1109/ICWS.2004.64},
 acmid = {1010128},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

% div book
@book{Mullender:1993:DS:302430,
 editor = {Mullender, Sape},
 title = {Distributed systems (2nd Ed.)},
 year = {1993},
 isbn = {0-201-62427-3},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 address = {New York, NY, USA},
 }

% master thesis (as techreport and thesis)

@techreport{Petrie:1986:NAD:899644,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 publisher = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }

@MASTERSTHESIS{Petrie:1986:NAD:12345,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 school = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }




@BOOK{book-minimal,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   publisher = "Addison-Wesley",
   year = "1981",
}

% incollection (has an editor, title, and possibly a booktitle)
@INcollection{KA:2001,
 author = {Kong, Wei-Chang},
 Title = {The implementation of electronic commerce in SMEs in Singapore (as Incoll)},
 booktitle = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}


% with bibfield 'type' before chapter (note no editor)
@INBOOK{KAGM:2001,
 author = {Kong, Wei-Chang},
 type = {Name of Chapter:},
 chapter = {The implementation of electronic commerce in SMEs in Singapore (Inbook-w-chap-w-type)},
 title = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

%%% Notes! This is because the atsign-INBOOK citation type specifies EITHER
%%% editor or author, but not both. In my experiments with the harvard/dcu
%%% bibtex style (and presumably this applies to other styles too), bibtex
%%% ignores the editor information if author information exists in an
%%% atsign-INBOOK entry. atsign-INCOLLECTION is far more commonly used in my references,
%%% and in the absence of an editor I believe most bibtex styles will just
%%% ommit the editor from the reference - the chapter information will not
%%% end up in the in-text citation as you suggest it should be but at least
%%% there is a place to put the editor if necessary.



% was 'Inbook' -- changed to incollection - (editor is different to author) - need to tell Asad to codify as such.
@incollection{Kong:2002:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {Chapter 9},
  booktitle =   {E-commerce and cultural values (Incoll-w-text (chap 9) 'title')},
  year =        {2002},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}

% incol when the chapter is 'text' - due to presence of editor (different to author)
@incollection{Kong:2003:IEC:887006.887011,
 author = {Kong, Wei-Chang},
 title = {The implementation of electronic commerce in SMEs in Singapore (Incoll)},
 booktitle = {E-commerce and cultural values},
 editor = {Thanasankit, Theerasak},
 year = {2003},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

% ------ test
%incollection{Kong:2003:IEC:887006.887010,
% author = {Kong, Wei-Chang},
% chapter = {The implementation of electronic commerce in SMEs in Singapore (Incoll-text-in-chap)},
% booktitle = {booktitle E-commerce and cultural values},
% title =   {The title},
% editor = {Thanasankit, Theerasak},
% year = {2003},
% isbn = {1-59140-056-2},
% pages = {51--74},
% numpages = {24},
% url = {http://portal.acm.org/citation.cfm?id=887006.887010},
% acmid = {887010},
% publisher = {IGI Publishing},
% address = {Hershey, PA, USA},
%}


% ---------





% Need inbook with num in chapter

% and inbook with number in chapter
@InBook{Kong:2004:IEC:123456.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values - (InBook-num-in-chap)},
  chapter =     {9},
  year =        {2004},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}


% and inbook with text in chapter
@Inbook{Kong:2005:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-text-in-chap)},
  chapter =     {The implementation of electronic commerce in SMEs in Singapore},
  year =        {2005},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter:},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and inbook with a num and type field
@Inbook{Kong:2006:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-num chap)},
  chapter =     {22},
  year =        {2006},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter (in type field)},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and incol coz we have a BLANK chapter - due to presence of editor
%atIncollection{Kong:2006:IEC:887006.887011,
%  author =     {Kong, Wei-Chang},
%  editor =     {Theerasak Thanasankit},
%  title =      "The title"
%  booktitle =  {E-commerce and cultural values (Incol-coz-blank-chap)},
%  year =       {2006},
%  address =    {Hershey, PA, USA},
%  publisher =  {IGI Publishing},
%  url =        {http://portal.acm.org/citation.cfm?id=887006.887010},
%  type =       {Type!},
%  chapter =    {},
%  pages =      {51--74},
%  numpages =   {24},
%  acmid =      {887010},
%  isbn =       {1-59140-056-2},
%  number =     "",
%  month =      "",
%  note =       "",
%}

@article{SaeediMEJ10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi},
            title = {A library-based synthesis methodology for reversible logic},
            journal = {Microelectron. J.},
            volume = {41},
            number = {4},
            month = apr,
            year = {2010},
            pages = {185--194},
}

@ARTICLE{SaeediJETC10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi and Zahra Sasanian},
            title = {Synthesis of Reversible Circuit Using Cycle-Based Approach},
            journal = {J. Emerg. Technol. Comput. Syst.},
            volume = {6},
            number = {4},
            month = dec,
            year = {2010}
            }

% Asad's new version
@article{Kirschmer:2010:AEI:1958016.1958018,
 author = {Kirschmer, Markus and Voight, John},
 title = {Algorithmic Enumeration of Ideal Classes for Quaternion Orders},
 journal = {SIAM J. Comput.},
 issue_date = {January 2010},
 volume = {39},
 number = {5},
 month = jan,
 year = {2010},
 issn = {0097-5397},
 pages = {1714--1747},
 numpages = {34},
 url = {http://dx.doi.org/10.1137/080734467},
 doi = {https://doi.org/10.1137/080734467},
 acmid = {1958018},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {ideal classes, maximal orders, number theory, quaternion algebras},
}


% incol due to presence of booktitle
@incollection{Hoare:1972:CIN:1243380.1243382,
 author = {Hoare, C. A. R.},
 title = {Chapter II: Notes on data structuring},
 booktitle = {Structured programming (incoll)},
 editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
 year = {1972},
 isbn = {0-12-200550-3},
 pages = {83--174},
 numpages = {92},
 url = {http://portal.acm.org/citation.cfm?id=1243380.1243382},
 acmid = {1243382},
 publisher = {Academic Press Ltd.},
 address = {London, UK, UK},
}

% incol due to presence of booktitle
@incollection{Lee:1978:TQA:800025.1198348,
 author = {Lee, Jan},
 title = {Transcript of question and answer session},
 booktitle = {History of programming languages I (incoll)},
 editor = {Wexelblat, Richard L.},
 year = {1981},
 isbn = {0-12-745040-8},
 pages = {68--71},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/800025.1198348},
 doi = {http://doi.acm.org/10.1145/800025.1198348},
 acmid = {1198348},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Dijkstra:1979:GSC:1241515.1241518,
 author = {Dijkstra, E.},
 title = {Go to statement considered harmful},
 booktitle = {Classics in software engineering (incoll)},
 year = {1979},
 isbn = {0-917072-14-6},
 pages = {27--33},
 numpages = {7},
 url = {http://portal.acm.org/citation.cfm?id=1241515.1241518},
 acmid = {1241518},
 publisher = {Yourdon Press},
 address = {Upper Saddle River, NJ, USA},
}

% incol due to booktitle
@incollection{Wenzel:1992:TVA:146022.146089,
 author = {Wenzel, Elizabeth M.},
 title = {Three-dimensional virtual acoustic displays},
 booktitle = {Multimedia interface design (incoll)},
 year = {1992},
 isbn = {0-201-54981-6},
 pages = {257--288},
 numpages = {32},
 url = {http://portal.acm.org/citation.cfm?id=146022.146089},
 doi = {10.1145/146022.146089},
 acmid = {146089},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Mumford:1987:MES:54905.54911,
 author = {Mumford, E.},
 title = {Managerial expert systems and organizational change: some critical research issues},
 booktitle = {Critical issues in information systems research (incoll)},
 year = {1987},
 isbn = {0-471-91281-6},
 pages = {135--155},
 numpages = {21},
 url = {http://portal.acm.org/citation.cfm?id=54905.54911},
 acmid = {54911},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

@book{McCracken:1990:SSC:575315,
 author = {McCracken, Daniel D. and Golden, Donald G.},
 title = {Simplified Structured COBOL with Microsoft/MicroFocus COBOL},
 year = {1990},
 isbn = {0471514071},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

% Let's include Boris / BBeeton entries  (multi-volume works)

@book {MR781537,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {III}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Pseudodifferential operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {viii+525},
      ISBN = {3-540-13828-5},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781536 (87d:35002a)},
MRREVIEWER = {Min You Qi},
}

@book {MR781536,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {IV}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Fourier integral operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {vii+352},
      ISBN = {3-540-13829-3},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781537 (87d:35002b)},
MRREVIEWER = {Min You Qi},
}

%%%%%%%%%%%%%%%%%%%%%% Start of Aptara sample bib entries

% acmsmall-sam.bib
@InProceedings{Adya-01,
  author        = {A. Adya and P. Bahl and J. Padhye and A.Wolman and L. Zhou},
  title         = {A multi-radio unification protocol for {IEEE} 802.11 wireless networks},
  booktitle     = {Proceedings of the IEEE 1st International Conference on Broadnets Networks (BroadNets'04)},
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "210--217"
}

@article{Akyildiz-01,
  author        = {I. F. Akyildiz and W. Su and Y. Sankarasubramaniam and E. Cayirci},
  title         = {Wireless Sensor Networks: A Survey},
  journal       = {Comm. ACM},
  volume        = 38,
  number        = "4",
  year          = {2002},
  pages         = "393--422"
}

@article{Akyildiz-02,
  author        = {I. F. Akyildiz and T. Melodia and K. R. Chowdhury},
  title         = {A Survey on Wireless Multimedia Sensor Networks},
  journal       = {Computer Netw.},
  volume        = 51,
  number        = "4",
  year          = {2007},
  pages         = "921--960"
}

@InProceedings{Bahl-02,
  author        = {P. Bahl and R. Chancre and J. Dungeon},
  title         = {{SSCH}: Slotted Seeded Channel Hopping for Capacity Improvement in {IEEE} 802.11 Ad-Hoc Wireless Networks},
  booktitle     = {Proceeding of the 10th International Conference on Mobile Computing and Networking (MobiCom'04)},
  publisher     = "ACM",
  address       = "New York, NY",
  year          = {2004},
  pages         = "112--117"
}

@misc{CROSSBOW,
  key       = {CROSSBOW},
  title     = {{XBOW} Sensor Motes Specifications},
  note      = {http://www.xbow.com},
  year      = 2008
}

@article{Culler-01,
  author        = {D. Culler and D. Estrin and M. Srivastava},
  title         = {Overview of Sensor Networks},
  journal       = {IEEE Comput.},
  volume        = 37,
  number        = "8 (Special Issue on Sensor Networks)",
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "41--49"
}

@misc{Harvard-01,
    key         = {Harvard CodeBlue},
    title       = {{CodeBlue}: Sensor Networks for Medical Care},
    note        = {http://www.eecs.harvard.edu/mdw/ proj/codeblue/},
    year        = 2008
}

@InProceedings{Natarajan-01,
    author      = {A. Natarajan and M. Motani and B. de Silva and K. Yap and K. C. Chua},
    title       = {Investigating Network Architectures for Body Sensor Networks},
    booktitle   = {Network Architectures},
    editor      = {G. Whitcomb and P. Neece},
    publisher   = "Keleuven Press",
    address     = "Dayton, OH",
    year        = {2007},
    pages       = "322--328",
    eprint      = "960935712",
    primaryclass = "cs",
}

@techreport{Tzamaloukas-01,
  author        = {A. Tzamaloukas and J. J. Garcia-Luna-Aceves},
  title         = {Channel-Hopping Multiple Access},
  number =        {I-CA2301},
  institution =   {Department of Computer Science, University of California},
  address =       {Berkeley, CA},
  year          = {2000}
}

@BOOK{Zhou-06,
  author        = {G. Zhou and J. Lu and C.-Y. Wan and M. D. Yarvis and J. A. Stankovic},
  title         = {Body Sensor Networks},
  publisher     = "MIT Press",
  address       = "Cambridge, MA",
  year          = {2008}
}

@mastersthesis{ko94,
author = "Jacob Kornerup",
title = "Mapping Powerlists onto Hypercubes",
school = "The University of Texas at Austin",
note = "(In preparation)",
year = "1994"}
%month = "dec",}

@PhdThesis{gerndt:89,
  author =       "Michael Gerndt",
  title =        "Automatic Parallelization for Distributed-Memory
                  Multiprocessing Systems",
  school =       "University of Bonn",
  year =         1989,
  address =      "Bonn, Germany",
  month =        dec
}

@article{6:1:1,
author = "J. E. {Archer, Jr.} and R. Conway and F. B. Schneider",
title = "User recovery and reversal in interactive systems",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "1",
month = jan,
year = 1984,
pages = "1--19"}

@article{7:1:137,
author = "D. D. Dunlop and V. R. Basili",
title = "Generalizing specifications for uniformly implemented loops",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "1",
month = jan,
year = 1985,
pages = "137--158"}

@article{7:2:183,
author = "J. Heering and P. Klint",
title = "Towards monolingual programming environments",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "2",
month = apr,
year = 1985,
pages = "183--213"}

@book{knuth:texbook,
author = "Donald E. Knuth",
title = "The {\TeX{}book}",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1984}

@article{6:3:380,
author = "E. Korach and D.  Rotem and N. Santoro",
title = "Distributed algorithms for finding centers and medians in networks",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "3",
month = jul,
year = 1984,
pages = "380--401"}

@book{Lamport:LaTeX,
author = "Leslie Lamport",
title = "\it {\LaTeX}: A Document Preparation System",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1986}

@article{7:3:359,
author = "F. Nielson",
title = "Program transformations in a denotational setting",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "3",
month = jul,
year = 1985,
pages = "359--379"}

%testing
@BOOK{test,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   volume = 2,
   series = "The Art of Computer Programming",
   publisher = "Addison-Wesley",
   address = "Reading, MA",
   edition = "2nd",
   month = "10~" # jan,
   year = "1981",
}

@inproceedings{reid:scribe,
author = "Brian K. Reid",
title = "A high-level approach to computer document formatting",
booktitle = "Proceedings of the 7th Annual Symposium on Principles of
  Programming Languages",
month = jan,
year = 1980,
publisher = "ACM",
address = "New York",
pages = "24--31"}

@article{Zhou:2010:MMS:1721695.1721705,
 author = {Zhou, Gang and Wu, Yafeng and Yan, Ting and He, Tian and Huang, Chengdu and Stankovic, John A. and Abdelzaher, Tarek F.},
 title = {A multifrequency MAC specially designed for wireless sensor network applications},
 journal = {ACM Trans. Embed. Comput. Syst.},
 issue_date = {March 2010},
 volume = 9,
 number = 4,
 month = {April},
 year = 2010,
 issn = {1539-9087},
 pages = {39:1--39:41},
 articleno = 39,
 numpages = 41,
 url = {http://doi.acm.org/10.1145/1721695.1721705},
 doi = {10.1145/1721695.1721705},
 acmid = 1721705,
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Wireless sensor networks, media access control, multi-channel, radio interference, time synchronization},
}


@online{TUGInstmem,
  key =          {TUG},
  year  =        2017,
  title =        "Institutional members of the {\TeX} Users Group",
  url =          "http://wwtug.org/instmem.html",
  lastaccessed = "May 27, 2017",
}

@online{CTANacmart,
  author =    {Boris Veytsman},
  title =  {acmart---{C}lass for typesetting publications of {ACM}},
  url =    {http://www.ctan.org/pkg/acmart},
  lastaccessed = {May 27, 2017}
  }

@ARTICLE{bowman:reasoning,
    author = {Bowman, Mic and Debray, Saumya K. and Peterson, Larry L.},
    title = {Reasoning About Naming Systems},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {795-825},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161471},
}

@ARTICLE{braams:babel,
    author = {Braams, Johannes},
    title = {Babel, a Multilingual Style-Option System for Use with LaTeX's Standard Document Styles},
    journal = {TUGboat},
    volume = {12},
    number = {2},
    pages = {291-301},
    month = {June},
    year = {1991},
}

@INPROCEEDINGS{clark:pct,
  AUTHOR = "Malcolm Clark",
  TITLE = "Post Congress Tristesse",
  BOOKTITLE = "TeX90 Conference Proceedings",
  PAGES = "84-89",
  ORGANIZATION = "TeX Users Group",
  MONTH = "March",
  YEAR = {1991}
}

@ARTICLE{herlihy:methodology,
    author = {Herlihy, Maurice},
    title = {A Methodology for Implementing Highly Concurrent Data Objects},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {745-770},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161469},
}

@BOOK{salas:calculus,
  AUTHOR = "S.L. Salas and Einar Hille",
  TITLE = "Calculus: One and Several Variable",
  PUBLISHER = "John Wiley and Sons",
  ADDRESS = "New York",
  YEAR = "1978"
}

@MANUAL{Fear05,
  title =        {Publication quality tables in {\LaTeX}},
  author =       {Simon Fear},
  month =        {April},
  year =         2005,
  note =         {\url{http://www.ctan.org/pkg/booktabs}}
}

@Manual{Amsthm15,
  title =        {Using the amsthm Package},
  organization = {American Mathematical Society},
  month =        {April},
  year =         2015,
  note =         {\url{http://www.ctan.org/pkg/amsthm}}
}

@ArtifactSoftware{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
}

@ArtifactDataset{UMassCitations,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}

@Eprint{Bornmann2019,
       author = {Bornmann, Lutz and Wray, K. Brad and Haunschild,
                  Robin},
        title = {Citation concept analysis {(CCA)}---A new form of
                  citation analysis revealing the usefulness of
                  concepts for other researchers illustrated by two
                  exemplary case studies including classic books by
                  {Thomas S.~Kuhn} and {Karl R.~Popper}},
     keywords = {Computer Science - Digital Libraries},
         year = 2019,
        month = "May",
          eid = {arXiv:1905.12410},
archivePrefix = {arXiv},
       eprint = {1905.12410},
 primaryClass = {cs.DL},
}

@Eprint{AnzarootPBM14,
  author    = {Sam Anzaroot and
               Alexandre Passos and
               David Belanger and
               Andrew McCallum},
  title     = {Learning Soft Linear Constraints with Application to
                  Citation Field Extraction},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1403.1349},
}

@inproceedings{Hagerup1993,
title        = {Maintaining Discrete Probability Distributions Optimally},
author       = {Hagerup, Torben and Mehlhorn, Kurt and Munro, J. Ian},
booktitle    = {Proceedings of the 20th International Colloquium on Automata, Languages and Programming},
series       = {Lecture Notes in Computer Science},
volume       = {700},
pages        = {253--264},
year         = {1993},
publisher    = {Springer-Verlag},
address      = {Berlin},
}

@incollection{songMultiAgentGenerativeAdversarial2018,
	title = {Multi-{Agent} {Generative} {Adversarial} {Imitation} {Learning}},
	url = {http://papers.nips.cc/paper/7975-multi-agent-generative-adversarial-imitation-learning.pdf},
	urldate = {2020-09-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Song, Jiaming and Ren, Hongyu and Sadigh, Dorsa and Ermon, Stefano},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {7461--7472},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/NX9CIWV9/7975-multi-agent-generative-adversarial-imitation-learning.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/WCJF7A8Y/Song et al. - 2018 - Multi-Agent Generative Adversarial Imitation Learn.pdf:application/pdf}
}

@inproceedings{liuImitationObservationLearning2018,
  title={Imitation from observation: Learning to imitate behaviors from raw video via context translation},
  author={Liu, YuXuan and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1118--1125},
  year={2018},
  organization={IEEE}
}

@incollection{wangRobustImitationDiverse2017,
	title = {Robust {Imitation} of {Diverse} {Behaviors}},
	url = {http://papers.nips.cc/paper/7116-robust-imitation-of-diverse-behaviors.pdf},
	urldate = {2020-09-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Wang, Ziyu and Merel, Josh S and Reed, Scott E and de Freitas, Nando and Wayne, Gregory and Heess, Nicolas},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {5320--5329},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/Y7EPQ84L/7116-robust-imitation-of-diverse-behaviors.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/BABPS2RI/Wang et al. - 2017 - Robust Imitation of Diverse Behaviors.pdf:application/pdf}
}

@inproceedings{pathakZeroShotVisualImitation2018,
	address = {Salt Lake City, UT, USA},
	title = {Zero-{Shot} {Visual} {Imitation}},
	isbn = {978-1-5386-6100-0},
	url = {https://ieeexplore.ieee.org/document/8575448/},
	doi = {10.1109/CVPRW.2018.00278},
	language = {en},
	urldate = {2020-09-01},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Fred and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A. and Darrell, Trevor},
	month = jun,
	year = {2018},
	pages = {2131--21313},
	file = {Pathak et al. - 2018 - Zero-Shot Visual Imitation.pdf:/home/bryan/Zotero/storage/V48CHURY/Pathak et al. - 2018 - Zero-Shot Visual Imitation.pdf:application/pdf}
}

@incollection{aytarPlayingHardExploration2018,
	title = {Playing hard exploration games by watching {YouTube}},
	url = {http://papers.nips.cc/paper/7557-playing-hard-exploration-games-by-watching-youtube.pdf},
	urldate = {2020-09-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Aytar, Yusuf and Pfaff, Tobias and Budden, David and Paine, Thomas and Wang, Ziyu and de Freitas, Nando},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {2930--2941},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/N9TYY23T/7557-playing-hard-exploration-games-by-watching-youtube.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/V2TJJSCT/Aytar et al. - 2018 - Playing hard exploration games by watching YouTube.pdf:application/pdf}
}

@inproceedings{baramEndtoEndDifferentiableAdversarial2017,
  title={End-to-end differentiable adversarial imitation learning},
  author={Baram, Nir and Anschel, Oron and Caspi, Itai and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={390--399},
  year={2017}
}


@incollection{pomerleauALVINNAutonomousLand1989,
	title = {{ALVINN}: {An} {Autonomous} {Land} {Vehicle} in a {Neural} {Network}},
	shorttitle = {{ALVINN}},
	url = {http://papers.nips.cc/paper/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf},
	urldate = {2020-08-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 1},
	publisher = {Morgan-Kaufmann},
	author = {Pomerleau, Dean A.},
	editor = {Touretzky, D. S.},
	year = {1989},
	pages = {305--313},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/5J2RKF8A/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/USQ2K468/Pomerleau - 1989 - ALVINN An Autonomous Land Vehicle in a Neural Net.pdf:application/pdf}
}

@inproceedings{bainFrameworkBehaviouralCloning1999,
	title = {A framework for behavioural cloning},
	abstract = {This paper describes recent experiments in automatically constructing reactive agents. The method used is behavioural cloning, where the logged data from skilled, human operators are input to an induction program which outputs a control strategy for a complex control task. Initial studies were able to successfully construct such behavioural clones, but suffered from several drawbacks, namely, that the clones were brittle and difficult to understand. Current research is aimed at solving these problems by learning in a framework where there is a separation between an agent’s goals and its knowledge of how to achieve them. 1},
	booktitle = {Machine {Intelligence} 15},
	publisher = {Oxford University Press},
	author = {Bain, Michael and Sammut, Claude},
	year = {1999},
	pages = {103--129},
	file = {Citeseer - Full Text PDF:/home/bryan/Zotero/storage/C9Q8KBIH/Bain and Sammut - 1999 - A framework for behavioural cloning.pdf:application/pdf;Citeseer - Snapshot:/home/bryan/Zotero/storage/T8NFG2NF/summary.html:text/html}
}

@article{lioutikovLearningMovementPrimitive2017,
	title = {Learning movement primitive libraries through probabilistic segmentation},
	volume = {36},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364917713116},
	doi = {10.1177/0278364917713116},
	abstract = {Movement primitives are a well-established approach for encoding and executing movements. While the primitives themselves have been extensively researched, the concept of movement primitive libraries has not received similar attention. Libraries of movement primitives represent the skill set of an agent. Primitives can be queried and sequenced in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into a representative set of primitives. Our proposed method differs from current approaches by taking advantage of the often neglected, mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. By exploiting this mutual dependency, we show that we can improve both the segmentation and the movement primitive library. Based on probabilistic inference our novel approach segments the demonstrations while learning a probabilistic representation of movement primitives. We demonstrate our method on two real robot applications. First, the robot segments sequences of different letters into a library, explaining the observed trajectories. Second, the robot segments demonstrations of a chair assembly task into a movement primitive library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.},
	number = {8},
	urldate = {2020-08-09},
	journal = {The International Journal of Robotics Research},
	author = {Lioutikov, Rudolf and Neumann, Gerhard and Maeda, Guilherme and Peters, Jan},
	month = jul,
	year = {2017},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {879--894},
	file = {SAGE PDF Full Text:/home/bryan/Zotero/storage/M8PIDPN2/Lioutikov et al. - 2017 - Learning movement primitive libraries through prob.pdf:application/pdf}
}

@article{songweakly2020,
  title={Weakly Supervised Group Mask Network for Object Detection},
  author={Song, Lingyun and Liu, Jun and Sun, Mingxuan and Shang, Xuequn},
  journal={International Journal of Computer Vision},
  url={https://doi.org/10.1007/s11263-020-01397-w},
  year={2020}
}

@article{hufinegrained2020,
  author={X. {Hu} and J. {Liu} and J. {Ma} and Y. {Pan} and L. {Zhang}},
  journal={Neural Computation}, 
  title={Fine-Grained 3D-Attention Prototypes for Few-Shot Learning}, 
  year={2020},
  volume={32},
  number={9},
  pages={1664-1684},
  doi={10.1162/neco_a_01302}}

@article{liu2019ahng,
  title={AHNG: representation learning on attributed heterogeneous network},
  author={Liu, Mengyue and Liu, Jun and Chen, Yihe and Wang, Meng and Chen, Hao and Zheng, Qinghua},
  journal={Information Fusion},
  volume={50},
  pages={221--230},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{finnGuidedCostLearning2016,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{stadieThirdPersonImitationLearning2017,
  title={Third-person imitation learning},
  author={Stadie, Bradly C and Abbeel, Pieter and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.01703},
  year={2017}
}

@article{finnOneShotVisualImitation2017,
	title = {One-{Shot} {Visual} {Imitation} {Learning} via {Meta}-{Learning}},
	url = {http://arxiv.org/abs/1709.04905},
	abstract = {In order for a robot to be a generalist that can perform a wide range of jobs, it must be able to acquire a wide variety of skills quickly and efficiently in complex unstructured environments. High-capacity models such as deep neural networks can enable a robot to represent complex skills, but learning each skill from scratch then becomes infeasible. In this work, we present a meta-imitation learning method that enables a robot to learn how to learn more efficiently, allowing it to acquire new skills from just a single demonstration. Unlike prior methods for one-shot imitation, our method can scale to raw pixel inputs and requires data from significantly fewer prior tasks for effective learning of new skills. Our experiments on both simulated and real robot platforms demonstrate the ability to learn new tasks, end-to-end, from a single visual demonstration.},
	urldate = {2020-08-09},
	journal = {arXiv:1709.04905 [cs]},
	author = {Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.04905},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
	annote = {Comment: Conference on Robot Learning, 2017 (to appear). First two authors contributed equally. Video available at https://sites.google.com/view/one-shot-imitation},
	file = {arXiv.org Snapshot:/home/bryan/Zotero/storage/VH9HWTEY/1709.html:text/html;arXiv Fulltext PDF:/home/bryan/Zotero/storage/YI8U6VZE/Finn et al. - 2017 - One-Shot Visual Imitation Learning via Meta-Learni.pdf:application/pdf}
}

@inproceedings{finnModelAgnosticMetaLearningFast2017,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{guptaLearningInvariantFeature2017,
  title={Learning invariant feature spaces to transfer skills with reinforcement learning},
  author={Gupta, Abhishek and Devin, Coline and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1703.02949},
  year={2017} 
}

@article{osaOnlineTrajectoryPlanning2018,
	title = {Online {Trajectory} {Planning} and {Force} {Control} for {Automation} of {Surgical} {Tasks}},
	volume = {15},
	issn = {1558-3783},
	doi = {10.1109/TASE.2017.2676018},
	abstract = {Automation of surgical tasks is expected to improve the quality of surgery. In this paper, we address two issues that must be resolved for automation of robotic surgery: online trajectory planning and force control under dynamic conditions. By leveraging demonstrations under various conditions, we model the conditional distribution of the trajectories given the task condition. This scheme enables generalization of the trajectories of spatial motion and contact force to new conditions in real time. In addition, we propose a force tracking controller that robustly and stably tracks the planned profile of the contact force by learning the spatial motion and contact force simultaneously. The proposed scheme was tested with bimanual tasks emulating surgical tasks that require online trajectory planning and force tracking control, such as tying knots and cutting soft tissues. Experimental results show that the proposed scheme enables planning of the task trajectory under dynamic conditions in real time. In addition, the performance of the force control schemes was verified in the experiments.},
	number = {2},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Osa, Takayuki and Sugita, Naohiko and Mitsuishi, Mamoru},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Automation Science and Engineering},
	keywords = {automation force control, bimanual tasks, biomechanics, conditional distribution, contact force, dynamic conditions, Force, force control, Force control, force control schemes, force tracking control, force tracking controller, medical robotics, motion planning, online trajectory planning, path planning, planned profile, Planning, position control, robotic surgery, Robots, spatial motion, surgery, Surgery, surgical robot, surgical tasks, task condition, task trajectory, Tracking, Trajectory},
	pages = {675--691},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/EQRXFI2A/7888981.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/NTEDVJCP/Osa et al. - 2018 - Online Trajectory Planning and Force Control for A.pdf:application/pdf}
}

@article{osaGuidingTrajectoryOptimization2017,
	title = {Guiding {Trajectory} {Optimization} by {Demonstrated} {Distributions}},
	volume = {2},
	issn = {2377-3766},
	doi = {10.1109/LRA.2017.2653850},
	abstract = {Trajectory optimization is an essential tool for motion planning under multiple constraints of robotic manipulators. Optimization-based methods can explicitly optimize a trajectory by leveraging prior knowledge of the system and have been used in various applications such as collision avoidance. However, these methods often require a hand-coded cost function in order to achieve the desired behavior. Specifying such cost function for a complex desired behavior, e.g., disentangling a rope, is a nontrivial task that is often even infeasible. Learning from demonstration (LfD) methods offer an alternative way to program robot motion. LfD methods are less dependent on analytical models and instead learn the behavior of experts implicitly from the demonstrated trajectories. However, the problem of adapting the demonstrations to new situations, e.g., avoiding newly introduced obstacles, has not been fully investigated in the literature. In this letter, we present a motion planning framework that combines the advantages of optimization-based and demonstration-based methods. We learn a distribution of trajectories demonstrated by human experts and use it to guide the trajectory optimization process. The resulting trajectory maintains the demonstrated behaviors, which are essential to performing the task successfully, while adapting the trajectory to avoid obstacles. In simulated experiments and with a real robotic system, we verify that our approach optimizes the trajectory to avoid obstacles and encodes the demonstrated behavior in the resulting trajectory.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Osa, Takayuki and Esfahani, Amir M. Ghalamzan and Stolkin, Rustam and Lioutikov, Rudolf and Peters, Jan and Neumann, Gerhard},
	month = apr,
	year = {2017},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {path planning, Planning, Robots, collision avoidance, Collision avoidance, Cost function, hand-coded cost function, learning and adaptive systems, learning from demonstration method, LfD methods, manipulation planning, manipulators, Motion and path planning, motion planning framework, optimisation, optimization-based methods, robotic manipulators, trajectory control, trajectory optimization, Trajectory optimization},
	pages = {819--826},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/2XSUFB6K/7819469.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/DXAQEF7J/Osa et al. - 2017 - Guiding Trajectory Optimization by Demonstrated Di.pdf:application/pdf}
}

@inproceedings{osaOnlineTrajectoryPlanning2014,
	title = {Online {Trajectory} {Planning} in {Dynamic} {Environments} for {Surgical} {Task} {Automation}},
	isbn = {978-0-9923747-0-9},
	url = {http://www.roboticsproceedings.org/rss10/p11.pdf},
	doi = {10.15607/RSS.2014.X.011},
	abstract = {Automation of robotic surgery has the potential to improve the performance of surgeons and the quality of the life of patients. However, the automation of surgical tasks has challenging problems that must be resolved. One such problem is adaptive online trajectory planning based on the state of the surrounding dynamic environment. This study presents a framework for online trajectory planning in a dynamic environment for automatic assistance in robotic surgery. In the proposed system, a demonstration under various states of the environment is used for learning. The distribution of the demonstrated trajectory over the environmental conditions is modeled using a statistical model. The trajectory, under given environmental conditions, is computed as a conditional expectation using the learned model. Because of its low computational cost, the proposed scheme is able to generalize and plan a trajectory online in a dynamic environment. To design the motion of the system to track the planned trajectory in a stable and smooth manner, the concept of a sliding mode control was employed; its stability was proved theoretically. The proposed scheme was implemented on a robotic surgical system and the performance was veriﬁed through experiments and simulations. These experiments and simulations veriﬁed that the developed system successfully planned and updated the trajectories of the learned tasks in response to the changes in the dynamic environment.},
	language = {en},
	urldate = {2020-08-09},
	booktitle = {Robotics: {Science} and {Systems} {X}},
	publisher = {Robotics: Science and Systems Foundation},
	author = {Osa, Takayuki and Sugita, Naohiko and Mitsuishi, Mamoru},
	month = jul,
	year = {2014},
	file = {Osa et al. - 2014 - Online Trajectory Planning in Dynamic Environments.pdf:/home/bryan/Zotero/storage/HAVFB7FL/Osa et al. - 2014 - Online Trajectory Planning in Dynamic Environments.pdf:application/pdf}
}

@article{abbeelAutonomousHelicopterAerobatics2010,
	title = {Autonomous {Helicopter} {Aerobatics} through {Apprenticeship} {Learning}},
	volume = {29},
	issn = {0278-3649, 1741-3176},
	url = {http://journals.sagepub.com/doi/10.1177/0278364910371999},
	doi = {10.1177/0278364910371999},
	abstract = {Autonomous helicopter flight is widely regarded to be a highly challenging control problem. Despite this fact, human experts can reliably fly helicopters through a wide range of maneuvers, including aerobatic maneuvers at the edge of the helicopter’s capabilities. We present apprenticeship learning algorithms, which leverage expert demonstrations to efficiently learn good controllers for tasks being demonstrated by an expert. These apprenticeship learning algorithms have enabled us to significantly extend the state of the art in autonomous helicopter aerobatics. Our experimental results include the first autonomous execution of a wide range of maneuvers, including but not limited to in-place flips, in-place rolls, loops and hurricanes, and even auto-rotation landings, chaos and tic-tocs, which only exceptional human pilots can perform. Our results also include complete airshows, which require autonomous transitions between many of these maneuvers. Our controllers perform as well as, and often even better than, our expert pilot.},
	language = {en},
	number = {13},
	urldate = {2020-08-09},
	journal = {The International Journal of Robotics Research},
	author = {Abbeel, Pieter and Coates, Adam and Ng, Andrew Y.},
	month = nov,
	year = {2010},
	pages = {1608--1639},
	file = {Abbeel et al. - 2010 - Autonomous Helicopter Aerobatics through Apprentic.pdf:/home/bryan/Zotero/storage/MCNETDCN/Abbeel et al. - 2010 - Autonomous Helicopter Aerobatics through Apprentic.pdf:application/pdf}
}

@inproceedings{nairCombiningSelfSupervisedLearning2017,
  title={Combining self-supervised learning and imitation for vision-based rope manipulation},
  author={Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={2146--2153},
  year={2017},
  organization={IEEE}
}

@article{lemmeOpensourceBenchmarkingLearned2015,
	title = {Open-source benchmarking for learned reaching motion generation in robotics},
	volume = {6},
	issn = {2081-4836},
	url = {https://www.degruyter.com/doi/10.1515/pjbr-2015-0002},
	doi = {10.1515/pjbr-2015-0002},
	abstract = {This paper introduces a benchmark framework to evaluate the performance of reaching motion generation approaches that learn from demonstrated examples. The system implements ten different performance measures for typical generalization tasks in robotics using open source MATLAB software. Systematic comparisons are based on a default training data set of human motions, which specify the respective ground truth. In technical terms, an evaluated motion generation method needs to compute velocities, given a state provided by the simulation system. This however is agnostic to how this is done by the method or how the methods learns from the provided demonstrations. The framework focuses on robustness, which is tested statistically by sampling from a set of perturbation scenarios. These perturbations interfere with motion generation and challenge its generalization ability. The benchmark thus helps to identify the strengths and weaknesses of competing approaches, while allowing the user the opportunity to configure the weightings between different measures.},
	language = {en},
	number = {1},
	urldate = {2020-08-05},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Lemme, A. and Meirovitch, Y. and Khansari-Zadeh, M. and Flash, T. and Billard, A. and Steil, J. J.},
	month = jan,
	year = {2015},
	file = {Lemme et al. - 2015 - Open-source benchmarking for learned reaching moti.pdf:/home/bryan/Zotero/storage/HUYLS6Y4/Lemme et al. - 2015 - Open-source benchmarking for learned reaching moti.pdf:application/pdf}
}

@article{silverMasteringGameGo2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	language = {en},
	number = {7587},
	urldate = {2020-08-05},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	month = jan,
	year = {2016},
	pages = {484--489},
	file = {AlphaGo.nature16961.pdf:/home/bryan/Zotero/storage/WYCBNPML/AlphaGo.nature16961.pdf:application/pdf}
}

@inproceedings{changLearningSearchBetter2015,
  title={Learning to search better than your teacher},
  author={Chang, Kai-Wei and Krishnamurthy, Akshay and Agarwal, Alekh and Daume, Hal and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={2058--2066},
  year={2015},
  organization={PMLR}
}

@inproceedings{sunDeeplyAggreVaTeDDifferentiable2017,
  title={Deeply aggrevated: Differentiable imitation learning for sequential prediction},
  author={Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  booktitle={International Conference on Machine Learning},
  pages={3309--3318},
  year={2017},
  organization={PMLR}
}

@article{levineEndtoEndTrainingDeep2016,
	title = {End-to-{End} {Training} of {Deep} {Visuomotor} {Policies}},
	url = {http://arxiv.org/abs/1504.00702},
	abstract = {Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a partially observed guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.},
	urldate = {2020-08-03},
	journal = {arXiv:1504.00702 [cs]},
	author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	month = apr,
	year = {2016},
	note = {arXiv: 1504.00702},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
	annote = {Comment: updating with revisions for JMLR final version},
	file = {arXiv.org Snapshot:/home/bryan/Zotero/storage/5ID5KMQ4/1504.html:text/html;arXiv Fulltext PDF:/home/bryan/Zotero/storage/KXZ6DEUC/Levine et al. - 2016 - End-to-End Training of Deep Visuomotor Policies.pdf:application/pdf}
}

@article{pomerleauEfficientTrainingArtificial1991,
  title={Efficient training of artificial neural networks for autonomous navigation},
  author = {Pomerleau, Dean A.},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={88--97},
  year={1991},
  publisher={MIT Press}
}

@article{osaAlgorithmicPerspectiveImitation2018,
	title = {An {Algorithmic} {Perspective} on {Imitation} {Learning}},
	volume = {7},
	issn = {1935-8253, 1935-8261},
	url = {http://www.nowpublishers.com/article/Details/ROB-053},
	doi = {10.1561/2300000053},
	language = {en},
	number = {1-2},
	urldate = {2020-07-29},
	journal = {FNT in Robotics},
	author = {Osa, Takayuki and Pajarinen, Joni and Neumann, Gerhard and Bagnell, J. Andrew and Abbeel, Pieter and Peters, Jan},
	year = {2018},
	pages = {1--179},
	file = {Osa et al. - 2018 - An Algorithmic Perspective on Imitation Learning.pdf:/home/bryan/Zotero/storage/8BS6VXX4/Osa et al. - 2018 - An Algorithmic Perspective on Imitation Learning.pdf:application/pdf}
}

@inproceedings{zhangDeepImitationLearning2018,
	title = {Deep {Imitation} {Learning} for {Complex} {Manipulation} {Tasks} from {Virtual} {Reality} {Teleoperation}},
	doi = {10.1109/ICRA.2018.8461249},
	abstract = {Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Robots, manipulators, consumer-grade Virtual Reality headsets, control engineering computing, deep imitation learning, deep neural network policies, Grippers, hand tracking hardware, Head, human-robot interaction, learning by example, manipulation tasks, neural nets, Neural networks, PR2 robot, raw pixels, RGB-D images, robot programming, robot skill acquisition, robot vision, Task analysis, telerobotics, Three-dimensional displays, virtual reality, virtual reality teleoperation, Visualization},
	pages = {5628--5635},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/XSGPC2YY/8461249.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/47UQ4MQL/Zhang et al. - 2018 - Deep Imitation Learning for Complex Manipulation T.pdf:application/pdf}
}

@incollection{liInfoGAILInterpretableImitation2017,
	title = {{InfoGAIL}: {Interpretable} {Imitation} {Learning} from {Visual} {Demonstrations}},
	shorttitle = {{InfoGAIL}},
	url = {http://papers.nips.cc/paper/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations.pdf},
	urldate = {2020-07-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {3812--3822},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/JMGCVQ3P/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/P7SS75X3/Li et al. - 2017 - InfoGAIL Interpretable Imitation Learning from Vi.pdf:application/pdf}
}

@inproceedings{codevillaEndtoEndDrivingConditional2018,
	title = {End-to-{End} {Driving} {Via} {Conditional} {Imitation} {Learning}},
	doi = {10.1109/ICRA.2018.8460487},
	abstract = {Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Codevilla, Felipe and Müller, Matthias and López, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {collision avoidance, Task analysis, Cameras, condition imitation, conditional imitation learning, deep networks, driving policies, driving policy functions, high-level command input, high-level navigational commands, learning systems, mobile robots, Navigation, road traffic control, Roads, Robot sensing systems, robotic truck, sensorimotor coordination, urban driving, Vehicles, vision-based driving},
	pages = {4693--4700},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/GVJ87TQQ/8460487.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/VECZ8YXM/Codevilla et al. - 2018 - End-to-End Driving Via Conditional Imitation Learn.pdf:application/pdf}
}

@incollection{duanOneShotImitationLearning2017,
	title = {One-{Shot} {Imitation} {Learning}},
	url = {http://papers.nips.cc/paper/6709-one-shot-imitation-learning.pdf},
	urldate = {2020-07-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Jonathan Ho, OpenAI and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {1087--1098},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/SN2IS8F8/6709-one-shot-imitation-learning.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/Z9CNK9J7/Duan et al. - 2017 - One-Shot Imitation Learning.pdf:application/pdf}
}

@incollection{hoGenerativeAdversarialImitation2016,
	title = {Generative {Adversarial} {Imitation} {Learning}},
	url = {http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning.pdf},
	urldate = {2020-07-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Ho, Jonathan and Ermon, Stefano},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {4565--4573},
	file = {NIPS Snapshot:/home/bryan/Zotero/storage/FH4C77FM/6391-generative-adversarial-imitation-learning.html:text/html;NIPS Full Text PDF:/home/bryan/Zotero/storage/F5VMKRXM/Ho and Ermon - 2016 - Generative Adversarial Imitation Learning.pdf:application/pdf}
}

@inproceedings{rossReductionImitationLearning2011,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{judahActiveImitationLearning2012,
	title = {Active {Imitation} {Learning} via {Reduction} to {I}.{I}.{D}. {Active} {Learning}},
	abstract = {In standard passive imitation learning, the goal is to learn an expert’s policy by passively observing full execution trajectories of it. Unfortunately, generating such trajectories can require substantial expert effort and be impractical in some cases. In this paper, we consider Active Imitation Learning (AIL) with the goal of reducing this effort by querying the expert about the desired action at individual states, which are selected based on answers to past queries and the learner’s interactions with an environment simulator. Our new approach is based on reducing AIL to i.i.d. active learning, which can leverage progress in the i.i.d. setting. We introduce and analyze reductions for both non-stationary and stationary policies, showing that the label complexity (number of queries) of AIL can be substantially less than passive learning. We also introduce a practical algorithm inspired by the reductions, which is shown to be highly effective in four test domains compared to a number of alternatives.},
	language = {en},
	author = {Judah, Kshitij and Fern, Alan and Dietterich, Tom},
	month = jul,
	year = {2012},
	pages = {9},
	file = {Judah et al. - Active Imitation Learning via Reduction to I.I.D. .pdf:/home/bryan/Zotero/storage/QTF2N9I4/Judah et al. - Active Imitation Learning via Reduction to I.I.D. .pdf:application/pdf}
}

@inproceedings{kimMaximumMeanDiscrepancy2013,
	title = {Maximum {Mean} {Discrepancy} {Imitation} {Learning}},
	isbn = {978-981-07-3937-9},
	url = {http://www.roboticsproceedings.org/rss09/p38.pdf},
	doi = {10.15607/RSS.2013.IX.038},
	abstract = {Imitation learning is an efﬁcient method for many robots to acquire complex skills. Some recent approaches to imitation learning provide strong theoretical performance guarantees. However, there remain crucial practical issues, especially during the training phase, where the training strategy may require execution of control policies that are possibly harmful to the robot or its environment. Moreover, these algorithms often require more demonstrations than necessary to achieve good performance in practice. This paper introduces a new approach called Maximum-Mean-Discrepancy imitation learning that uses fewer demonstrations and safer exploration policy than existing methods, while preserving strong theoretical guarantees on performance. We demonstrate empirical performance of this method for effective navigation control of a social robot in a populated environment, where safety and efﬁciency during learning are primary considerations.},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {Robotics: {Science} and {Systems} {IX}},
	publisher = {Robotics: Science and Systems Foundation},
	author = {Kim, Beomjoon and Pineau, Joelle},
	month = jun,
	year = {2013},
	file = {Kim and Pineau - 2013 - Maximum Mean Discrepancy Imitation Learning.pdf:/home/bryan/Zotero/storage/V3Z62RL3/Kim and Pineau - 2013 - Maximum Mean Discrepancy Imitation Learning.pdf:application/pdf}
}

@article{daumeiiiSearchbasedStructuredPrediction2009a,
  title={Search-based structured prediction},
  author={Daum{\'e}, Hal and Langford, John and Marcu, Daniel},
  journal={Machine learning},
  volume={75},
  number={3},
  pages={297--325},
  year={2009},
  publisher={Springer}
}

@article{ingimundardottirDiscoveringDispatchingRules2018,
	title = {Discovering dispatching rules from data using imitation learning: {A} case study for the job-shop problem},
	volume = {21},
	issn = {1099-1425},
	url = {https://doi.org/10.1007/s10951-017-0534-0},
	doi = {10.1007/s10951-017-0534-0},
	abstract = {Dispatching rules can be automatically generated from scheduling data. This paper will demonstrate that the key to learning an effective dispatching rule is through the careful construction of the training data, \$\${\textbackslash}\{{\textbackslash}mathbf \{x\}\_i(k),y\_i(k){\textbackslash}\}\_\{k=1\}{\textasciicircum}K{\textbackslash}in \{{\textbackslash}mathscr \{D\}\}\$\$\{xi(k),yi(k)\}k=1K∈D, where (i) features of partially constructed schedules \$\${\textbackslash}mathbf \{x\}\_i\$\$xishould necessarily reflect the induced data distribution \$\$\{{\textbackslash}mathscr \{D\}\}\$\$Dfor when the rule is applied. This is achieved by updating the learned model in an active imitation learning fashion; (ii) \$\$y\_i\$\$yiis labelled optimally using a MIP solver; and (iii) data need to be balanced, as the set is unbalanced with respect to the dispatching step k. Using the guidelines set by our framework the design of custom dispatching rules, for a particular scheduling application, will become more effective. In the study presented three different distributions of the job-shop will be considered. The machine learning approach considered is based on preference learning, i.e. which dispatch (post-decision state) is preferable to another.},
	number = {4},
	journal = {Journal of Scheduling},
	author = {Ingimundardottir, Helga and Runarsson, Thomas Philip},
	month = aug,
	year = {2018},
	pages = {413--428},
	file = {Discovering dispatching rules from data using imit.pdf:/home/bryan/Zotero/storage/HU5FQ6VR/Discovering dispatching rules from data using imit.pdf:application/pdf}
}

@article{rossReinforcementImitationLearning2014,
  title={Reinforcement and imitation learning via interactive no-regret learning},
  author={Ross, Stephane and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:1406.5979},
  year={2014}
}

@article{sartorHiLITEHierarchicalLightweight2020,
	title = {{HiLITE}: {Hierarchical} and {Lightweight} {Imitation} {Learning} for {Power} {Management} of {Embedded} {SoCs}},
	volume = {19},
	issn = {1556-6064},
	shorttitle = {{HiLITE}},
	doi = {10.1109/LCA.2020.2992182},
	abstract = {Modern systems-on-chip (SoCs) use dynamic power management (DPM) techniques to improve energy efficiency. However, existing techniques are unable to efficiently adapt the runtime decisions considering multiple objectives (e.g., energy and real-time requirements) simultaneously on heterogeneous platforms. To address this need, we propose HiLITE, a hierarchical imitation learning framework that maximizes the energy efficiency while satisfying soft real-time constraints on embedded SoCs. Our approach first trains DPM policies using imitation learning; then, it applies a regression policy at runtime to minimize deadline misses. HiLITE improves the energy-delay product by 40 percent on average, and reduces deadline misses by up to 76 percent, compared to state-of-the-art approaches. In addition, we show that the trained policies not only achieve high accuracy, but also have negligible prediction time overhead and small memory footprint.},
	number = {1},
	journal = {IEEE Computer Architecture Letters},
	author = {Sartor, Anderson L. and Krishnakumar, Anish and Arda, Samet E. and Ogras, Umit Y. and Marculescu, Radu},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Computer Architecture Letters},
	keywords = {DPM policies, dynamic power management, dynamic power management techniques, embedded SoCs, embedded systems, energy conservation, energy efficiency, energy-delay product, heterogeneous platforms, Hierarchical imitation learning, hierarchical imitation learning framework, HiLITE, learning (artificial intelligence), machine learning, power aware computing, prediction time overhead, real-time, real-time constraints, regression analysis, regression policy, SoC, system-on-chip, systems-on-chip},
	pages = {63--67},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/ZZC98MSF/9085952.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/5PYPIT4X/Sartor et al. - 2020 - HiLITE Hierarchical and Lightweight Imitation Lea.pdf:application/pdf}
}

@article{zuoDeterministicGenerativeAdversarial2020,
	title = {Deterministic generative adversarial imitation learning},
	volume = {388},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231220300436},
	doi = {10.1016/j.neucom.2020.01.016},
	abstract = {This paper proposes a deterministic generative adversarial imitation learning method which allows the robot to implement the motion planning task rapidly by learning from the demonstration data without reward function. In our method, the deep deterministic policy gradient method is used as the generator for learning the action policy on the basis of discriminator, and the demonstration data is input into the generator to ensure its stability. Three experiments on the push and pick-and-place tasks are conducted in the gym robotic environment. Results show that the learning speed of our method is much faster than the stochastic generative adversarial imitation learning method, and it can effectively learn from the demonstration data in different states of the task with higher learning stability. The proposed method can complete the motion planning task without environmental reward quickly and improve the stability of the training process.},
	language = {en},
	urldate = {2020-07-09},
	journal = {Neurocomputing},
	author = {Zuo, Guoyu and Chen, Kexin and Lu, Jiahao and Huang, Xiangsheng},
	month = may,
	year = {2020},
	pages = {60--69},
	file = {Zuo et al. - 2020 - Deterministic generative adversarial imitation lea.pdf:/home/bryan/Zotero/storage/PBYHGCYC/Zuo et al. - 2020 - Deterministic generative adversarial imitation lea.pdf:application/pdf}
}

@article{kinoseIntegrationImitationLearning2020,
	title = {Integration of imitation learning using {GAIL} and reinforcement learning using task-achievement rewards via probabilistic graphical model},
	issn = {0169-1864, 1568-5535},
	url = {https://www.tandfonline.com/doi/full/10.1080/01691864.2020.1778521},
	doi = {10.1080/01691864.2020.1778521},
	abstract = {The integration of reinforcement learning (RL) and imitation learning (IL) is an important problem that has long been studied in the field of intelligent robotics. RL optimizes policies to maximize the cumulative reward, whereas IL attempts to extract general knowledge about the trajectories demonstrated by experts, i.e, demonstrators. Because each has its own drawbacks, many methods combining them and compensating for each set of drawbacks have been explored thus far. However, many of these methods are heuristic and do not have a solid theoretical basis. This paper presents a new theory for integrating RL and IL by extending the probabilistic graphical model (PGM) framework for RL, control as inference. We develop a new PGM for RL with multiple types of rewards, called probabilistic graphical model for Markov decision processes with multiple optimality emissions (pMDP-MO). Furthermore, we demonstrate that the integrated learning method of RL and IL can be formulated as a probabilistic inference of policies on pMDP-MO by considering the discriminator in generative adversarial imitation learning (GAIL) as an additional optimality emission. We adapt the GAIL and task-achievement reward to our proposed framework, achieving significantly better performance than policies trained with baseline methods.},
	language = {en},
	urldate = {2020-07-08},
	journal = {Advanced Robotics},
	author = {Kinose, Akira and Taniguchi, Tadahiro},
	month = jun,
	year = {2020},
	pages = {1--13},
	file = {Kinose and Taniguchi - 2020 - Integration of imitation learning using GAIL and r.pdf:/home/bryan/Zotero/storage/BX8LFEJT/Kinose and Taniguchi - 2020 - Integration of imitation learning using GAIL and r.pdf:application/pdf}
}

@article{shouOptimalPassengerseekingPolicies2020,
	title = {Optimal passenger-seeking policies on {E}-hailing platforms using {Markov} decision process and imitation learning},
	volume = {111},
	issn = {0968090X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0968090X18316577},
	doi = {10.1016/j.trc.2019.12.005},
	abstract = {Vacant taxi drivers’ passenger seeking process in a road network generates additional vehicle miles traveled, adding congestion and pollution into the road network and the environment. This paper aims to employ a Markov Decision Process (MDP) to model idle e-hailing drivers’ optimal sequential decisions in passenger-seeking. Transportation network companies (TNC) or e-hailing (e.g., Didi, Uber) drivers exhibit different behaviors from traditional taxi drivers because ehailing drivers do not need to actually search for passengers. Instead, they reposition themselves so that the matching platform can match a passenger. Accordingly, we incorporate e-hailing drivers’ new features into our MDP model. The reward function used in the MDP model is uncovered by leveraging an inverse reinforcement learning technique. We then use 44,160 Didi drivers’ 3-day trajectories to train the model. To validate the effectiveness of the model, a Monte Carlo simulation is conducted to simulate the performance of drivers under the guidance of the optimal policy, which is then compared with the performance of drivers following one baseline heuristic, namely, the local hotspot strategy. The results show that our model is able to achieve a 17.5\% improvement over the local hotspot strategy in terms of the rate of return. The proposed MDP model captures the supply-demand ratio considering the fact that the number of drivers in this study is sufficiently large and thus the number of unmatched orders is assumed to be negligible. To better incorporate the competition among multiple drivers into the model, we have also devised and calibrated a dynamic adjustment strategy of the order matching probability.},
	language = {en},
	urldate = {2020-07-08},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {Shou, Zhenyu and Di, Xuan and Ye, Jieping and Zhu, Hongtu and Zhang, Hua and Hampshire, Robert},
	month = feb,
	year = {2020},
	pages = {91--113},
	file = {Shou et al. - 2020 - Optimal passenger-seeking policies on E-hailing pl.pdf:/home/bryan/Zotero/storage/W4CMFFJL/Shou et al. - 2020 - Optimal passenger-seeking policies on E-hailing pl.pdf:application/pdf}
}

@inproceedings{rossEfficientReductionsImitation2010,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{choudhuryDatadrivenPlanningImitation2018,
	title = {Data-driven planning via imitation learning},
	volume = {37},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364918781001},
	doi = {10.1177/0278364918781001},
	abstract = {Robot planning is the process of selecting a sequence of actions that optimize for a task=specific objective. For instance, the objective for a navigation task would be to find collision-free paths, whereas the objective for an exploration task would be to map unknown areas. The optimal solutions to such tasks are heavily influenced by the implicit structure in the environment, i.e. the configuration of objects in the world. State-of-the-art planning approaches, however, do not exploit this structure, thereby expending valuable effort searching the action space instead of focusing on potentially good actions. In this paper, we address the problem of enabling planners to adapt their search strategies by inferring such good actions in an efficient manner using only the information uncovered by the search up until that time. We formulate this as a problem of sequential decision making under uncertainty where at a given iteration a planning policy must map the state of the search to a planning action. Unfortunately, the training process for such partial-information-based policies is slow to converge and susceptible to poor local minima. Our key insight is that if we could fully observe the underlying world map, we would easily be able to disambiguate between good and bad actions. We hence present a novel data-driven imitation learning framework to efficiently train planning policies by imitating a clairvoyant oracle: an oracle that at train time has full knowledge about the world map and can compute optimal decisions. We leverage the fact that for planning problems, such oracles can be efficiently computed and derive performance guarantees for the learnt policy. We examine two important domains that rely on partial-information-based policies: informative path planning and search-based motion planning. We validate the approach on a spectrum of environments for both problem domains, including experiments on a real UAV, and show that the learnt policy consistently outperforms state-of-the-art algorithms. Our framework is able to train policies that achieve up to 39\% more reward than state-of-the art information-gathering heuristics and a 70? speedup as compared with A* on search-based planning problems. Our approach paves the way forward for applying data-driven techniques to other such problem domains under the umbrella of robot planning.},
	number = {13-14},
	urldate = {2020-07-02},
	journal = {The International Journal of Robotics Research},
	author = {Choudhury, Sanjiban and Bhardwaj, Mohak and Arora, Sankalp and Kapoor, Ashish and Ranade, Gireeja and Scherer, Sebastian and Dey, Debadeepta},
	month = dec,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {1632--1672},
	file = {SAGE PDF Full Text:/home/bryan/Zotero/storage/EADWS2IE/Choudhury et al. - 2018 - Data-driven planning via imitation learning.pdf:application/pdf}
}

@article{husseinDeepImitationLearning2018,
	title = {Deep imitation learning for {3D} navigation tasks},
	volume = {29},
	issn = {0941-0643, 1433-3058},
	url = {http://link.springer.com/10.1007/s00521-017-3241-z},
	doi = {10.1007/s00521-017-3241-z},
	language = {en},
	number = {7},
	urldate = {2020-07-04},
	journal = {Neural Comput \& Applic},
	author = {Hussein, Ahmed and Elyan, Eyad and Gaber, Mohamed Medhat and Jayne, Chrisina},
	month = apr,
	year = {2018},
	pages = {389--404},
	file = {Hussein et al. - 2018 - Deep imitation learning for 3D navigation tasks.pdf:/home/bryan/Zotero/storage/SLX2P7Y8/Hussein et al. - 2018 - Deep imitation learning for 3D navigation tasks.pdf:application/pdf}
}

@article{husseinImitationLearningSurvey2017,
	title = {Imitation {Learning}: {A} {Survey} of {Learning} {Methods}},
	volume = {50},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Imitation {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3054912},
	doi = {10.1145/3054912},
	language = {en},
	number = {2},
	urldate = {2020-07-02},
	journal = {ACM Comput. Surv.},
	author = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
	month = jun,
	year = {2017},
	pages = {1--35},
	file = {Hussein et al. - 2017 - Imitation Learning A Survey of Learning Methods.pdf:/home/bryan/Zotero/storage/RNJ9FJQI/Hussein et al. - 2017 - Imitation Learning A Survey of Learning Methods.pdf:application/pdf}
}

@article{hesterDeepQlearningDemonstrations2017,
	title = {Deep {Q}-learning from {Demonstrations}},
	url = {http://arxiv.org/abs/1704.03732},
	abstract = {Deep reinforcement learning (RL) has achieved several high profile successes in difficult decision-making problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages small sets of demonstration data to massively accelerate the learning process even from relatively small amounts of demonstration data and is able to automatically assess the necessary ratio of demonstration data while learning thanks to a prioritized replay mechanism. DQfD works by combining temporal difference updates with supervised classification of the demonstrator's actions. We show that DQfD has better initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN) as it starts with better scores on the first million steps on 41 of 42 games and on average it takes PDD DQN 83 million steps to catch up to DQfD's performance. DQfD learns to out-perform the best demonstration given in 14 of 42 games. In addition, DQfD leverages human demonstrations to achieve state-of-the-art results for 11 games. Finally, we show that DQfD performs better than three related algorithms for incorporating demonstration data into DQN.},
	urldate = {2020-09-04},
	journal = {arXiv:1704.03732 [cs]},
	author = {Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and Leibo, Joel Z. and Gruslys, Audrunas},
	month = nov,
	year = {2017},
	note = {arXiv: 1704.03732},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: Published at AAAI 2018. Previously on arxiv as "Learning from Demonstrations for Real World Reinforcement Learning"},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/H3VUBLT8/Hester 等。 - 2017 - Deep Q-learning from Demonstrations.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/SAN7KS3G/1704.html:text/html}
}

@inproceedings{sermanetTimeContrastiveNetworksSelfSupervised2018,
  title={Time-contrastive networks: Self-supervised learning from video},
  author={Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1134--1141},
  year={2018},
  organization={IEEE}
}

@inproceedings{schulmanTrustRegionPolicy2017,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@inproceedings{edwardsImitatingLatentPolicies2019,
  title={Imitating latent policies from observation},
  author={Edwards, Ashley and Sahni, Himanshu and Schroecker, Yannick and Isbell, Charles},
  booktitle={International Conference on Machine Learning},
  pages={1755--1763},
  year={2019},
  organization={PMLR}
}

@inproceedings{sunProvablyEfficientImitation2019,
  title={Provably efficient imitation learning from observation alone},
  author={Sun, Wen and Vemula, Anirudh and Boots, Byron and Bagnell, Drew},
  booktitle={International Conference on Machine Learning},
  pages={6036--6045},
  year={2019},
  organization={PMLR}
}

@article{torabiImitationLearningVideo2019,
	title = {Imitation {Learning} from {Video} by {Leveraging} {Proprioception}},
	url = {http://arxiv.org/abs/1905.09335},
	abstract = {Classically, imitation learning algorithms have been developed for idealized situations, e.g., the demonstrations are often required to be collected in the exact same environment and usually include the demonstrator's actions. Recently, however, the research community has begun to address some of these shortcomings by offering algorithmic solutions that enable imitation learning from observation (IfO), e.g., learning to perform a task from visual demonstrations that may be in a different environment and do not include actions. Motivated by the fact that agents often also have access to their own internal states (i.e., proprioception), we propose and study an IfO algorithm that leverages this information in the policy learning process. The proposed architecture learns policies over proprioceptive state representations and compares the resulting trajectories visually to the demonstration data. We experimentally test the proposed technique on several MuJoCo domains and show that it outperforms other imitation from observation algorithms by a large margin.},
	urldate = {2020-09-13},
	journal = {arXiv:1905.09335 [cs, stat]},
	author = {Torabi, Faraz and Warnell, Garrett and Stone, Peter},
	month = jun,
	year = {2019},
	note = {arXiv: 1905.09335},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: International Joint Conference on Artificial Intelligence (IJCAI 2019)},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/EXMQ2EZM/Torabi 等。 - 2019 - Imitation Learning from Video by Leveraging Propri.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/4KGZA9FE/1905.html:text/html}
}

@article{bhattacharyyaMultiAgentImitationLearning2018,
	title = {Multi-{Agent} {Imitation} {Learning} for {Driving} {Simulation}},
	url = {http://arxiv.org/abs/1803.01044},
	abstract = {Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.},
	urldate = {2020-09-13},
	journal = {arXiv:1803.01044 [cs]},
	author = {Bhattacharyya, Raunak P. and Phillips, Derek J. and Wulfe, Blake and Morton, Jeremy and Kuefler, Alex and Kochenderfer, Mykel J.},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.01044},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 6 pages, 3 figures, 1 table},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/W5VHWN6U/Bhattacharyya 等。 - 2018 - Multi-Agent Imitation Learning for Driving Simulat.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/CNUKRJPG/1803.html:text/html}
}

@article{zhanGeneratingMultiAgentTrajectories2019,
  title={Generating multi-agent trajectories using programmatic weak supervision},
  author={Zhan, Eric and Zheng, Stephan and Yue, Yisong and Sha, Long and Lucey, Patrick},
  journal={arXiv preprint arXiv:1803.07612},
  year={2018}
}

@article{salimansLearningMontezumaRevenge2018,
  title={Learning Montezuma's Revenge from a Single Demonstration},
  author={Salimans, Tim and Chen, Richard},
  journal={arXiv preprint arXiv:1812.03381},
  year={2018}
}

@inproceedings{nairOvercomingExplorationReinforcement2018,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@inproceedings{ohSelfImitationLearning2018,
  title={Self-imitation learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={3878--3887},
  year={2018},
  organization={PMLR}
}

@article{torabiGenerativeAdversarialImitation2019,
  title={Generative adversarial imitation from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1807.06158},
  year={2018}
}

@incollection{bagnellBoostingStructuredPrediction2007,
	title = {Boosting {Structured} {Prediction} for {Imitation} {Learning}},
	url = {http://papers.nips.cc/paper/3154-boosting-structured-prediction-for-imitation-learning.pdf},
	urldate = {2020-09-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 19},
	publisher = {MIT Press},
	author = {Bagnell, J. A. and Chestnutt, Joel and Bradley, David M. and Ratliff, Nathan D.},
	editor = {Schölkopf, B. and Platt, J. C. and Hoffman, T.},
	year = {2007},
	pages = {1153--1160},
	file = {NIPS Full Text PDF:/home/bryan/Zotero/storage/CQF3GPJ6/Bagnell 等。 - 2007 - Boosting Structured Prediction for Imitation Learn.pdf:application/pdf;NIPS Snapshot:/home/bryan/Zotero/storage/7YJF4CIW/3154-boosting-structured-prediction-for-imitation-learning.html:text/html}
}

@article{dingGoalconditionedImitationLearning2019,
  title={Goal-conditioned imitation learning},
  author={Ding, Yiming and Florensa, Carlos and Phielipp, Mariano and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1906.05838},
  year={2019}
}

@inproceedings{yu2020intrinsic,
  title={Intrinsic reward driven imitation learning via generative model},
  author={Yu, Xingrui and Lyu, Yueming and Tsang, Ivor},
  booktitle={International Conference on Machine Learning},
  pages={10925--10935},
  year={2020},
  organization={PMLR}
}

@article{palanLearningRewardFunctions2019,
	title = {Learning {Reward} {Functions} by {Integrating} {Human} {Demonstrations} and {Preferences}},
	url = {http://arxiv.org/abs/1906.08928},
	abstract = {Our goal is to accurately and efficiently learn reward functions for autonomous robots. Current approaches to this problem include inverse reinforcement learning (IRL), which uses expert demonstrations, and preference-based learning, which iteratively queries the user for her preferences between trajectories. In robotics however, IRL often struggles because it is difficult to get high-quality demonstrations; conversely, preference-based learning is very inefficient since it attempts to learn a continuous, high-dimensional function from binary feedback. We propose a new framework for reward learning, DemPref, that uses both demonstrations and preference queries to learn a reward function. Specifically, we (1) use the demonstrations to learn a coarse prior over the space of reward functions, to reduce the effective size of the space from which queries are generated; and (2) use the demonstrations to ground the (active) query generation process, to improve the quality of the generated queries. Our method alleviates the efficiency issues faced by standard preference-based learning methods and does not exclusively depend on (possibly low-quality) demonstrations. In numerical experiments, we find that DemPref is significantly more efficient than a standard active preference-based learning method. In a user study, we compare our method to a standard IRL method; we find that users rated the robot trained with DemPref as being more successful at learning their desired behavior, and preferred to use the DemPref system (over IRL) to train the robot.},
	urldate = {2020-09-26},
	journal = {arXiv:1906.08928 [cs]},
	author = {Palan, Malayandi and Landolfi, Nicholas C. and Shevchuk, Gleb and Sadigh, Dorsa},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.08928},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
	annote = {Comment: Presented at RSS 2019},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/IMQ2QEH4/Palan 等。 - 2019 - Learning Reward Functions by Integrating Human Dem.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/6ESWG7LI/1906.html:text/html}
}

@incollection{dehaanCausalConfusionImitation2019,
	title = {Causal {Confusion} in {Imitation} {Learning}},
	url = {http://papers.nips.cc/paper/9343-causal-confusion-in-imitation-learning.pdf},
	urldate = {2020-09-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {de Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {11698--11709},
	file = {NIPS Full Text PDF:/home/bryan/Zotero/storage/9EAPKNJH/de Haan 等。 - 2019 - Causal Confusion in Imitation Learning.pdf:application/pdf;NIPS Snapshot:/home/bryan/Zotero/storage/N4KSPMYU/9343-causal-confusion-in-imitation-learning.html:text/html}
}

@article{reddySQILImitationLearning2019,
	title = {{SQIL}: {Imitation} {Learning} via {Reinforcement} {Learning} with {Sparse} {Rewards}},
	shorttitle = {{SQIL}},
	url = {http://arxiv.org/abs/1905.11108},
	abstract = {Learning to imitate expert behavior from demonstrations can be challenging, especially in environments with high-dimensional, continuous observations and unknown dynamics. Supervised learning methods based on behavioral cloning (BC) suffer from distribution shift: because the agent greedily imitates demonstrated actions, it can drift away from demonstrated states due to error accumulation. Recent methods based on reinforcement learning (RL), such as inverse RL and generative adversarial imitation learning (GAIL), overcome this issue by training an RL agent to match the demonstrations over a long horizon. Since the true reward function for the task is unknown, these methods learn a reward function from the demonstrations, often using complex and brittle approximation techniques that involve adversarial training. We propose a simple alternative that still uses RL, but does not require learning a reward function. The key idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. We accomplish this by giving the agent a constant reward of r=+1 for matching the demonstrated action in a demonstrated state, and a constant reward of r=0 for all other behavior. Our method, which we call soft Q imitation learning (SQIL), can be implemented with a handful of minor modifications to any standard Q-learning or off-policy actor-critic algorithm. Theoretically, we show that SQIL can be interpreted as a regularized variant of BC that uses a sparsity prior to encourage long-horizon imitation. Empirically, we show that SQIL outperforms BC and achieves competitive results compared to GAIL, on a variety of image-based and low-dimensional tasks in Box2D, Atari, and MuJoCo.},
	urldate = {2020-09-26},
	journal = {arXiv:1905.11108 [cs, stat]},
	author = {Reddy, Siddharth and Dragan, Anca D. and Levine, Sergey},
	month = sep,
	year = {2019},
	note = {arXiv: 1905.11108},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/A7VSRW9X/Reddy 等。 - 2019 - SQIL Imitation Learning via Reinforcement Learnin.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/9XCGP4HJ/1905.html:text/html}
}

@inproceedings{brownExtrapolatingSuboptimalDemonstrations2019,
  title={Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations},
  author={Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  booktitle={International Conference on Machine Learning},
  pages={783--792},
  year={2019},
  organization={PMLR}
}

@article{arumugamDeepReinforcementLearning2019,
  title={Deep reinforcement learning from policy-dependent human feedback},
  author={Arumugam, Dilip and Lee, Jun Ki and Saskin, Sophie and Littman, Michael L},
  journal={arXiv preprint arXiv:1902.04257},
  year={2019}
}

@article{ghasemipourDivergenceMinimizationPerspective2019,
	title = {A {Divergence} {Minimization} {Perspective} on {Imitation} {Learning} {Methods}},
	url = {http://arxiv.org/abs/1911.02256},
	abstract = {In many settings, it is desirable to learn decision-making and control policies through learning or bootstrapping from expert demonstrations. The most common approaches under this Imitation Learning (IL) framework are Behavioural Cloning (BC), and Inverse Reinforcement Learning (IRL). Recent methods for IRL have demonstrated the capacity to learn effective policies with access to a very limited set of demonstrations, a scenario in which BC methods often fail. Unfortunately, due to multiple factors of variation, directly comparing these methods does not provide adequate intuition for understanding this difference in performance. In this work, we present a unified probabilistic perspective on IL algorithms based on divergence minimization. We present \$f\$-MAX, an \$f\$-divergence generalization of AIRL [Fu et al., 2018], a state-of-the-art IRL method. \$f\$-MAX enables us to relate prior IRL methods such as GAIL [Ho \& Ermon, 2016] and AIRL [Fu et al., 2018], and understand their algorithmic properties. Through the lens of divergence minimization we tease apart the differences between BC and successful IRL approaches, and empirically evaluate these nuances on simulated high-dimensional continuous control domains. Our findings conclusively identify that IRL's state-marginal matching objective contributes most to its superior performance. Lastly, we apply our new understanding of IL methods to the problem of state-marginal matching, where we demonstrate that in simulated arm pushing environments we can teach agents a diverse range of behaviours using simply hand-specified state distributions and no reward functions or expert demonstrations. For datasets and reproducing results please refer to https://github.com/KamyarGh/rl\_swiss/blob/master/reproducing/fmax\_paper.md .},
	urldate = {2020-09-27},
	journal = {arXiv:1911.02256 [cs, stat]},
	author = {Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.02256},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published at Conference on Robot Learning (CoRL) 2019. For datasets and reproducing results please refer to https://github.com/KamyarGh/rl\_swiss/blob/master/reproducing/fmax\_paper.md},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/Z9USQPAW/Ghasemipour 等。 - 2019 - A Divergence Minimization Perspective on Imitation.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/M43GASMP/1911.html:text/html}
}

@inproceedings{lynchLearningLatentPlans2019,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle={Conference on Robot Learning},
  pages={1113--1132},
  year={2020},
  organization={PMLR}
}

@inproceedings{chenLearningCheating2019,
  title={Learning by cheating},
  author={Chen, Dian and Zhou, Brady and Koltun, Vladlen and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={Conference on Robot Learning},
  pages={66--75},
  year={2020},
  organization={PMLR}
}

@article{georgeImitationLearningEnd2018,
	title = {Imitation {Learning} for {End} to {End} {Vehicle} {Longitudinal} {Control} with {Forward} {Camera}},
	url = {http://arxiv.org/abs/1812.05841},
	abstract = {In this paper we present a complete study of an end-to-end imitation learning system for speed control of a real car, based on a neural network with a Long Short Term Memory (LSTM). To achieve robustness and generalization from expert demonstrations, we propose data augmentation and label augmentation that are relevant for imitation learning in longitudinal control context. Based on front camera image only, our system is able to correctly control the speed of a car in simulation environment, and in a real car on a challenging test track. The system also shows promising results in open road context.},
	urldate = {2020-10-06},
	journal = {arXiv:1812.05841 [cs]},
	author = {George, Laurent and Buhet, Thibault and Wirbel, Emilie and Le-Gall, Gaetan and Perrotton, Xavier},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.05841},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	annote = {Comment: NeurIps 2018 Imitation Learning Workshop},
	file = {arXiv.org Snapshot:/home/bryan/Zotero/storage/24TDGQKQ/1812.html:text/html;arXiv Fulltext PDF:/home/bryan/Zotero/storage/6TTJBNY5/George et al. - 2018 - Imitation Learning for End to End Vehicle Longitud.pdf:application/pdf}
}

@article{zhouModelingCarFollowingBehaviors2020,
	title = {Modeling {Car}-{Following} {Behaviors} and {Driving} {Styles} with {Generative} {Adversarial} {Imitation} {Learning}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/18/5034},
	doi = {10.3390/s20185034},
	abstract = {Building a human-like car-following model that can accurately simulate drivers’ car-following behaviors is helpful to the development of driving assistance systems and autonomous driving. Recent studies have shown the advantages of applying reinforcement learning methods in car-following modeling. However, a problem has remained where it is diﬃcult to manually determine the reward function. This paper proposes a novel car-following model based on generative adversarial imitation learning. The proposed model can learn the strategy from drivers’ demonstrations without specifying the reward. Gated recurrent units was incorporated in the actor-critic network to enable the model to use historical information. Drivers’ car-following data collected by a test vehicle equipped with a millimeter-wave radar and controller area network acquisition card was used. The participants were divided into two driving styles by K-means with time-headway and time-headway when braking used as input features. Adopting ﬁve-fold cross-validation for model evaluation, the results show that the proposed model can reproduce drivers’ car-following trajectories and driving styles more accurately than the intelligent driver model and the recurrent neural network-based model, with the lowest average spacing error (19.40\%) and speed validation error (5.57\%), as well as the lowest Kullback-Leibler divergences of the two indicators used for driving style clustering.},
	language = {en},
	number = {18},
	urldate = {2020-10-06},
	journal = {Sensors},
	author = {Zhou, Yang and Fu, Rui and Wang, Chang and Zhang, Ruibin},
	month = sep,
	year = {2020},
	pages = {5034},
	file = {Zhou et al. - 2020 - Modeling Car-Following Behaviors and Driving Style.pdf:/home/bryan/Zotero/storage/7CFHBSCK/Zhou et al. - 2020 - Modeling Car-Following Behaviors and Driving Style.pdf:application/pdf}
}

@article{kebriaDeepImitationLearning2020,
	title = {Deep imitation learning for autonomous vehicles based on convolutional neural networks},
	volume = {7},
	issn = {2329-9274},
	doi = {10.1109/JAS.2019.1911825},
	abstract = {Providing autonomous systems with an effective quantity and quality of information from a desired task is challenging. In particular, autonomous vehicles, must have a reliable vision of their workspace to robustly accomplish driving functions. Speaking of machine vision, deep learning techniques, and specifically convolutional neural networks, have been proven to be the state of the art technology in the field. As these networks typically involve millions of parameters and elements, designing an optimal architecture for deep learning structures is a difficult task which is globally under investigation by researchers. This study experimentally evaluates the impact of three major architectural properties of convolutional networks, including the number of layers, filters, and filter size on their performance. In this study, several models with different properties are developed, equally trained, and then applied to an autonomous car in a realistic simulation environment. A new ensemble approach is also proposed to calculate and update weights for the models regarding their mean squared error values. Based on design properties, performance results are reported and compared for further investigations. Surprisingly, the number of filters itself does not largely affect the performance efficiency. As a result, proper allocation of filters with different kernel sizes through the layers introduces a considerable improvement in the performance. Achievements of this study will provide the researchers with a clear clue and direction in designing optimal network architectures for deep learning purposes.},
	number = {1},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Kebria, Parham M. and Khosravi, Abbas and Salaken, Syed Moshfeq and Nahavandi, Saeid},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE/CAA Journal of Automatica Sinica},
	keywords = {architectural properties, autonomous car, autonomous systems, autonomous vehicles, Autonomous vehicles, computer vision, convolutional networks, convolutional neural nets, convolutional neural networks, Convolutional neural networks, deep imitation, Deep learning, deep learning purposes, deep learning structures, deep learning techniques, design properties, filter size, intelligent transportation systems, kernel sizes, learning (artificial intelligence), machine vision, mean square error methods, mean squared error values, neural net architecture, optimal architecture, optimal network architectures, performance efficiency, realistic simulation environment, Reinforcement learning, Task analysis, Training},
	pages = {82--95},
	file = {IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/JGMLKRBF/8945486.html:text/html;IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/R8L2GVYB/Kebria et al. - 2020 - Deep imitation learning for autonomous vehicles ba.pdf:application/pdf}
}

@inproceedings{russelllearning1998,
	address = {Madison, Wisconsin, United States},
	title = {Learning agents for uncertain environments (extended abstract)},
	isbn = {978-1-58113-057-7},
	doi = {10.1145/279943.279964},
	abstract = {This talk proposes a very simple “baseline architecture” for a learning agent that can handle stochastic, partially observable environments. The architecture uses reinforcement learning together with a method for representing temporal processes as graphical models. I will discuss methods for learning the parameters and structure of such representations from sensory inputs, and for computing posterior probabilities. Some open problems remain before we can try out the complete agent; more arise when we consider scaling up.},
	language = {en},
	urldate = {2020-10-07},
	booktitle = {Proceedings of the eleventh annual conference on {Computational} learning theory  - {COLT}' 98},
	publisher = {ACM Press},
	author = {Russell, Stuart},
	year = {1998},
	pages = {101--103},
	file = {Russell - 1998 - Learning agents for uncertain environments (extend.pdf:C\:\\Users\\17248\\Zotero\\storage\\GS9FUNFL\\Russell - 1998 - Learning agents for uncertain environments (extend.pdf:application/pdf}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

@article{torabirecent2019,
  title={Recent advances in imitation learning from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1905.13566},
  year={2019}
}

@inproceedings{wang2019reinforced,
  title={Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation},
  author={Wang, Xin and Huang, Qiuyuan and Celikyilmaz, Asli and Gao, Jianfeng and Shen, Dinghan and Wang, Yuan-Fang and Wang, William Yang and Zhang, Lei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6629--6638},
  year={2019}
}

@incollection{chungrecurrent2015,
	title = {A {Recurrent} {Latent} {Variable} {Model} for {Sequential} {Data}},
	url = {http://papers.nips.cc/paper/5653-a-recurrent-latent-variable-model-for-sequential-data.pdf},
	urldate = {2020-08-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	publisher = {Curran Associates, Inc.},
	author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron C and Bengio, Yoshua},
	editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
	pages = {2980--2988},
	annote = {bc mf},
	file = {NIPS Full Text PDF:C\:\\Users\\17248\\Zotero\\storage\\K34ETBCK\\Chung et al. - 2015 - A Recurrent Latent Variable Model for Sequential D.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\17248\\Zotero\\storage\\JFQN7QYK\\5653-a-recurrent-latent-variable-model-for-sequential-data.html:text/html}
}

@article{tailorlearning2019,
	title = {Learning the optimal state-feedback via supervised imitation learning},
	volume = {3},
	issn = {2522-0098},
	url = {https://doi.org/10.1007/s42064-019-0054-0},
	doi = {10.1007/s42064-019-0054-0},
	abstract = {Imitation learning is a control design paradigm that seeks to learn a control policy reproducing demonstrations from expert agents. By substituting expert demonstrations for optimal behaviours, the same paradigm leads to the design of control policies closely approximating the optimal state-feedback. This approach requires training a machine learning algorithm (in our case deep neural networks) directly on state-control pairs originating from optimal trajectories. We have shown in previous work that, when restricted to low-dimensional state and control spaces, this approach is very successful in several deterministic, non-linear problems in continuous-time. In this work, we refine our previous studies using as a test case a simple quadcopter model with quadratic and time-optimal objective functions. We describe in detail the best learning pipeline we have developed, that is able to approximate via deep neural networks the state-feedback map to a very high accuracy. We introduce the use of the softplus activation function in the hidden units of neural networks showing that it results in a smoother control profile whilst retaining the benefits of rectifiers. We show how to evaluate the optimality of the trained state-feedback, and find that already with two layers the objective function reached and its optimal value differ by less than one percent. We later consider also an additional metric linked to the system asymptotic behaviour-time taken to converge to the policy’s fixed point. With respect to these metrics, we show that improvements in the mean absolute error do not necessarily correspond to better policies.},
	language = {en},
	number = {4},
	urldate = {2020-07-12},
	journal = {Astrodynamics},
	author = {Tailor, Dharmesh and Izzo, Dario},
	month = dec,
	year = {2019},
	pages = {361--374},
	annote = {bc mb},
	file = {Submitted Version:C\:\\Users\\17248\\Zotero\\storage\\TLVNYNT9\\Tailor and Izzo - 2019 - Learning the optimal state-feedback via supervised.pdf:application/pdf}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in neural information processing systems},
  pages={5048--5058},
  year={2017}
}

@misc{lillicrap2019continuous,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{arenzNonAdversarialImitationLearning2020,
	title = {Non-{Adversarial} {Imitation} {Learning} and its {Connections} to {Adversarial} {Methods}},
	url = {http://arxiv.org/abs/2008.03525},
	abstract = {Many modern methods for imitation learning and inverse reinforcement learning, such as GAIL or AIRL, are based on an adversarial formulation. These methods apply GANs to match the expert's distribution over states and actions with the implicit state-action distribution induced by the agent's policy. However, by framing imitation learning as a saddle point problem, adversarial methods can suffer from unstable optimization, and convergence can only be shown for small policy updates. We address these problems by proposing a framework for non-adversarial imitation learning. The resulting algorithms are similar to their adversarial counterparts and, thus, provide insights for adversarial imitation learning methods. Most notably, we show that AIRL is an instance of our non-adversarial formulation, which enables us to greatly simplify its derivations and obtain stronger convergence guarantees. We also show that our non-adversarial formulation can be used to derive novel algorithms by presenting a method for offline imitation learning that is inspired by the recent ValueDice algorithm, but does not rely on small policy updates for convergence. In our simulated robot experiments, our offline method for non-adversarial imitation learning seems to perform best when using many updates for policy and discriminator at each iteration and outperforms behavioral cloning and ValueDice.},
	urldate = {2020-11-08},
	journal = {arXiv:2008.03525 [cs, math, stat]},
	author = {Arenz, Oleg and Neumann, Gerhard},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.03525},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/U2DPAV42/Arenz and Neumann - 2020 - Non-Adversarial Imitation Learning and its Connect.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/9S9R35YQ/2008.html:text/html}
}

@article{tanwaniMotion2VecSemiSupervisedRepresentation2020,
	title = {{Motion2Vec}: {Semi}-{Supervised} {Representation} {Learning} from {Surgical} {Videos}},
	shorttitle = {{Motion2Vec}},
	url = {http://arxiv.org/abs/2006.00545},
	abstract = {Learning meaningful visual representations in an embedding space can facilitate generalization in downstream tasks such as action segmentation and imitation. In this paper, we learn a motion-centric representation of surgical video demonstrations by grouping them into action segments/sub-goals/options in a semi-supervised manner. We present Motion2Vec, an algorithm that learns a deep embedding feature space from video observations by minimizing a metric learning loss in a Siamese network: images from the same action segment are pulled together while pushed away from randomly sampled images of other segments, while respecting the temporal ordering of the images. The embeddings are iteratively segmented with a recurrent neural network for a given parametrization of the embedding space after pre-training the Siamese network. We only use a small set of labeled video segments to semantically align the embedding space and assign pseudo-labels to the remaining unlabeled data by inference on the learned model parameters. We demonstrate the use of this representation to imitate surgical suturing motions from publicly available videos of the JIGSAWS dataset. Results give 85.5 \% segmentation accuracy on average suggesting performance improvement over several state-of-the-art baselines, while kinematic pose imitation gives 0.94 centimeter error in position per observation on the test set. Videos, code and data are available at https://sites.google.com/view/motion2vec},
	urldate = {2020-11-08},
	journal = {arXiv:2006.00545 [cs]},
	author = {Tanwani, Ajay Kumar and Sermanet, Pierre and Yan, Andy and Anand, Raghav and Phielipp, Mariano and Goldberg, Ken},
	month = may,
	year = {2020},
	note = {arXiv: 2006.00545},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	annote = {Comment: IEEE International Conference on Robotics and Automation (ICRA), 2020},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/3RL2CMAD/Tanwani et al. - 2020 - Motion2Vec Semi-Supervised Representation Learnin.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/SA7DYR3L/2006.html:text/html}
}

@article{dasModelBasedInverseReinforcement2020,
	title = {Model-{Based} {Inverse} {Reinforcement} {Learning} from {Visual} {Demonstrations}},
	url = {http://arxiv.org/abs/2010.09034},
	abstract = {Scaling model-based inverse reinforcement learning (IRL) to real robotic manipulation tasks with unknown dynamics remains an open problem. The key challenges lie in learning good dynamics models, developing algorithms that scale to high-dimensional state-spaces and being able to learn from both visual and proprioceptive demonstrations. In this work, we present a gradient-based inverse reinforcement learning framework that utilizes a pre-trained visual dynamics model to learn cost functions when given only visual human demonstrations. The learned cost functions are then used to reproduce the demonstrated behavior via visual model predictive control. We evaluate our framework on hardware on two basic object manipulation tasks.},
	urldate = {2020-11-08},
	journal = {arXiv:2010.09034 [cs]},
	author = {Das, Neha and Bechtle, Sarah and Davchev, Todor and Jayaraman, Dinesh and Rai, Akshara and Meier, Franziska},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.09034},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
	annote = {Comment: Accepted at the 4th Conference on Robotic Learning (CoRL 2020), Cambridge MA, USA},
	file = {arXiv Fulltext PDF:/home/bryan/Zotero/storage/MEE3VCKF/Das et al. - 2020 - Model-Based Inverse Reinforcement Learning from Vi.pdf:application/pdf;arXiv.org Snapshot:/home/bryan/Zotero/storage/J9NW8UDE/2010.html:text/html}
}

@misc{brownBetterthanDemonstratorImitationLearning2019,
      title={Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations}, 
      author={Daniel S. Brown and Wonjoon Goo and Scott Niekum},
      year={2019},
      eprint={1907.03976},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{liu2020imitationcache,
  title={An imitation learning approach for cache replacement},
  author={Liu, Evan and Hashemi, Milad and Swersky, Kevin and Ranganathan, Parthasarathy and Ahn, Junwhan},
  booktitle={International Conference on Machine Learning},
  pages={6237--6247},
  year={2020},
  organization={PMLR}
}

@article{zhu2021offpolicyifo,
  title={Off-policy imitation learning from observations},
  author={Zhu, Zhuangdi and Lin, Kaixiang and Dai, Bo and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2102.13185},
  year={2021}
}

@article{Zuo2020offpolicyRAIL,
   abstract = {The goal of imitation learning (IL) is to enable the robot to imitate expert behavior given expert demonstrations. Adversarial imitation learning (AIL) is a recent successful IL architecture that has shown significant progress in complex continuous tasks, particularly robotic tasks. However, in most cases, the acquisition of high-quality demonstrations is costly and laborious, which poses a significant challenge for AILs. Although generative adversarial imitation learning (GAIL) and its extensions have shown that they are robust to sub-optimal experts, it is difficult for them to surpass the performance of experts by a large margin. To address this issue, in this paper, we propose a novel off-policy AIL method called robust adversarial imitation learning (RAIL). To enable the agent to significantly outperform a sub-optimal expert providing demonstrations, the hindsight idea of variable reward (VR) is first incorporated into the off-policy AIL framework. Then, a strategy called hindsight copy (HC) of demonstrations is designed to provide the discriminator and trained policy in the AIL framework with different demonstrations to maximize the use of such demonstrations and speed up the learning. Experiments were conducted on two multi-goal robotic tasks to test the proposed method. The results show that our method is not limited to the quality of expert demonstrations and can outperform other IL approaches.},
   author = {Guoyu Zuo and Qishen Zhao and Kexin Chen and Jiangeng Li and Daoxiong Gong},
   doi = {10.1016/j.asoc.2020.106795},
   isbn = {2020.106795},
   journal = {Applied Soft Computing Journal},
   keywords = {Demonstrations,Hindsight copy,Robot learning,Robust adversarial imitation learning,Variable reward},
   pages = {106795},
   title = {Off-policy adversarial imitation learning for robotic tasks with low-quality demonstrations},
   volume = {97},
   url = {https://doi.org/10.1016/j.asoc.2020.106795},
   year = {2020},
}

@article{huTwoStageModelAgnosticMetaLearning2020,
	title = {Two-{Stage} {Model}-{Agnostic} {Meta}-{Learning} {With} {Noise} {Mechanism} for {One}-{Shot} {Imitation}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3029220},
	abstract = {Given that humans and animals can learn new behaviors in a short time by observing others, the question we need to consider is how to make robots behave like humans or animals, that is, through effective demonstration, robots can quickly understand and learn a new ability. One possible solution is imitation based meta-learning, but most of the related approaches are limited in a particular network structure or a specific task. Particularly, meta-learning methods based on gradient-update are prone to overfit. In this article, we propose a generic meta-learning algorithm that divides the learning process into two independent stages (skill cloning and skill transfer) with a noise mechanism which is compatible with any model. The skill cloning stage enables a good understanding of the demonstration, which helps the skill transfer stage when the robot applies the learned experience into new tasks. The experimental results show that our algorithm can alleviate the phenomenon of overfitting by introducing a noise mechanism. Our method not only performs well on the regression task but is significantly better than the existing state-of-the-art one-shot imitation learning methods in the same simulation environments (i.e., simulated pushing and simulated reaching).},
	journal = {IEEE Access},
	author = {Hu, Z. and Gan, Z. and Li, W. and Wen, J. Z. and Zhou, D. and Wang, X.},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Adaptation models, Animals, Cloning, effective demonstration, generic meta-learning algorithm, humanoid robots, imitation based meta-learning, independent stages, learned experience, learning (artificial intelligence), Learning (artificial intelligence), learning process, Learning to learn, meta-learning, meta-learning methods, network structure, network theory (graphs), noise mechanism, one-shot imitation, one-shot imitation learning, robot learning, Robots, skill cloning stage, skill transfer stage, stage model-agnostic meta-learning, Task analysis, Training},
	pages = {182720--182730},
	file = {IEEE Xplore Full Text PDF:/home/bryan/Zotero/storage/NKPNH4KY/Hu et al. - 2020 - Two-Stage Model-Agnostic Meta-Learning With Noise .pdf:application/pdf;IEEE Xplore Abstract Record:/home/bryan/Zotero/storage/5GKDDYV6/9214823.html:text/html}
}

@misc{buhlerDrivingGhostsBehavioral2020,
      title={Driving Through Ghosts: Behavioral Cloning with False Positives}, 
      author={Andreas Bühler and Adrien Gaidon and Andrei Cramariuc and Rares Ambrus and Guy Rosman and Wolfram Burgard},
      year={2020},
      eprint={2008.12969},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={arXiv preprint arXiv:1811.06521},
  year={2018}
}

@inproceedings{tanwani2020motion2vec,
  title={Motion2Vec: Semi-supervised representation learning from surgical videos},
  author={Tanwani, Ajay Kumar and Sermanet, Pierre and Yan, Andy and Anand, Raghav and Phielipp, Mariano and Goldberg, Ken},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2174--2181},
  year={2020},
  organization={IEEE}
}

@article{wang2021minimizing,
  title={Minimizing the age-of-critical-information: an imitation learning-based scheduling approach under partial observations},
  author={Wang, Xiaojie and Ning, Zhaolong and Guo, Song and Wen, Miaowen and Poor, Vincent},
  journal={IEEE Transactions on Mobile Computing},
  year={2021},
  publisher={IEEE}
}

@article{hussein2021robust,
  title={Robust Maximum Entropy Behavior Cloning},
  author={Hussein, Mostafa and Crowe, Brendan and Petrik, Marek and Begum, Momotaz},
  journal={arXiv preprint arXiv:2101.01251},
  year={2021}
}

@article{luo2021self,
  title={Self-Imitation Learning by Planning},
  author={Luo, Sha and Kasaei, Hamidreza and Schomaker, Lambert},
  journal={arXiv preprint arXiv:2103.13834},
  year={2021}
}

@article{tu2021closing,
  title={Closing the closed-loop distribution shift in safe imitation learning},
  author={Tu, Stephen and Robey, Alexander and Matni, Nikolai},
  journal={arXiv preprint arXiv:2102.09161},
  year={2021}
}

@article{torabi2018behavioral,
  title={Behavioral cloning from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1805.01954},
  year={2018}
}