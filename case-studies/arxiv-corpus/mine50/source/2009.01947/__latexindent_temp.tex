\section{Threshold Sequence}
\begin{algorithm}[H]
	\caption{A Parallelizable Greedy Algorithm for Fixed Threshold $\tau$}
	\label{alg:threshold}
	\begin{algorithmic}[1]
	\Procedure{\threshold}{$f, \mathcal N, k, \delta, \epsi, \tau$}
	\State \textbf{Input:} evaluation oracle $f:2^{\mathcal N} \to \reals$, constraint $k$, revision $\delta$, error $\epsi$, threshold $\tau$
	\State Initialize $A \gets \emptyset$, $A' \gets \emptyset$, $V \gets \mathcal N$, 
	$\ell = \lceil 4\left(\frac{2}{\epsi}\log(n)+\log\left(\frac{n}{\delta}\right)\right) \rceil$ 
	\For{ $j \gets 1$ to $\ell$ } 
		\State Update $V \gets \{ x \in V : \marge{x}{A} \ge \tau \}$ \label{line:threshold-filtering}
		\If{ $|V| = 0$ } 
			\State \textbf{return} $A,A'$
		\EndIf
		\State $V \gets$ \textbf{random-permutation}$(V)$ \label{line:threshold-permute}
		\State $s \gets \min \{k-|A|, |V|\}$
		\State $B[1:s] \gets [\textbf{none},\cdots,\textbf{none}]$
		\For{$i \gets 1 $ to $s$ in parallel} 
			\State $T_{i-1} \gets \{v_1, v_2, \ldots, v_{i-1}\}$ 
			\State \textbf{if} $ \marge{v_i}{A\cup T_{i-1}} \geq  \tau $
				\textbf{then} $B[i] \gets \textbf{true}$ \label{line:threshold-if}
			\State \textbf{elif} $ \marge{v_i}{A\cup T_{i-1}} <  0$
				\textbf{then} $B[i] \gets \textbf{false}$
		\EndFor
		\State $i^* \gets \max\{i:\# \text{\textbf{true}s in } B[1:i] \ge (1-\epsi)i\}$
		\State $A \gets A \cup T_{i^*}$
		\State $A' \gets A' \cup T_{i^*}[\text{where } B \not = \textbf{false}]$ \label{line:threshold-Aprime}
		\If{ $|A| = k$ }
			\State \textbf{return} $A,A'$ 
		\EndIf
	\EndFor
	\State \textbf{return} \textit{failure}
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{theorem} \label{thm:threshold}
Let $(f,k)$ be an instance of \sm . For any constant $\epsi$, 
the algorithm \threshold outputs $A'\subseteq A \subseteq \mathcal{N}$ such that the following properties hold:
1) The algorithm succeeds with probability at least $1 - \delta/n$.
2) There are $\oh{n/\epsi}$ oracle queries in expectation and $\oh{\log (n/\delta)/\epsi}$ adaptive rounds.
3) It holds that $f(A')/|A'| \ge (1-\epsi) \tau$.
If $|A| < k$, then $\marge{x}{A} < \tau$ for all $x\in \mathcal{N}$.
4) It also holds that $f(A')\ge f(A)$ and $|A'|\ge (1-\epsi)|A|$
\end{theorem}
\begin{proof}
\textbf{Success Probability.}
\begin{lemma} \label{lemma:threshold-filterset}
	After \textbf{random-permutation} on Line \ref{line:threshold-permute},
	let $S_i=\{x \in V: \marge{x}{A\cup T_i} < \tau\}$.
	It holds that $|S_0|=0$, $|S_{|V|}|=|V|$, and $|S_{i-1}| \le |S_i|$.
\end{lemma}
\begin{proof}
	After filtering on Line \ref{line:threshold-filtering},
	any element $x \in V$ follows that $\marge{x}{A} \ge \tau$.
	Therefore, $S_0 = \emptyset$.
	Also, it is obvious that $\marge{x}{A\cup V}=0$.
	So, $S_{|V|} = V$.
	Next, let's consider any $x \in S_{i-1}$.
	From submodularity,
	$$\marge{x}{A \cup T_i} \le \marge{x}{A\cup T_{i-1}}< \tau.$$
	Thus, $x_i \in S_i$, and $|S_{i-1}| \le |S_i|$.
\end{proof}
From Lemma \ref{lemma:threshold-filterset},
there exists a point $t$ such that
$t = \min \{i: |S_i| \ge \epsi |V|/2\}$.
\begin{lemma} \label{lemma:threshold-prob1}
	When $s > t$, it holds that $\prob{i^*<t} \le 1/2$.
\end{lemma}
\begin{proof}
	Call an element $v_i \in V$ \textit{bad} iff
	$\marge{v_i}{A\cup T_{i-1}} < \tau$.
	Let $X_i=1_{\{v_i \text{ is bad}\}}$.
	Since the selection of $v_i$ depends on the previous selection,
	$(X_i)$ is a sequence of dependent random variables.
	For $i < t$, $$\ex{X_i}=\prob{v_i \text{ is bad}} <\epsi/2.$$
	Suppose $(Y_i)$ is a sequence of independent and identically distributed random variables,
	where $\prob{Y_i=1}=\epsi/2$ and $\prob{Y_i=0}=1-\epsi/2$.

	

	% Condition on $t=\alpha$ and $s=\beta$, where $\beta > \alpha$.
	% Call an element $v_i \in V$ \textit{bad} iff
	% $\marge{v_i}{A\cup T_{i-1}} < \tau$.
	% For each $i$, $v_i$ can be regarded as randomly selected from the rest of the candidate set
	% conditioning on the previous selection.
	% Therefore, the probability that $v_i$ is bad is equal to $|S_i|/|V|$.

	% If $i^*<t$, it always holds that the number of \textbf{true}s in $B[1:t] < (1-\epsi)t$,
	% which means there are more than $\epsi t$ bad elements in $T_t$.
	% For $i < t$, $\prob{v_i \text{ is bad}|T_{i-1}} <\epsi/2$.
	% Let $F$ be $t$ independent Bernoulli random variables each with success probability $\epsi/2$,
	% where $\ex{F}=\epsi t/2$.
	% Then,
	% \begin{align*}
	% 	&\prob{i^*<t|t=\alpha, s=\beta} \\
	% 	&\le \prob{\#\text{\textbf{true}s in } B[1:t] < (1-\epsi)t|t=\alpha, s=\beta}\\
	% 	&= \prob{\#\text{bad elements in } T_t > \epsi t|t=\alpha, s=\beta}\\
	% 	&\le \prob{F \ge \epsi t} \numberthis \label{ineq:dep1}\\
	% 	&\le \frac{\ex{F}}{\epsi t} \numberthis \label{ineq:markov1}\\
	% 	&= 1/2,
	% \end{align*}
	% where Inequality \ref{ineq:dep1} and \ref{ineq:markov1} follow from 
	% Lemma \ref{lemma:indep} and Markovâ€™s inequality, respectively.
	% By the law of Total Probability, $\prob{i^*<t} < 1/2$ after unfixing the event
	% $t=\alpha, s=\beta$.
\end{proof}
\begin{lemma} \label{lemma:threshold-prob2}
	When $s \le t$, it holds that $\prob{i^* < s} \le 1/2$.
\end{lemma}
\begin{proof}
	First, condition on $t=\alpha$ and $s=\beta$.
	If $i^* < s$, it holds that there are more than $\epsi t$
	bad elements in $T_s$.
	Following the proof of Lemma \ref{lemma:threshold-prob1},
	it holds that 
	$$\prob{i^* < s|t=\alpha, s=\beta} \le \prob{\#\text{bad elements in } T_s > \epsi s|t=\alpha, s=\beta} \le 1/2.$$
	Therefore, by the law of Total Probability and unfixing the event $t=\alpha$ and $s=\beta$,
	$\prob{i^* <s} < 1/2$.
\end{proof}
If Algorithm \ref{alg:threshold} returns a \textit{failure}, 
it holds that $|V| > 0$ and $|A| < k$ 
and the outer for loop runs $\ell$ iterations.
For any iteration $j$, there are two cases of $s$ and $t$:
the first one is $s>t$; the second one is $s \le t$.
For those iterations with $s>t$,
there should be no more than $m=\lceil\log_{1-\epsi/2}(1/n) \rceil$ iterations 
which successfully filter out $\epsi/2$ elements.
Otherwise, the algorithm terminates with $|V|=0$.
As for those iterations with $s \le t$,
it should hold that $i^* < s$.
Otherwise, $i^*=s$ and the algorithm terminates with $|A|=k$.

From the above discussion, to fail the algorithm, for the iterations that $s\le t$,
it always holds that $i^* < s$; for the iterations that $s >t$, 
there should be no more than $m$ iterations that $i^* \ge t$.
Define a \textit{successful iteration} as a iteration that successfully filters out $\epsi/2$ elements.
Condition on the event that the number of iterations with $s > t$ is $c=\alpha$.
Let $X_c$ be the number of successes during those $c$ iterations.
From the definition and Lemma \ref{lemma:threshold-prob1}, $X_c$ is the sum of $c$ dependent Bernoulli random variables,
where each variable has success probability more than $1/2$.
Then, let $Y_c$ be the sum of $c$ independent Bernoulli random variables
with success probability $1/2$.
Therefore, the failure probability of Algorithm \ref{alg:threshold} can be bounded as follows:
\begin{align*}
	&\prob{\text{Algorithm \ref{alg:threshold} fails}|c=\alpha} \\
	&\le \prob{X_c \le m|c=\alpha} \cdot \prod_{j:s_j \le t_j|c=\alpha}\prob{i_j^* < s_j}\\
	&\le \prob{Y_c \le m|c=\alpha} \cdot \left(\frac{1}{2}\right)^{\ell-\alpha} \numberthis \label{ineq:dep2}\\ 
	&\le \prob{Y_c \le 2\log(n)/\epsi|c=\alpha}\cdot \left(\frac{1}{2}\right)^{\ell-\alpha}\\ 
	&\le e^{-\frac{\alpha}{4}\left(1-\frac{4\log(n)}{\alpha\epsi}\right)^2 -(\ell-\alpha)\log(2)} \numberthis \label{ineq:chernoff}\\ 
	&= e^{\left(\log(2)-\frac{1}{4}\right)\alpha-\frac{4\log^2(n)}{\alpha \epsi^2}+\frac{2\log(n)}{\epsi}-\ell \log(2)}\\
	&\le e^{-\frac{\ell}{4}-\frac{4\log^2(n)}{\ell \epsi^2}+ \frac{2\log(n)}{\epsi}}  \numberthis \label{ineq:num1}\\
	&= e^{-\log\left(\frac{n}{\delta}\right)-\frac{\left(2\log(n) + \epsi\log\left(\frac{n}{\delta}\right)-\log(n)\right)^2}{\epsi^2\left(\frac{2}{\epsi}\log(n)+\log\left(\frac{n}{\delta}\right)\right)}} \le \frac{\delta}{n},
\end{align*}
where Inequality \ref{ineq:dep2} and \ref{ineq:chernoff} follow from 
Lemma \ref{lemma:indep} and \ref{lemma:chernoff}, respectively.
And Inequality \ref{ineq:num1} follows from monotonicity.

\textbf{Adaptivity and Query Complexity.}
From Algorithm \ref{alg:threshold}, the oracle queries occur on Line 
\ref{line:threshold-filtering} and \ref{line:threshold-if}.
Since filtering and inner \textbf{for} loop can be done in parallel, there are constant adaptive rounds in an iteration.
Therefore, the adaptivity is $\oh{\log(n)/\epsi}$.

Let $V_j$ be the set $V$ after filtering on Line \ref{line:threshold-filtering} at iteration $j$,
$j_{i}$ be the iteration which is the $i$-th successful iterations,
$Y_i=j_{i}-j_{i-1}$.
By Lemma \ref{lemma:indep}, it holds that $\ex{Y_i} \le 2$.
For any iteration $j$ that $j_{i-1}+1 \le j \le j_i$,
there are $i-1$ successes before it.
Thus, it holds that $|V_j| \le n(1-\epsi/2)^{i-1}$.

At any iteration $j$, there are $|V_{j-1}|+1$ oracle queries on Line \ref{line:threshold-filtering}.
As for the inner \textbf{for} loop, there are no more than $|V_j|+1$ oracle queries.
The expected number of total queries can be bounded as follows:
\begin{align*}
	\ex{\text{Queries}} &\le \sum_{j=1}^{\ell} \ex{|V_{j-1}|+|V_j|+2}\\
	&\le n+2\ell+\sum_{j=1}^{\ell} 2\ex{|V_j|}\\
	&\le n+2\ell+\sum_{i\ge 1} 2\ex{Y_i\cdot n(1-\epsi/2)^{i-1}}\\
	&\le n+2\ell+4n/\epsi.
\end{align*}
Therefore, the total queries are $\oh{n/\epsi}$.

\textbf{Marginal Gain.}
\begin{lemma} \label{lemma:threshold-good}
	A good element in $A$ is always a good element in $A'$. 
	There are at least $(1-\epsi)$-fraction of $A$ are good.
	So does $A'$.
	And, any element in $A'$ has nonnegative marginal gain.
\end{lemma}
\begin{proof}
	Let $A_j$ be the set $A$ after iteration $j$,
	$T_{j,i}$ be the first $i$ elements of $V_j$ at $j$-th iteration.
	Similarly, define $A_j'$ as the set $A'$ after iteration $j$,
	$T'_{j,i}= T_{j,i}[\text{where }B[1:i] \not = \textbf{false}]$.

	From Algorithm \ref{alg:threshold}, $A=\sum_{j=1}^{\ell} T_{j,i^*}$.
	For each $T_{j,i^*}$, there are at least $(1-\epsi)$-fraction of $T_{j,i^*}$ are good.
	Totally, there are at least $(1-\epsi)$-fraction of $A$ are good.

	By Line \ref{line:threshold-Aprime}, $T'_{j,i}$ only contains the elements
	with nonnegative marginal gains in $T_{j,i}$.
	For any $v_i \in V_j$, by submodularity, 
	$\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge \marge{v_i}{A_{j-1}\cup T_{j,i-1}}$.
	Therefore, there are at least $(1-\epsi)|A|$ $v_i$s such that 
	$v_i \in A' \subseteq A$ and 
	$\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge \marge{v_i}{A_{j-1}\cup T_{j,i-1}}\ge \tau$.
	And for any $v_i \in A'$, $\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge 0$.
\end{proof}

From Lemma \ref{lemma:threshold-good}, it holds that 
$$f(A'_j)-f(A'_{j-1}) = \sum_{v_i \in T'_{j,i^*}} \marge{v_i}{A'_{j-1} \cup T'_{j,i-1}}
\ge (1-\epsi)\tau |A'_j\backslash A'_{j-1}|$$
Then,
$$f(A') = \sum_{i=1}^\ell (f(A'_j)-f(A'_{j-1})) 
\ge \sum_{i=1}^\ell (1-\epsi)\tau |A'_j\backslash A'_{j-1}|=(1-\epsi)\tau|A'|.$$

If $|A| < k$, the algorithm terminates because of $V=\emptyset$.
So, for any $x \in \mathcal{N}$,
there exists an iteration $j_{(x)}+1$ such that
$x$ is filtered out at iteration $j_{(x)}+1$.
Then, it holds that $\marge{x}{A} \le \marge{x}{A_{j_{(x)}}}<\tau$.

\textbf{Relationship between $A$ and $A'$.}
From Algorithm \ref{alg:threshold}, at any iteration $j$,
$$|T'_{j,i^*}|=|T_{j,i^*}[\text{where } B \not = \textbf{false}]|\ge (1-\epsi)|T_{j,i^*}|.$$
Therefore, 
$$|A'|=\sum_{j=1}^\ell |T'_{j,i^*}|\ge 
(1-\epsi)\sum_{j=1}^\ell |T_{j,i^*}| = (1-\epsi)|A|.$$

For any $a\in A$(or $a \in A'$), let $A_{i(a)}$(or $A'_{i(a)}$) be the first several elements in $A$(or $A'$) before $a$.
If $a \in A'$, it holds that $A'_{i(a)} \subseteq A_{i(a)}$ and $\marge{a}{A'_{i(a)}} \ge \marge{a}{A_{i(a)}}$.
If $a \in A\backslash A'$, it holds that $\marge{a}{A_{i(a)}} < 0$.
Then,
\begin{align*}
    f(A') &= \sum_{a\in A'} \marge{a}{A'_{i(a)}} \\
    &\ge \sum_{a\in A'} \marge{a}{A_{i(a)}} + \sum_{a\in A\backslash A'} \marge{a}{A_{i(a)}}\\  
    &= \sum_{a\in A} \marge{a}{A_{i(a)}}=f(A).
\end{align*}
\end{proof}

