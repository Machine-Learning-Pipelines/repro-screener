\section{Analysis of \threseq} \label{apx:threseq}
\ThresholdFilterSet*
\begin{proof}[proof of Lemma~\ref{lemma:ThresholdFilterSet}]
    After filtering on Line~\ref{line:threshold-filtering},
    any element $x \in V$ follows that $\marge{x}{A} \ge \tau$.
    Therefore, $S_0 = \emptyset$.
    Also, it is obvious that $\marge{x}{A\cup V}=0$.
    So, $S_{|V|} = V$.
    Next, let's consider any $x \in S_{i-1}$.
    By submodularity,
    $$\marge{x}{A \cup T_i} \le \marge{x}{A\cup T_{i-1}}< \tau.$$
    Thus, for any $x \in S_{i-1}$, it holds that $x \in S_i$,
    which means $S_{i-1} \subseteq S_i$.
\end{proof}
\ThresholdProb*
\begin{proof}[proof of Lemma~\ref{lemma:ThresholdProb}]
    Call an element $v_i \in V$ \textit{bad} iff
    $\marge{v_i}{A\cup T_{i-1}} < \tau$;
	and \textit{good}, otherwise.
    The random permutation of $V$ can be regarded
    as $|V|$ dependent Bernoulli trials, with success
    iff the element is bad and failure otherwise.
	Observe that, the probability that an element in $T_i$ is bad,
	when $i \le t$,
	is less than $\epsi/2$, conditioned on the outcomes of the 
	preceding trials.
    We know that,
    $$\prob{i^* < \min\{s,t\}} \le \prob{\#\text{ bad elements in }
    T_{i'} > \epsi i' \text{, where } i' = \min\{s,t\}}.$$
    Let $X_i=1$, if $v_i$ is bad; and $X_i=0$, otherwise.
    Then, $(X_i)$ is a sequence of
    dependent Bernoulli trails.
    And for any $i \le i'$,
    $\prob{X_i = 1} \le \epsi/2$.
    Let $(Y_i)$ be a sequence of independent and identically distributed Bernoulli trails,
    each with success probability $\epsi/2$.
    Then, the probability of $i^* < \min\{s,t\}$ can be bounded as follows:
    $$\prob{i^* < \min\{s,t\}} 
    \le \prob{\sum_{i=1}^{i'} X_i > \epsi i'} \overset{(a)}{\le}
    \prob{\sum_{i=1}^{i'} Y_i > \epsi i'} \overset{(b)}{\le} 1/2, $$
    where Inequality (a) follows from Lemma~\ref{lemma:indep2},
    and Inequality (b) follows from Law of Total Probability
    and Markov's inequality.
\end{proof}
\begin{proof}[proof of success probability]
    When the algorithm fails to terminate, at each iteration,
	it always holds that $i^* < s$;
	and there are no more than $m=\lceil\log_{1-\epsi/2}(1/n) \rceil$ 
	iterations that $i^* \ge t$.
	Therefore, there are no more than $m$ iterations that
	$i^* \ge \min\{s,t\}$.
	Otherwise, with more than $m$ iterations that
	$i^* \ge \min\{s,t\}$, 
	if there is an iteration that
	$s \le t$, the algorithm terminates with $|A| = k$.
	Otherwise, with more than $m$ iterations that 
	$i^* \ge t$, the algorithm terminates with $|V| = 0$.
	Define a \textit{successful iteration} as an iteration that
	$i^* \ge \min\{s,t\}$, which means it successfully filters out 
	$\epsi/2$-fraction of $V$ or the algorithm stops here.
	Let $X$ be the number of successes in the $\ell$ iterations.
	Then, $X$ can be regarded as a sum of dependent Bernoulli trails,
	where the success probability is larger than 1/2 
	from Lemma~\ref{lemma:ThresholdProb}.
	Let $Y$ be a sum of independent Bernoulli trials,
	where the success probability is equal to 1/2.
	Then, the probability of failure can be bounded as follows,
	\begin{align*} 
		\prob{\text{failure}} &\le \prob{X \le m} \\
        &\overset{(a)}{\le} \prob{Y \le m} \\
        &\le \prob{Y \le 2\log(n)/\epsi}\\ 
        &\overset{(b)}{\le} e^{-\left(\frac{\log(n)}{2\log(n)+
        \epsi \log\left(\frac{n}{\delta}\right)}-1\right)^2
        \cdot \left(\frac{2}{\epsi}\log(n)+\log\left(\frac{n}{\delta}\right)\right)}\\ 
        &=e^{-\log\left(\frac{n}{\delta}\right)-
        \frac{\log^2(n)}{\epsi^2 \log\left(\frac{n}{\delta}\right) 
        +2\epsi \log(n)}}\\
        & \le \frac{\delta}{n},
	\end{align*}
	where Inequality (a) follows from Lemma~\ref{lemma:indep},
	and Inequality (b) follows from Lemma~\ref{lemma:chernoff}.
\end{proof}
% Algorithm~\ref{alg:threshold} succeeds once $|V|=0$ or $|A|=k$, before termination.
% If either case happens with high probability, Algorithm~\ref{alg:threshold}
% succeeds with high probability.
% In the following, we discuss the failure which
% happens when $|V| > 0$ and $|A| < k$ at termination.
% % If Algorithm~\ref{alg:threshold} returns a \textit{failure}, 
% % it holds that $|V| > 0$ and $|A| < k$ 
% % and the outer for loop runs $\ell$ iterations.

% For any iteration $j$, there are two cases of $s$ and $t$.
% First, for the iterations that $s>t$, 
% there should be no more than $m=\lceil\log_{1-\epsi/2}(1/n) \rceil$ iterations 
% which successfully filter out $\epsi/2$ elements.
% Otherwise, the algorithm terminates with $|V|=0$.
% And for those iterations with $s \le t$,
% it should hold that $i^* < s$.
% Otherwise, $i^*=s$ and the algorithm terminates with $|A|=k$.

% From the above discussion, to fail the algorithm, for the iterations that $s\le t$,
% it always holds that $i^* < s$; for the iterations that $s >t$, 
% there should be no more than $m$ iterations that $i^* \ge t$.
% Define a \textit{successful iteration}, which holds that $s\le t$, as an iteration
% that successfully filters out $\epsi/2$ elements.
% Condition on the event that the number of iterations with $s > t$ is $c=\alpha$.
% Let $X_c$ be the number of successes during those $c$ iterations.
% From the definition and Lemma~\ref{lemma:threshold-prob1}, $X_c$ is the sum of $c$ dependent Bernoulli random variables,
% where each variable has success probability more than $1/2$.
% Then, let $Y_c$ be the sum of $c$ independent Bernoulli random variables
% with success probability $1/2$.
% Therefore, the failure probability of Algorithm~\ref{alg:threshold} can be bounded as follows:

\ThresholdGood*
\begin{proof}[proof of Lemma~\ref{lemma:ThresholdGood}]
    Let $A_j$ be the set $A$ after iteration $j$,
    $T_{j,i}$ be the first $i$ elements of $V_j$ at $j$-th iteration.
    Similarly, define $A_j'$ as the set $A'$ after iteration $j$,
    $T'_{j,i}= T_{j,i}[\text{where }B[1:i] \not = \textbf{false}]$.

    From Algorithm~\ref{alg:threshold}, $A=\sum_{j=1}^{\ell} T_{j,i^*}$.
    For each $T_{j,i^*}$, there are at least $(1-\epsi)$-fraction of $T_{j,i^*}$ are good.
    Totally, there are at least $(1-\epsi)$-fraction of $A$ are good.

    By Line~\ref{line:threshold-Aprime}, $T'_{j,i}$ only contains the elements
    with nonnegative marginal gains in $T_{j,i}$.
    Therefore, any element in $A'$ has nonnegative marginal gain when added.
    For any good element $v_i \in V_j$, by submodularity, 
    $\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge 
    \marge{v_i}{A_{j-1}\cup T_{j,i-1}} \ge \tau$.
    Thus, a good element in $A$ is always good in $A'$.
    % there are at least $(1-\epsi)|A|$ $v_i$s such that 
    % $v_i \in A' \subseteq A$ and 
    % $\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge \marge{v_i}{A_{j-1}\cup T_{j,i-1}}\ge \tau$.
    % And for any $v_i \in A'$, $\marge{v_i}{A'_{j-1}\cup T'_{j,i-1}}\ge 0$.
\end{proof}

% From Lemma~\ref{lemma:ThresholdGood}, it holds that 
% $$f(A'_j)-f(A'_{j-1}) = \sum_{v_i \in T'_{j,i^*}} \marge{v_i}{A'_{j-1} \cup T'_{j,i-1}}
% \ge (1-\epsi)\tau |A'_j\backslash A'_{j-1}|$$
% Then,
% $$f(A') = \sum_{i=1}^\ell (f(A'_j)-f(A'_{j-1})) 
% \ge \sum_{i=1}^\ell (1-\epsi)\tau |A'_j\backslash A'_{j-1}|=(1-\epsi)\tau|A'|.$$

% If $|A| < k$, the algorithm terminates because of $V=\emptyset$.
% So, for any $x \in \mathcal{N}$,
% there exists an iteration $j_{(x)}+1$ such that
% $x$ is filtered out at iteration $j_{(x)}+1$.
% Then, it holds that $\marge{x}{A} \le \marge{x}{A_{j_{(x)}}}<\tau$.

% \textbf{Relationship between $A$ and $A'$.}
% From Algorithm~\ref{alg:threshold}, at any iteration $j$,
% $$|T'_{j,i^*}|=|T_{j,i^*}[\text{where } B \not = \textbf{false}]|\ge (1-\epsi)|T_{j,i^*}|.$$
% Therefore, 
% $$|A'|=\sum_{j=1}^\ell |T'_{j,i^*}|\ge 
% (1-\epsi)\sum_{j=1}^\ell |T_{j,i^*}| = (1-\epsi)|A|.$$

% For any $a\in A$(or $a \in A'$), let $A_{i(a)}$(or $A'_{i(a)}$) be the first several elements in $A$(or $A'$) before $a$.
% If $a \in A'$, it holds that $A'_{i(a)} \subseteq A_{i(a)}$ and $\marge{a}{A'_{i(a)}} \ge \marge{a}{A_{i(a)}}$.
% If $a \in A\backslash A'$, it holds that $\marge{a}{A_{i(a)}} < 0$.
% Then,
% \begin{align*}
%     f(A') &= \sum_{a\in A'} \marge{a}{A'_{i(a)}} \\
%     &\ge \sum_{a\in A'} \marge{a}{A_{i(a)}} + \sum_{a\in A\backslash A'} \marge{a}{A_{i(a)}}\\  
%     &= \sum_{a\in A} \marge{a}{A_{i(a)}}=f(A).
% \end{align*}

\begin{proof}[Calculation of Query Complexity]
    Let $V_j$ be the set $V$ after filtering on Line~\ref{line:threshold-filtering} at iteration $j$,
    $j_{i}$ be the iteration which is the $i$-th successful iterations,
    $Y_i=j_{i}-j_{i-1}$.
    By Lemma~\ref{lemma:indep}, it holds that $\ex{Y_i} \le 2$.
    For any iteration $j$ that $j_{i-1}+1 \le j \le j_i$,
    there are $i-1$ successes before it.
    Thus, it holds that $|V_j| \le n(1-\epsi/2)^{i-1}$.

    At any iteration $j$, there are $|V_{j-1}|+1$ oracle queries on Line~\ref{line:threshold-filtering}.
    As for the inner \textbf{for} loop, there are no more than $|V_j|+1$ oracle queries.
    The expected number of total queries can be bounded as follows:
    \begin{align*}
        \ex{\text{Queries}} &\le \sum_{j=1}^{\ell} \ex{|V_{j-1}|+|V_j|+2}\\
        &\le n+2\ell+\sum_{j=1}^{\ell} 2\ex{|V_j|}\\
        &\le n+2\ell+\sum_{i\ge 1} 2\ex{Y_i\cdot n(1-\epsi/2)^{i-1}}\\
        &\le n+2\ell+4n/\epsi.
    \end{align*}
    Therefore, the total queries are $\oh{n/\epsi}$.
\end{proof}