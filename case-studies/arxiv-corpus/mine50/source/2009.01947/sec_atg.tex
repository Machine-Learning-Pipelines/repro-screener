\section{The \algTwofullname Algorithm} \label{sec:latg}
\begin{algorithm}[t]
  \caption{The \adaptg Algorithm}
  \label{alg:latg}
  \begin{algorithmic}[1]
    \Procedure{ATG}{$f, \mathcal{N}, k, \epsi$}
    \Statex \textbf{Input:} evaluation oracle $f:2^{\mathcal N} \to \reals$, constraint $k$,
    accuracy parameter $\epsi > 0$, failure probability $\delta > 0$
    \State Initialize $c \gets 8 / \epsi$, $\epsi' \gets (1 - 1/e)\epsi / 8 $, 
    $\ell=\lceil \log_{1 -  \epsi'}(1/(ck)) \rceil+1$,
    $\delta\gets 1/ (2\ell)$,
    $M \gets \max_{x \in \mathcal N} f(x)$, $A \gets \emptyset$, 
    $A' \gets \emptyset$, $B \gets \emptyset$, $B' \gets \emptyset$
    \For{ $i \gets 1$ to $\ell$}\label{line:for1}
    \State $\tau \gets M \left( 1 -  \epsi' \right)^{i-1}$
    \State $S,S' \gets \threseq (f_A, k - |A|,  \tau,  \epsi', \delta)$ \label{line:thresh1}
    \State $A \gets A \cup S$
    \State $A' \gets A' \cup S'$
    \State \textbf{if} $|A|=k$ \textbf{then} break
    \EndFor
    \For{ $i \gets 1$ to $\ell$}\label{line:for2}
    \State $\tau \gets M \left( 1 -  \epsi' \right)^{i-1}$
    \State $S,S' \gets \threseq ( f_B\restriction_{ \mathcal N \setminus A }, k - |B|, \tau,  \epsi', \delta)$ \label{line:thresh2}
    \State $B \gets B \cup S$
    \State $B' \gets B' \cup S'$
    \State \textbf{if} $|B|=k$ \textbf{then} break
    \EndFor
    \State $A'' \gets \unc (A,  \epsi')$\label{line:unc}
    \State $C \gets \argmax \{ f(A'), f(B'), f(A'') \}$\label{line:chooseC}
    \State \textbf{return} $C$
    \EndProcedure
\end{algorithmic}
\end{algorithm}
In this section, we present the algorithm \algTwofullname 
(\latg, Alg.~\ref{alg:latg}), 
which achieves ratio $\approx 0.193 - \epsi$ 
in nearly optimal query and
adaptive complexity. 
The price of improving the ratio of the preceding section 
is an extra $\log(k)$ factor in the adaptivity. 

\textbf{Overview of Algorithm.}
Our algorithm (pseudocode in Alg.~\ref{alg:latg}) works
as follows. Each \textbf{for} loop corresponds to a low-adaptivity
greedy procedure using \threseq with descending thresholds. Thus,
the algorithm is structured as two iterated calls to a greedy algorithm,
where the second greedy call is restricted to select elements outside the
auxiliary set $A$ returned by the first. 
Finally, an unconstrained maximization
procedure is used within the first greedily-selected auxiliary set $A$.
Then, the best
of three candidate sets is returned. 
In the pseudocode for \latg, Alg.~\ref{alg:latg}, \threseq is called with
functions of the form $f_S$, which is defined
to be the submodular function $f_S( \cdot ) = f( S \cup \cdot )$.

At a high level, our approach is the following:
the \iter framework of \shortciteS{Gupta2010a}
runs two standard greedy algorithms followed by an
unconstrained maximization, which yields an algorithm
with $O(nk)$ query complexity and $O(k)$ adaptivity. 
We adopt this framework
but replace the standard greedy algorithm with a
novel greedy approach with low adaptivity and query complexity.
To design this novel greedy approach, we modify
the descending thresholds algorithm of \shortciteS{Badanidiyuru2014},
which has query complexity $O(n \log k)$ but very high adaptivity
of $\Omega(n \log k)$.
We use \threseq to lower the adaptivity of the descending thresholds 
greedy algorithm (see
Appendix~\ref{apx:threshgreedy} for pseudocode and a detailed discussion).
% The use of a new approach in step 1 is necessary
% because of the specific way the analysis works in step 2
% as discussed below, although
% the method of step 1 does resemble in some respects the algorithm
% developed in \cite{Fahrbach2018} for monotone functions (see
% Related Work for a comparison).

For the resulting algorithm \latg, 
we prove a ratio of %we improve the $1/6$ ratio proven for \iter in \cite{Gupta2010}
$0.193 - \epsi$ (Theorem~\ref{thm:latg}), which
improves the $1/6$ ratio for \iter proven in \shortciteS{Gupta2010a}.
Also, by adopting \threseq proposed in this paper,
the analysis of approximation ratio is simplified.
Thanks to that the contribution of each element added to the
solution set $A'$ is determined,
at least $(1-\epsi)|A|$ elements in the solution set $A'$ 
have marginal gains which exactly exceed the threshold $\tau$,
while the rest of it have non-negative marginal gains.
Therefore, it is not needed to analyze the marginal gain in expectation anymore.
An exact lower bound is given by the analysis of the two greedy procedures.
% This novel analysis requires that partial solutions returned by the greedy algorithms
% are analyzed together, which creates
% difficulties since the output of the second greedy algorithm
% must be conditioned on the random set $A$ chosen by the first
% greedy algorithm. If the output of the first greedy
% approach is conditioned upon selecting set $A$, a lower bound on the
% expected marginal gain of choosing elements into $A$ cannot be obtained. 
% Therefore, 
% a careful analysis is required to prove the ratio for
% the \latg algorithm.
% In
% addition to \thresam and a procedure
% for \unc, \latg uses
% 1) a low-adaptivity modification of the \thresamgreedy algorithm
% for monotone functions of \cite{Badanidiyuru2014},
% and 2) a framework analagous to
% that of the \iter algorithm of \cite{Gupta2010}.


% Equipped with the low-adaptivity modification of \thresamgreedy
% described in Appendix~\ref{apx:threshgreedy},
% the overall strategy of \latg is as
% follows:
% %this subroutine in a manner analogous to
% %how the IteratedGreedy of \cite{Gupta2010}
% %employs the standard greedy algorithm: 
% first run
% one greedy approach to yield set $A$ (\textbf{for} loop on line~\ref{line:for1}). Next,
% run a second greedy approach with $f$ restricted to $\mathcal N \setminus A$, which yields set $B$
% (\textbf{for} loop on line~\ref{line:for2}).
% Finally, run an algorithm for \unc on $A$ to yield
% set $A'$, and
% return the best of the resulting candidates $A,B,A'$.
% Although this strategy is analagous to
% \iter of \cite{Gupta2010} modulo the greedy approach used, 
% we are able to improve the approximation ratio
% of \cite{Gupta2010} from $1/(4 + \alpha)$
% to $\algTwoRatio$.
% We remark that the application of Lemma~\ref{lemm:thresh}
% required by \thresam
% creates considerable technical complications in the proof
% of Theorem~\ref{thm:latg} below.
% In Appendix~\ref{apx:iter}, we give
% a simpler form of these arguments to prove ratio
% $\frac{e - 1}{e(2 + \alpha) - \alpha}$ for \iter.

A simpler form of our arguments shows that
the improved ratio also holds for the original
\iter of \shortciteS{Gupta2010a}; this analysis is 
given in Appendix
\ref{apx:iter}. 
We prove the following theorem concerning the performance of \latg.
\begin{theorem} \label{thm:latg}
  Suppose there exists an $(1/\alpha)$-approximation for
  \unc with adaptivity $\Theta$ and query complexity
  $\Xi$, and let $\epsi> 0$.
  Then the algorithm \algTwofullname  for \sm
  has expected approximation ratio
  $\atgRatio$ %$ \approx 0.193 - \epsi $
  %Let $(f,k)$ be an instance of MCC, 
  %Choose $c = 8 / \eta$, and $\epsi = (1 - 1/e) \eta / 8$.
  %Then
%The parameters $\epsi, c$ can be chosen, such that
  %the set $C$ returned by algorithm \latg$(f,k,\epsi,\delta, c)$ satisfies
  with probability at
  least $(1 - 1/n)$,
  adaptive complexity of
  % $O\left( \log( n / \delta ) / \epsi + \log(1 / \epsi) / \epsi \right)$
  $O\left( \log_{1 - \epsi} (1/k) \log( n) / \epsi + \Theta \right)$ 
  and expected query complexity
  of
  % $O \left( \log_{1 - \epsi}(1/(6k)) \cdot \left( n / \epsi + n \log^3(1 / \epsi) / \epsi^4 \right) \right)$.
  $O \left( \log_{1 - \epsi}(1/k) \cdot \left( n / \epsi \right) + \Xi \right)$.
\end{theorem}
  If the algorithm of \shortciteS{Chen2018b} is used for \unc,
\latg achieves approximation
  ratio $\approx 0.193 - \epsi$
  with adaptive complexity
  $\oh{\log(n)\log( k )}$
  and query complexity
  $\oh{n \log(k) }$, wherein the $\epsi$
  dependence has been suppressed.
\begin{proof}[Proof of Theorem~\ref{thm:latg}]
  In this proof, we
  assume that the guarantees 
  of Theorem~\ref{thm:threshold} hold
  for each call to \threseq made by
  \latg; this occurs with probability at least
  $(1 - 1/n)$ by the union bound and 
  the choice of $\delta$.
  
\textbf{Overview of Proof.}
For the proof, a substantial amount of
machinery is necessary to lower bound
the marginal gain. The necessary notations
are made first; then, in Lemmas~\ref{lemm:A} --~\ref{lemm:B},
we formulate the necessary lower bounds on the marginal gains
for the first and second greedy procedures. For each respective
greedy procedure, 
this is accomplished by considering the good elements in the selected set
returned by \threseq, or the dummy element if the size of 
selected set is limited. 
This allows us to formulate a recurrence
on the sum of the marginal gains (Lemma~\ref{lemma:three}).
Finally, the recurrence allows us to proceed similarly to our proof
in Appendix~\ref{apx:iter} after a careful analysis of the error
introduced (Lemma~\ref{lemm:seven} in Appendix~\ref{apx:latg}).
% \paragraph{Definitions of Random Variables}
% Consider the probability space of all possible
% sequences of sets returned by the successive calls to
% \threseq on line~\ref{line:thresh1} and line~\ref{line:thresh2} and
% the call to \unc on line~\ref{line:unc}. Further,
% after each call to \threseq, 
% suppose the elements of $S$ returned by
% \threseq are added to $A$ or $B$ in uniformly random order.
% Let $\mathcal A_i$ 
% be the random variable defined as the 
% value of the set $A$ during the execution
% of \latg when $|A| = i$; define 
% $\mathcal B_i$ analogously.
% Let $\mathbf{t} = (t_1,t_2,\ldots,t_l)$ and
% $\boldsymbol{\tau} = (\tau_1,\tau_2,\ldots,\tau_l)$ be the random variables recording the 
% sizes of nonempty sets returned by \thresam and 
% the corresponding values of $\tau$, respectively,
% during the \textbf{for}
% loop on line~\ref{line:for1}.
% Similarly,
% let $\mathbf{t}' = (t_1',t_2',\ldots,t_{l'}')$ and
% $\boldsymbol{\tau}' = (\tau_1',\tau_2',\ldots,\tau_{l'}')$ 
% record the analogous
% values during the \textbf{for} loop on line~\ref{line:for2}.
% For $0 \le i \le k$, let 
% $j(i)$ be the maximum value of the
% following set: $\{ \sum_{h=1}^j t_h = s_j : j \ge 1 \land s_j \le i \}$
% or $0$ if $t_1 > i$.
% and let $j'(i)$ be defined analogously for the
% sequence $(t_1',\ldots,t_{l'}')$.
% Finally, let $O \subseteq \mathcal N$ have $f(O) = \opt$,
% $|O| \le k$.

% Let $l \le k$,
% $\boldsymbol{\alpha} \in \mathbb{N}^l$ and  $\boldsymbol{\beta} \in \mathbb{R}^l$ be
% sequences of length $l$. Let $i \le k$, and let $E \subseteq \mathcal N$.
% Let $\omega$ be the event that
% $\boldsymbol{t}=\boldsymbol{\alpha}$ and
% $\boldsymbol{\tau} = \boldsymbol{\beta}$ and
% $\mathcal{A}_{j(i)} = E$; let $\Omega$ be
% the collection of all events $\omega$ of this form.

% The next four lemmas are proven in Appendix~\ref{apx:latg}.
\textbf{Notations.}
  Followed by the notations in the pseudocode of Alg.~\ref{alg:atg},
  $A$ and $A'$ are returned by the first greedy procedure,
  while $B$ and $B'$ are returned by the second one.
  % Let $A_i$ be the set $A$ returned at the end of iteration $i$
  % by the first greedy procedure.
  Let $\mathcal{A}_j'$ be the first $j$ elements in $A'$,
  where $1 \le j \le |A'|$.
  Furthermore, for $|A'| < j \le k$, 
  let $\mathcal{A}_j'$ be $A'$
  combined with $j-|A'|$ dummy elements.
  Let $\{a_j'\} = \mathcal{A}_j' \backslash \mathcal{A}_{j-1}'$,
  $a_j'$ be returned at iteration $i(j)$,
  and $A_{i(j)}$ be the set $A$ returned at iteration $i(j)$.
  If $a_j'$ is dummy element, let $i(j)=\ell+1$.
  Then, we define $\mathcal{B}_j'$ and $B_{i(j)}$ analogously.
\begin{restatable}{lemma}{LemmaA}
  \label{lemm:A}
  For $1 \le j \le k$, there are at least $\lceil(1-\epsi')k\rceil$ of $j$ such that 
    $$f(\mathcal{A}_j')-f(\mathcal{A}_{j-1}')+\frac{M}{ck}\ge 
    \frac{1-\epsi'}{k}\left(f(O\cup A_{i(j)-1})-f(\mathcal{A}_{j-1}')\right).$$
    And for any $j$,
    $$f(\mathcal{A}_j')\ge f(\mathcal{A}_{j-1}').$$
\end{restatable}
The proof of the above lemma can be found in Appendix~\ref{apx:latg}.
Following the notations and the proof of Lemma~\ref{lemm:A},
we can get an analogous result
for the gain of $\mathcal B'$ as follows.
% Let $l \le k$,
% $\boldsymbol{\alpha} \in \mathbb{N}^l$ and  $\boldsymbol{\beta} \in \mathbb{R}^l$ be
% sequences of length $l$. Let $i \le k$, and let $E \subseteq U$.
% Let $\omega$ be the event that
% $\boldsymbol{t}=\boldsymbol{\alpha}$ and
% $\boldsymbol{\tau} = \boldsymbol{\beta}$ and
% $\mathcal{A}_{j(i)} = E$; let $\Omega$ be
% the collection of all events $\omega$ of this form.

%   Let $l \le k$, and let 
%   $\boldsymbol{\alpha} \in \mathbb{N}^l$ and  
%   $\boldsymbol{\beta} \in \mathbb{R}^l$ be
%   sequences of length $l$.
%   Let $i \le k$, let $A$ 
%   be a subset of $U$ of size at most $k$, and let $F$ be a 
%   subset of $U \setminus A$.
%   Let $\omega'$ be the event that
%   $\mathcal A = A \land \mathcal B_{j'(i)} = F \land \mathbf{t}' = \boldsymbol{\alpha} \land \boldsymbol{\tau}' = \boldsymbol{\beta}$. Finally, let $\Omega'$ be
% the collection of all events $\omega'$ of this form.
\begin{restatable}{lemma}{LemmaB} 
  \label{lemm:B}
  For $1 \le j \le k$, there are at least $\lceil(1-\epsi')k\rceil$ of $j$ such that
    $$f(\mathcal{B}_j')-f(\mathcal{B}_{j-1}')+\frac{M}{ck}\ge 
    \frac{1-\epsi'}{k}\left(f((O\backslash A)\cup B_{i(j)-1})-f(\mathcal{B}_{j-1}')\right).$$
    And for any $j$,
    $$f(\mathcal{B}_j')\ge f(\mathcal{B}_{j-1}').$$
\end{restatable}

The next lemma proved in Appendix~\ref{apx:latg} establishes the main recurrence.
\begin{restatable}{lemma}{LemmaC} 
  \label{lemma:three}
  Let $\Gamma_u=f(\mathcal{A}_{j(u)}')+f(\mathcal{B}_{j(u)}')$, 
    where $j(u)$ is the $u$-th $j$ which satisfies
    Lemma~\ref{lemm:A} or Lemma~\ref{lemm:B}.
    Then, there are at least $\lceil(1-\epsi')k\rceil$ of $u$ follow that
    $$f(O\backslash A)-\Gamma_u-\frac{2M}{c(1-\epsi')}\le 
    \left(1-\frac{1-\epsi'}{k}\right)\left(f(O\backslash A)-
    \Gamma_{u-1}-\frac{2M}{c(1-\epsi')}\right).$$
  \end{restatable}

Lemma~\ref{lemma:three} yields a recurrence of the form 
$\left(b-u_{i+1}\right) \le a\left(b-u_{i}\right)$, $u_0 = 0$,
and has the solution $u_i \ge b(1 - a^i)$.
Consequently, we have 
\begin{align} \label{eq:part}
f(A') + f(B') &\ge \left(1-\left(1-\frac{1-\epsi'}{k}\right)^{(1-\epsi')k}\right)
\left(f(O \backslash A) - \frac{2M}{c(1-\epsi')}\right) \nonumber \\
& \ge \left(1-e^{-(1-\epsi')^2}\right)
\left(f(O \backslash A) - \frac{2M}{c(1-\epsi')}\right)
\end{align}
Let $\beta = 1 - e^{-(1 - \epsi')^2}$. From
the choice of $C$ on line~\ref{line:chooseC}, we have $2f(C) \ge f(A') + f(B')$ and
so from (\ref{eq:part}), we have 
\begin{align} \label{eq:part3}
f(O \setminus A) &\le \frac{2}{\beta} f(C) + \frac{2M}{c(1 - \epsi')^2} \nonumber \\ 
&\le \frac{2}{\beta} f(C) + \frac{2f(O)}{c(1 - \epsi')^2}.
\end{align}

Since an $(1/\alpha)$-approximation is used 
for \unc, for any $A$, $f(O \cap A) / \alpha \le \ex{ f(A'') | A }$; therefore, 
\begin{equation} \label{eq:int}
f( O \cap A ) \le \alpha \ex{f(C)}.
\end{equation}

For any set $A$, $f(O) \le f(O \cap A) + f(O \setminus A)$
by submodularity and nonnegativity. 
Therefore, by Inequalities~\ref{eq:part3} and~\ref{eq:int},
\begin{align*}
f(O) &\le f(O \cap A) + f(O \setminus A)\\
&\le \frac{2}{\beta} f(C) + \frac{2f(O)}{c(1 - \epsi')^2} + 
\alpha \ex{f(C)}.
\end{align*}
Therefore,
$$
  \ex{f(C)}\ge \frac{1-\frac{2}{c(1-\epsi')}}{\alpha+\frac{2}{\beta}}f(O)
  \ge \left(\frac{e-1}{\alpha(e-1)+2e}-\epsi\right)f(O).
  $$

%Let $\hat \epsi$ be the accuracy parameter
%$\epsi$ that is input to \latg. 
% From (\ref{eq:part3}), (\ref{eq:total}), and (\ref{eq:int}) and the choices of $c$, $\epsi'$
% on line~\ref{alg2:setparams},
% we have from Lemma~\ref{lemm:seven} in Appendix~\ref{apx:latg}
% \begin{align*}
% \ex{f(C)} &\ge \left( \frac{1 - \frac{2}{c(1-\epsi')^2}}{\alpha + \frac{2}{\beta}} \right) f(O) \\ 
% &\ge \left( \frac{(e - 1)}{ \alpha ( e - 1 ) + 2e} - \epsi  \right) f(O).
% \end{align*}  %\approx (0.193 - \eta) f(O). $$
\end{proof}
% \begin{figure*}[t] \centering
%   \subfigure[Objective, small $k$]{ \label{fig:val-Google}
%     \includegraphics[width=0.28\textwidth,height=0.15\textheight]{val-google}
%   }
%   \subfigure[Rounds, small $k$]{ \label{fig:rounds-Google}
%     \includegraphics[width=0.29\textwidth,height=0.15\textheight]{rounds-google}
%   }
% %zn  \subfigure[Rounds, small $k$]{ \label{fig:rounds-Google}
% %zn    \includegraphics[width=0.28\textwidth,height=0.15\textheight]{../plot/figs/rounds-google}
% %  }
%   \subfigure[Objective, large $k$]{ \label{fig:val-Google-largek}
%     \includegraphics[width=0.28\textwidth,height=0.15\textheight]{val-google-largek}
%   }

%   \subfigure[Queries, large $k$]{ \label{fig:query-Google-largek}
%     \includegraphics[width=0.28\textwidth,height=0.15\textheight]{query-google-largek}
%   }
%   \subfigure[Rounds, large $k$]{ \label{fig:rounds-Google-largek}
%     \includegraphics[width=0.28\textwidth,height=0.15\textheight]{rounds-google-largek}
%   }
% % %  \subfigure[Queries, RM]{ \label{fig:query-Facebook}
% % %    \includegraphics[width=0.23\textwidth,height=0.11\textheight]{../plot/figs/query-Facebook-largek}
% % %  }
% %   \subfigure[val-epsi-Google]{ \label{fig:val-epsi-Google}
% %     \includegraphics[width=0.23\textwidth,height=0.11\textheight]{../plot/figs/val-epsi-Google}
% %   }
% %   \subfigure[query-epsi-Google]{ \label{fig:query-epsi-Google}
% %     \includegraphics[width=0.23\textwidth,height=0.11\textheight]{../plot/figs/query-epsi-Google}
% %   }
%    \subfigure[Legend]{ \label{fig:legend}
%      \includegraphics[width=0.28\textwidth,height=0.15\textheight]{Legend.pdf}
%    }
%   \caption{Comparison of objective value (normalized by the \iter objective value), 
%     total queries, and adaptive rounds on web-Google for the maxcut application for 
%     both small and large $k$ values. The large $k$ values are given as a fraction of the number of nodes in the network. The algorithm of \cite{Ene2020} is run with oracle access to the multilinear extension and its gradient; total queries reported for this algorithm are queries to these oracles, rather than the original set function.  } \label{fig:main}
% \end{figure*}
