\chapter{Conclusion}
In this report, we first reviewed and formulated the representative multi-armed bandit and collaborative filtering methods. Subsequently, we introduce the matrix factorization methods, and a matrix factorization considering bias is proposed. Based on it, we illustrate the memory-based collaborative filtering recommender system and a hybrid recommender system that combines the content-based method with matrix factorization techniques. Importantly, in this work, BanditMF has been proposed, which is a multi-armed bandit-based matrix factorization recommender system. This system combines the matrix factorization (MF) which is model-based collaborative filtering with the multi-armed bandit algorithm. BanditMF uses a multi-armed bandit algorithm to solve the cold start problem in collaborative filtering. Also, with the help of matrix factorization results, the bandit algorithm can quickly derive user preferences. When we get the user preferences of the new users, we can transfer them to the offline module for the recommendation. That is, we add the user preference vector obtained from the online module to the user-item rating matrix. The advantage of this is that the collaborative filtering technology in the offline module fills a gap in the multi-armed bandit algorithm where similarity and user relationships are not taken into account. Also, for BanditMF, there are disadvantages. As we explain in the report, the contextual bandit algorithm can be based on contextual information to achieve a better balance between exploration and exploitation. However, in our BanditMF, we apply the context-free bandit, i.e., a bandit algorithm that does not consider contextual feature information, which may result in the recommended items not being optimal. The future work is to extend the contextual bandit to the BanditMF.