\vspace{-0.05in}
\section{Conclusion}
\vspace{-0.1in}
We have presented  \ours, a novel meta learning approach of model initializations. We view the inner-optimization as solving a forward ODE, and use the adjoint method to compute the gradient of the meta-loss w.r.t. the initialization in an efficient and accurate way. %Our method does not need aggressive approximations or additional regularization, and applies to long training trajectories with various lengths. 
We plan to extend our work to conditional meta learning~\citep{denevi2021conditional,wang2020structured} so as to further leverage side information to estimate task-specific initializations. 

