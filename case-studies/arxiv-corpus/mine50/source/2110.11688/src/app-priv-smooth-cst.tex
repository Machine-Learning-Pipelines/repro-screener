
\section{Private Estimation of Smoothness Constants}
\label{sec:priv-estim-smoothn}


In this section, we explain how a fraction $\epsilon'$ of the $\epsilon$ budget
of DP
can be used to estimate the coordinate-wise smoothness constants,
which are essential to the good performance of DP-CD on imbalanced problems.
Let
$f$ be
defined as the average loss over the dataset $D$ as in
problem~\eqref{eq:dp-erm}. We
denote
by $M_j^{(i)}$ the $j$-th component-smoothness constant of
$\ell(\cdot, d_i)$, where $d_i$ is the $i$-th point in
$D$. The $j$-th smoothness constant of the function $f$ is thus the
average of all these constants:
$M_j = \frac{1}{n} \sum_{i=1}^n M_j^{(i)}$.

Assuming that the practitioner knows an approximate upper bound $b_j$
over the $M_j^{(i)}$'s, they can enforce it by clipping $M_j^{(i)}$ to
$b_j$ for each $i\in[n]$. The sensitivity of the average of the clipped $M_j^{
(i)}$'s is
thus $2b_j/n$. One can then compute an estimate of $M_1,\dots,M_p$ under $\epsilon$-DP using the Laplace mechanism as follows:
\begin{align}
  M_j^{priv} = \frac{1}{n} \sum_{i=1}^n \clip(M_j^{(i)}, b_j) + \text{Lap}\left
  (\frac{2b_jp}{n\epsilon'}\right),\quad\text{for each }j\in[p]\enspace,
\end{align}
where the factor $p$ in noise scale comes from using the simple
composition theorem \cite{dwork2013Algorithmic}, and
$\text{Lap}(\lambda)$ is a sample drawn in a Laplace distribution of
mean zero and scale $\lambda$.  The computed constant can then
directly be used in DP-CD, allocating the remaining budget
$\epsilon-\epsilon'$ to the optimization procedure.


