<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-10-21">21 Oct 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paul</forename><surname>Mangold</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ. Lille</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ. Lille</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><surname>Salmon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ. Lille</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">IMAG</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Institut Universitaire de France (IUF)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ. Lille</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">=</forename><surname>Diag</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ. Lille</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 -CRIStAL</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-10-21">21 Oct 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">40ED374BE5706A055579196BE8132061</idno>
					<idno type="arXiv">arXiv:2110.11688v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-27T19:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning models can leak information about the data used to train them. To mitigate this issue, Differentially Private (DP) variants of optimization algorithms like Stochastic Gradient Descent (DP-SGD) have been designed to trade-off utility for privacy in Empirical Risk Minimization (ERM) problems. In this paper, we propose Differentially Private proximal Coordinate Descent (DP-CD), a new method to solve composite DP-ERM problems. We derive utility guarantees through a novel theoretical analysis of inexact coordinate descent. Our results show that, thanks to larger step sizes, DP-CD can exploit imbalance in gradient coordinates to outperform DP-SGD. We also prove new lower bounds for composite DP-ERM under coordinate-wise regularity assumptions, that are nearly matched by DP-CD. For practical implementations, we propose to clip gradients using coordinate-wise thresholds that emerge from our theory, avoiding costly hyperparameter tuning. Experiments on real and synthetic data support our results, and show that DP-CD compares favorably with DP-SGD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning fundamentally relies on the availability of data, which can be sensitive or confidential. It is now well-known that preventing learned models from leaking information about individual training points requires particular attention <ref type="bibr" target="#b48">(Shokri et al., 2017)</ref>. A standard approach for training models while provably controlling the amount of leakage is to solve an empirical risk minimization (ERM) problem under a differential privacy (DP) constraint <ref type="bibr" target="#b13">(Chaudhuri et al., 2011)</ref>. In this work, we aim to design a differentially private algorithm which approximates the solution to a composite ERM problem of the form:</p><formula xml:id="formula_0">w * ∈ arg min w∈R p 1 n n i=1 (w; d i ) + ψ(w) ,<label>(1)</label></formula><p>where D = (d 1 , . . . , d n ) is a dataset of n samples drawn from a universe X , : R p × X → R is a loss function which is convex and smooth in w, and ψ : R p → R is a convex regularizer which is separable (i.e., ψ(w) = p j=1 ψ j (w j )) and typically nonsmooth (e.g., 1 -norm). Differential privacy constraints induce a trade-off between the privacy and the utility (i.e., optimization error) of the solution of (1). This trade-off was made explicit by <ref type="bibr" target="#b7">Bassily et al. (2014)</ref>, who derived lower bounds on the achievable error given a fixed privacy budget. To solve the DP-ERM problem in practice, the most popular approaches are based on Differentially Private variants of Stochastic Gradient Descent (DP-SGD) <ref type="bibr" target="#b7">(Bassily et al., 2014;</ref><ref type="bibr" target="#b0">Abadi et al., 2016;</ref><ref type="bibr" target="#b55">Wang et al., 2017)</ref>, in which random perturbations are added to the (stochastic) gradients. <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> analyzed DP-SGD in the non-smooth DP-ERM setting, and <ref type="bibr" target="#b55">Wang et al. (2017)</ref> then proposed an efficient DP-SVRG algorithm for composite DP-ERM. Both algorithms match known lower bounds. SGD-style algorithms perform well in a wide variety of settings, but also have some flaws: they either require small (or decreasing) step sizes or variance reduction schemes to guarantee convergence, and they can be slow when gradients' coordinates are imbalanced. These flaws propagate to the private counterparts of these algorithms. Despite a few attempts at designing other differentially private solvers for ERM under different setups <ref type="bibr" target="#b49">(Talwar et al., 2015;</ref><ref type="bibr" target="#b14">Damaskinos et al., 2021)</ref>, the differentially private optimization toolbox remains limited, which undoubtedly restricts the resolution of practical problems.</p><p>In this paper, we propose and analyze a Differentially Private proximal Coordinate Descent algorithm (DP-CD), which performs updates based on perturbed coordinate-wise gradients (i.e., partial derivatives). Coordinate Descent (CD) methods have encountered a large success in non-private machine learning due to their simplicity and effectiveness <ref type="bibr" target="#b34">(Liu et al., 2009;</ref><ref type="bibr" target="#b23">Friedman et al., 2010;</ref><ref type="bibr" target="#b12">Chang et al., 2008;</ref><ref type="bibr" target="#b45">Sardy et al., 2000)</ref>, and have seen a surge of practical and theoretical interest in the last decade <ref type="bibr" target="#b39">(Nesterov, 2012;</ref><ref type="bibr" target="#b57">Wright, 2015;</ref><ref type="bibr" target="#b47">Shi et al., 2017;</ref><ref type="bibr" target="#b44">Richtárik and Takáč, 2014;</ref><ref type="bibr" target="#b22">Fercoq and Richtárik, 2015;</ref><ref type="bibr" target="#b50">Tappenden et al., 2016;</ref><ref type="bibr" target="#b24">Hanzely et al., 2020;</ref><ref type="bibr" target="#b41">Nutini et al., 2015;</ref><ref type="bibr" target="#b31">Karimireddy et al., 2019)</ref>. In contrast to SGD, they converge with constant step sizes that adapt to the coordinate-wise smoothness of the objective. Additionally, CD updates naturally tend to have a lower sensitivity. Operating with partial gradients thus enables our private algorithm to reduce the perturbation required to guarantee privacy without resorting to amplification by subsampling <ref type="bibr" target="#b2">(Balle et al., 2018;</ref><ref type="bibr" target="#b38">Mironov et al., 2019)</ref>.</p><p>We propose a novel analysis of proximal CD with perturbed gradients to derive optimal upper bounds on the privacy-utility trade-off achieved by DP-CD. We prove a recursion on distances of CD iterates to an optimal point that keeps track of coordinate-wise regularity constants in a tight manner and allows to use large, constant step sizes that yield high utility. Our results highlight the fact that DP-CD can exploit imbalanced gradient coordinates to outperform DP-SGD. They also improve upon known convergence rates for inexact CD in the non-private setting <ref type="bibr" target="#b50">(Tappenden et al., 2016)</ref>. We assess the optimality of DP-CD by deriving lower bounds that capture coordinate-wise Lipschitz regularity measures, and show that DP-CD matches those bounds up to logarithmic factors. Our lower bounds also suggest interesting perspectives for future work on DP-CD algorithms.</p><p>Our theoretical results have important consequences for practical implementations, which heavily rely on gradient clipping to achieve good utility. In contrast to DP-SGD, DP-CD requires to set coordinate-wise clipping thresholds, which can lead to impractical coordinate-wise hyperparameter tuning. We instead propose a simple rule for adapting these thresholds from a single hyperparameter. We also show how the coordinate-wise smoothness constants used by DP-CD can be estimated privately. We validate our theory with numerical experiments on real and synthetic datasets. These experiments further show that even in balanced problems, DP-CD can still improve over DP-SGD, confirming the relevance of DP-CD for DP-ERM.</p><p>Our main contributions can be summarized as follows:</p><p>1. We propose the first proximal CD algorithm for composite DP-ERM, formally prove its utility, and highlight regimes where it outperforms DP-SGD.</p><p>2. We show matching lower bounds under coordinate-wise regularity assumptions.</p><p>3. We give practical guidelines to use DP-CD, and show its relevance through numerical experiments.</p><p>The rest of this paper is organized as follows. We first describe some mathematical background in Section 2.</p><p>In Section 3, we present our DP-CD algorithm, show that it satisfies DP, establish utility guarantees, and compare these guarantees with those of DP-SGD. In Section 4, we derive lower bounds under coordinate-wise regularity assumptions, and show that DP-CD can match them. Section 5 discusses practical questions related to gradient clipping and the private estimation of smoothness constants. Section 6 presents our numerical experiments, comparing DP-CD and DP-SGD on LASSO and 2 -regularized logistic regression problems. Finally, we review existing work in Section 7, and conclude with promising lines of future work in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we introduce important technical notions that will be used throughout the paper.</p><p>Norms. We start by defining two conjugate norms that will be crucial in our analysis, for they allow to keep track of coordinate-wise quantities. Let u, v = Algorithm 1 Differentially Private Proximal Coordinate Descent Algorithm (DP-CD).</p><p>Input: noise scales σ = (σ 1 , . . . , σ p ) for σ 1 , . . . , σ p &gt; 0; step sizes γ 1 , . . . , γ p &gt; 0; initial point w0 ∈ R p ; iteration budgets T, K &gt; 0.</p><p>1: for t = 0, . . . , T − 1 do 2:</p><p>Set θ 0 = wt 3:</p><p>for k = 0, . . . , K − 1 do 4:</p><p>Pick j from {1, . . . , p} uniformly at random 5:</p><p>Draw η j ∼ N (0, σ 2 j )</p><p>6:</p><p>Set θ k+1 = θ k 7:</p><p>Set θ k+1 j = prox γj ψj (θ k j − γ j (∇ j f (θ k ) + η j ))</p><p>8:</p><p>Set wt+1 = 1 K K k=1 θ k 9: return w priv = wT are readily available: we have ∆(∇ j ) ≤ 2L j for any j ∈ [p] (see Appendix A). The following quantity, relating the coordinate-wise sensitivities of gradients to coordinate-wise smoothness is central in our analysis:</p><formula xml:id="formula_1">∆ M −1 (∇ ) = p j=1 1 M j ∆(∇ j ) 2 1 2 ≤ 2 L M −1 .<label>(2)</label></formula><p>In this paper, we consider the classic central model of DP, where a trusted curator has access to the raw dataset and releases a model trained on this dataset 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Differentially Private Coordinate Descent</head><p>In this section, we introduce the Differentially Private proximal Coordinate Descent (DP-CD) algorithm to solve problem (1) under ( , δ)-DP constraints. We first describe our algorithm, show how to parameterize it to satisfy the desired privacy constraint, and prove corresponding utility results. Finally, we compare these utility guarantees with DP-SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Private Proximal Coordinate Descent</head><p>Let D = {d 1 , . . . , d n } ∈ X n be a dataset. We denote by f (w) = 1 n n i=1 (w; d i ) the M -component-smooth part of (1), by ψ(w) = p j=1 ψ j (w j ) its separable part, and let F (w) = f (w) + ψ(w). Proximal coordinate descent methods Richtárik and Takáč, 2014 solve problem (1) through iterative proximal gradient steps along each coordinate of F . Formally, given w ∈ R p and j ∈ [p], the j-th coordinate of w is updated as follows:</p><formula xml:id="formula_2">w + j = prox γj ψj w j − γ j ∇ j f (w t ) ,<label>(3)</label></formula><p>where γ j &gt; 0 is the step size and prox γj ψj (w) = arg min v∈R p 1 2 v − w 2 2 + γ j ψ j (v) is the proximal operator associated with ψ j <ref type="bibr" target="#b42">(Parikh and Boyd, 2014)</ref>. Update (3) only requires the computation of the j-th entry of the gradient. To satisfy differential privacy, we perturb this gradient entry with additive Gaussian noise of variance σ 2 j . The complete DP-CD procedure is shown in Algorithm 1. At each iteration, we pick a coordinate uniformly at random and update according to (3), albeit with noise addition (see line 7). For technical reasons related to our analysis, we use a periodic averaging scheme (line 8). This scheme is similar to DP-SVRG <ref type="bibr" target="#b28">(Johnson and Zhang, 2013)</ref>, although no variance reduction is required since DP-CD computes coordinate gradients over the whole dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Privacy Guarantees</head><p>For Algorithm 1 to satisfy ( , δ)-DP, the noise scales σ = (σ 1 , . . . , σ p ) can be calibrated as given in Theorem 3.1.</p><formula xml:id="formula_3">Theorem 3.1. Assume (•; d) is L-component-Lipschitz ∀d ∈ X . Let ≤ 1 and δ &lt; 1/3. If σ 2 j = 12L 2 j T K log(1/δ) n 2 2</formula><p>for all j ∈ [p], then Algorithm 1 satisfies ( , δ)-DP.</p><p>Sketch of Proof. (Complete proof in Appendix B). We track the privacy loss using Rényi differential privacy (RDP), which gives better guarantees than ( , δ)-DP for the composition of Gaussian mechanisms <ref type="bibr" target="#b37">(Mironov, 2017)</ref>. The j-th entry of ∇f has sensitivity ∆(∇ j f ) = ∆(∇ j )/n ≤ 2L j /n. By the Gaussian mechanism each iteration of DP-CD is (α,</p><formula xml:id="formula_4">2L 2 j α n 2 σ 2 j</formula><p>)-RDP for all α &gt; 1. The composition theorem for RDP gives a global RDP guarantee for DP-CD, that we convert to ( , δ)-DP using Proposition 3 of <ref type="bibr" target="#b37">Mironov (2017)</ref>. Choosing α carefully finally proves the result.</p><p>The dependence of the noise scales on , δ, n and T K (the number of updates) in Theorem 3.1 is standard in DP-ERM. However, the noise is calibrated to the loss function's component-Lipschitz constants. These can be much lower their global counterpart, the latter being used to calibrate the noise in DP-SGD algorithms. This will be crucial for DP-CD to achieve better utility than DP-SGD in some regimes. We also note that, unlike DP-SGD, DP-CD does not rely on privacy amplification by subsampling <ref type="bibr" target="#b2">(Balle et al., 2018;</ref><ref type="bibr" target="#b38">Mironov et al., 2019)</ref>, and thereby avoids the approximations required by these schemes to bound the privacy loss.</p><p>Remark 3.2. Theorem 3.1 assumes ∈ (0, 1] to give a simple closed form for the noise scales. In practice we compute tighter values numerically using Rényi DP formulas directly (see Eq. 18 in Appendix B), removing the need for this assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Utility Guarantees</head><p>We now state our central result on the utility of DP-CD for the composite DP-ERM problem. As done in previous work, we use the asymptotic notation O to hide non-significant logarithmic factors. Non-asymptotic utility bounds can be found in Appendix C. Theorem 3.3. Let (•; d) be a convex and L-component-Lipschitz loss function for all d ∈ X , and f be convex and M -component-smooth. Let ψ : R p → R be a convex and separable function. Let ≤ 1, δ &lt; 1/3 be the privacy budget. Let w * be a minimizer of F and F * = F (w * ). Let w priv ∈ R p be the output of Algorithm 1 with step sizes γ j = 1/M j , and noise scales σ 1 , . . . , σ p set as in Theorem 3.1 (with T and K chosen below) to ensure ( , δ)-DP. Then, the following holds:</p><formula xml:id="formula_5">1. For F convex, K = O R M √ pn L M −1 , and T = 1, then: E[F (w priv ) − F * ] = O p log(1/δ) n L M −1 R M , where R M = max( F (w 0 ) − F (w * ), w 0 − w * M ) and more simply R M = w 0 − w * M when ψ = 0. 2. For F µ M -strongly convex w.r.t. • M , K = O (p/µ M ), and T = O (log(n µ M /p L M −1 )), then: E[F (w priv ) − F * ] = O p log(1/δ) n 2 2 L 2 M −1 µ M .</formula><p>Expectations are over the randomness of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sketch of Proof. (Complete proof in Appendix C</head><p>). Existing analyses of CD fail to track the noise tightly across coordinates when adapted to the private setting. Contrary to these classical analyses, we prove a  <ref type="bibr" target="#b7">(Bassily et al., 2014)</ref> DP-SVRG <ref type="bibr" target="#b55">(Wang et al., 2017</ref>)</p><formula xml:id="formula_6">O p log(1/δ) n L M −1 R M O p log(1/δ) n 2 2 L 2 M −1 µ M DP-SGD</formula><formula xml:id="formula_7">O p log(1/δ) n ΛR I O p log(1/δ) n 2 2 Λ 2 µ I recursion on E θ k − w * 2 M , rather than on E F (θ k ) − F (w * ) .</formula><p>Our key technical result is a descent lemma (Lemma C.3) allowing us to obtain</p><formula xml:id="formula_8">E F (θ k+1 ) − F * − p − 1 p E F (θ k ) − F * ≤ E θ k − w * 2 M − E θ k+1 − w * 2 M + σ 2 M p .<label>(4)</label></formula><p>The above inequality shows that coordinate-wise updates leave a fraction p−1 p of the function "unchanged", while the remaining part decreases (up to additive noise). Importantly, all quantities are measured in M -norm. When summing (4) for k = 0, . . . , K − 1, its left hand side simplifies and its right hand side is simplified as a telescoping sum:</p><formula xml:id="formula_9">1 p K k=1 E F (θ k ) − F * ≤ E F ( wt ) − F * + E wt − w * 2 M + K p σ 2 M −1 ,<label>(5)</label></formula><p>where wt comes from θ 0 = wt . As wt+1 =</p><formula xml:id="formula_10">K k=1 θ k K and F is convex, we have F ( wt+1 )−F * ≤ 1 K K k=1 F (θ k )− F * .</formula><p>This proves the sub-linear convergence (up to an additive noise term) of the inner loop. The result in the convex case follows directly (since T = 1, only one inner loop is run). For strongly convex F , it further holds that</p><formula xml:id="formula_11">E wt − w * 2 M ≤ 2 µ M E[F ( wt ) − F (w * )]. Replacing in (5) with large enough K gives E F ( wt+1 ) − F * ≤ 1 2 E[F ( wt ) − F * ] + σ 2 M −1</formula><p>, and linear convergence (up to an additive noise term) follows. Finally, K and T are chosen to balance the "optimization" and the "privacy" errors.</p><p>Remark 3.4. Our novel convergence proof of CD is also useful in the non-private setting. In particular, we improve upon known convergence rates for inexact CD methods with additive error <ref type="bibr" target="#b50">(Tappenden et al., 2016)</ref>, under the hypothesis that gradients are noisy and unbiased. In their formalism, we have α = 0 and β = σ 2 M −1 /p. With our analysis, the algorithm requires 2pR 2 M /(ξ−pβ) (resp. 4p/µ M log((F (w 0 )−F * )/(ξ−pβ))) iterations to achieve expected precision ξ &gt; pβ when F is convex (resp. µ M -strongly-convex w.r.t. • M ), improving upon <ref type="bibr" target="#b50">Tappenden et al. (2016)</ref>'s results by a factor pβ/2R 2 M (resp. µ M /2). See Appendix C.3 for details. Moreover, unlike this prior work, our analysis does not require the objective to decrease at each iteration, which is essential to guarantee DP.</p><p>Our utility guarantees stated in Theorem 3.3 directly depend on precise coordinate-wise regularity measures of the objective function. In particular, the initial distance to optimal, the strong convexity parameter and the overall sensitivity of the loss function are measured in the norms • M and • M −1 (i.e., weighted by coordinate-wise smoothness constants or their inverse). In the remainder of this section, we thoroughly compare our utility results with existing ones for DP-SGD. We will show the optimality of our utility guarantees in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Comparison with DP-SGD and DP-SVRG</head><p>We now compare DP-CD with DP-SGD and DP-SVRG, for which <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> and <ref type="bibr" target="#b55">Wang et al. (2017)</ref> proved utility guarantees. In this section, we assume that the loss function satisfies the hypotheses of Theorem 3.3, and is Λ-Lipschitz. We denote by µ I the strong convexity parameter of (•, d) w.r.t. • 2 and R I the equivalent of R M when M is the identity matrix I. As can be seen from Table <ref type="table" target="#tab_0">1</ref>, comparing DP-CD and DP-SGD boils down to comparing L M −1 R M with ΛR I for convex functions and L 2 M −1 /µ M with Λ 2 /µ I for strongly-convex functions. We compare these terms in two scenarios, depending on the distribution of coordinate-wise smoothness constants. To ease the comparison, we assume that R M = w 0 − w * M and R I = w 0 − w * I (which is notably the case when ψ = 0), and that F has a unique minimizer w * .</p><p>Balanced. When the smoothness constants M are all equal,</p><formula xml:id="formula_12">L M −1 R M = L 2 R I and L 2 M −1 /µ M = L 2 2 /µ I . This boils down to comparing L 2 to Λ. As Λ ≤ L 2 ≤</formula><p>√ pΛ, DP-CD can be up to p times worse than DP-SGD. This can only happen when features are extremely correlated, which is generally not the case in machine learning. We show empirically in Section 6.2 that, even in balanced regimes, DP-CD can still significantly outperform DP-SGD.</p><p>Unbalanced. More favorable regimes exist when smoothness constants are imbalanced. To illustrate this, consider the case where the first coordinate of the loss function dominates others. There,</p><formula xml:id="formula_13">M max = M 1 M min = M j and L max = L 1 L min = L j for all j = 1, so that L 2 1 /M 1 dominates the other terms of L 2 M −1 . This yields L 2 M −1 ≈ L 2 1 /M 1 ≈ Λ/M max</formula><p>, and µ M = µ I M min . Moreover, if the first coordinate of w * is already well estimated by w 0 (which is common for sparse models), then R M ≈ M min R I . We obtain that L M −1 R M ≈ M min /M max ΛR I for convex losses and</p><formula xml:id="formula_14">L M −1 µ M ≈ Mmin Mmax Λ 2</formula><p>µ I for strongly-convex ones. In both cases, DP-CD can perform arbitrarily better than DP-SGD, depending on the ratio between the smallest and largest coordinate-wise smoothness constants of the loss function. This is due to the inability of DP-SGD to adapt its step size to each coordinate. DP-CD thus converges quicker than DP-SGD on coordinates with smaller-scale gradients, requiring fewer accesses to the dataset, and in turn less noise addition. We give more details on this comparison in Appendix D, and complement it with an empirical evaluation on synthetic and real-world data in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lower Bounds</head><p>We now prove a new lower bound on the error achievable for composite DP-ERM with L-component-Lipschitz loss functions. While our proof borrows some ideas from the lower bounds known for constrained ERM with Λ-Lipschitz losses <ref type="bibr" target="#b7">(Bassily et al., 2014)</ref>, deriving our lower bounds requires to address a number of specific challenges. First, we cannot use an 2 norm constraint as in <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> in the design of the worst-case problem instances: we can only rely on separable regularizers. Second, imbalanced coordinate-wise Lipschitz constants prevent lower-bounding the distance between an arbitrary point and the solution. This leads us to revisit the construction of a "reidentifiable dataset" from <ref type="bibr" target="#b10">Bun et al. (2014)</ref> so that we have L-component-Lipschitzness while the sum of each column is large enough, which is crucial in our proof. The full proof is given in Appendix E.</p><formula xml:id="formula_15">Theorem 4.1. Let n, p &gt; 0, &gt; 0, δ = o( 1 n ), L 1 , . . . , L p &gt; 0, such that for all J ⊆ [p] of size at least p 75 , j∈J L 2 j = Ω( L<label>2</label></formula><p>2 ). Let X = p j=1 {±L j } and consider any ( , δ)-differentially private algorithm that outputs w priv . In each of the two following cases there exists a dataset D ∈ X n , a L-component-Lipschitz loss (•, d) for all d ∈ D and a regularizer ψ so that, with F the objective of (1) minimal at w * ∈ R p :</p><p>1. If F is convex:</p><formula xml:id="formula_16">E F (w priv ; D) − F (w * ) = Ω √ p L 2 w * 2 n . 2. If F is µ I -strongly-convex w.r.t. • 2 : E F (w priv ; D) − F (w * ) = Ω p L 2 2 µ I n 2 2 .</formula><p>We recover the lower bounds of <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> for Λ-Lipschitz losses as a special case of ours by setting</p><formula xml:id="formula_17">L 1 = • • • = L p = Λ/ √ p.</formula><p>In this case, the loss function used in our proof is indeed ( p j=1 L 2 j ) 1/2 = Λ-Lipschitz. To relate these lower bounds to the performance of DP-CD, consider a suboptimal version of our algorithm where the step sizes are set to γ 1 = • • • = γ p = (max j M j ) −1 . In this setting, results from Theorem 3.3 still hold, and match the lower bounds from Theorem 4.1 up to logarithmic factors. We leave open the question of the optimality of DP-CD under the additional hypothesis of smoothness.</p><p>We note that the assumption on the sum of the L j 's over a set of indices J in Theorem 4.1 can be eliminated at the cost of an additional factor of L min /L max for convex losses and (L min /L max ) 2 for strongly-convex losses, making the bound looser. Although the aforementioned assumption may seem solely technical, we conjecture that better utility is possible when a few coordinate-wise Lipschitz constants dominate the others. We discuss this further in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DP-CD in Practice</head><p>We now discuss practical questions related to DP-CD. First, we show how to implement coordinate-wise gradient clipping using a single hyperparameter. Second, we explain how to privately estimate the smoothness constants. Finally, we discuss the possibility of standardizing the features and how this relates to estimating smoothness constants for the important problem of fitting generalized linear models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Coordinate-wise Gradient Clipping</head><p>To bound the sensitivity of coordinate-wise gradients, our analysis of Section 3 relies on the knowledge of Lipschitz constants for the loss function (•; d) that must hold for all possible data points d ∈ X , see inequality (2) and the discussion above it. This is classic in the analysis of DP optimization algorithms (see e.g., <ref type="bibr" target="#b7">Bassily et al., 2014;</ref><ref type="bibr" target="#b55">Wang et al., 2017)</ref>. In practice however, these Lipschitz constants can be difficult to bound tightly and often give largely pessimistic estimates of sensitivities, thereby making gradients overly noisy. To overcome this problem, the common practice in concrete deployments of DP-SGD algorithms is to clip per-sample gradients so that their norm does not exceed a fixed threshold parameter C &gt; 0 <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>:</p><formula xml:id="formula_18">clip(∇ (w), C) = min 1, C ∇ (w) 2 ∇ (w) .<label>(6)</label></formula><p>This effectively ensures that the sensitivity ∆(clip(∇ , C)) of the clipped gradient is bounded by 2C.</p><p>In DP-CD, gradients are released one coordinate at a time and should thus be clipped in a coordinate-wise fashion. Using the same threshold for each coordinate would ruin the ability of DP-CD to account for imbalance across gradient coordinates, whereas tuning coordinate-wise thresholds as p individual hyperparameters {C j } p j=1 is impractical. Instead, we leverage the results of Theorem 3.3 to adapt them from a single hyperparameter. We first remark that our utility guarantees are invariant to the scale of the matrix M . After rescaling M to M = p tr(M ) M so that tr( M ) = tr(I) = p, as proposed by <ref type="bibr" target="#b44">Richtárik and Takáč (2014)</ref>, the key quantity ∆ M −1 (∇ ) as defined in (2) appears in our utility bounds instead of L M −1 . This suggests to parameterize the j-th threshold as</p><formula xml:id="formula_19">C j = M j /tr(M )C for some C &gt; 0, ensuring that ∆ M −1 ({clip(∇ j , C j )} p j=1 ) ≤ 2C.</formula><p>The parameter C thus controls the overall sensitivity, allowing clipped DP-CD to perform p iterations for the same privacy budget as one iteration of clipped DP-SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Private Smoothness Constants</head><p>DP-CD requires the knowledge of the coordinate-wise smoothness constants M 1 , . . . , M p of f to set appropriate step sizes (see Theorem 3.3) and clipping thresholds (see above). 2 In most problems, the M j 's depend on the dataset D and must thus be estimated privately using a fraction of the overall privacy budget. Since f is an average of loss terms, its coordinate-wise smoothness constants are the average of those of (•, d) over d ∈ D. These per-sample quantities are easy to get for typical losses (see Section 5.3 for the case of linear models). Privately estimating M 1 , . . . , M p thus reduces to a classic private mean estimation problem for which many methods exist. For instance, assuming that the practitioner knows a crude upper bound on per-sample smoothness constants, he/she can compute the smoothness constants of the (•, d)'s, clip them to the pre-defined upper bounds, and privately estimate their mean using the Laplace mechanism (see Appendix F for details). We show numerically in Section 6 that dedicating 10% of the total budget to this strategy allows DP-CD to effectively exploit the imbalance across gradients' coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Feature Standardization</head><p>CD algorithms are very popular to solve generalized linear models <ref type="bibr" target="#b23">(Friedman et al., 2010)</ref> and their regularized version (e.g., LASSO, logistic regression). For these problems, the coordinate-wise smoothness constants are M j ∝ 1 n X :,j 2 2 , where X :,j ∈ R n is the vector containing the value of the j-th feature. Therefore, standardizing the features to have zero mean and unit variance (a standard preprocessing step) makes coordinate-wise smoothness constants equal. However, this requires to compute the mean and variance of each feature in D, which is more costly than the smoothness constants to estimate privately. 3 Moreover, while our theory suggests that DP-CD may not be superior to DP-SGD when smoothness constants are all equal (see Section 3.4), the numerical results of Section 6 show that DP-CD often outperforms DP-SGD even when features are standardized.</p><p>Finally, we emphasize that standardization is not always possible. This notably happens when solving the problem at hand is a subroutine of another algorithm. For instance, the Iteratively Reweighted Least Squares (IRLS) algorithm <ref type="bibr" target="#b27">(Holland and Welsch, 1977)</ref> finds the maximum likelihood estimate of a generalized linear model by solving a sequence of linear regression problems with reweighted features, proscribing standardization. Similar situations happen when using reweighted 1 methods for non-convex sparse regression <ref type="bibr" target="#b11">(Candès et al., 2008)</ref>, relying on convex (LASSO) solvers for the inner loop. DP-CD is thus a method of choice to serve as subroutine in private versions of these algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Numerical Experiments</head><p>In this section, we assess the practical performance of DP-CD against (proximal) DP-SGD on LASSO 4 and 2 -regularized logistic regression 5 . On the latter problem, we also consider the dual private coordinate descent algorithm of <ref type="bibr" target="#b14">Damaskinos et al. (2021)</ref> (DP-SCD). For LASSO, we use the California dataset (Kelley Pace and Barry, 1997), with n = 20, 640 records and p = 8 features as well as a synthetic dataset (coined "Sparse LASSO") with n = 1, 000 records and p = 1, 000 independent features that follow a standard normal distribution. The labels are then computed as a noisy sparse linear combination of a subset of 10 active features. For logistic regression, we consider the Electricity dataset (Electricity, n.d.) with 45, 312 records and 8 features. On California and Electricity, we set = 1 and δ = 1/n 2 , which is generally seen as a rather high privacy regime. The Sparse LASSO dataset corresponds to a challenging setting for privacy (n = p), so we consider a low privacy regime with = 10, δ = 1/n 2 . Privacy accounting for DP-SGD is done by numerically evaluating the Rényi DP formula given by the sampled Gaussian mechanism <ref type="bibr" target="#b38">(Mironov et al., 2019)</ref>. Similarly 2 In fact, only M j / j M j is needed, as we tune the clipping threshold and scaling factor for the step sizes. See Section 6. 3 We note that the privacy cost of standardization is rarely accounted for in practical evaluations. 4 i.e., (w, (x, y)) = (w x − y) 2 , ψ(w) = λ w 1 . 5 i.e., (w, (x, y)</p><formula xml:id="formula_20">) = log(1 + exp(−yw x)), ψ(w) = λ 2 w 2 2 .</formula><p>Relative Error to Non-Private Opt 0 10 20 30 40 50</p><p>Passes on data Figure <ref type="figure" target="#fig_4">1</ref>: Relative error to non-private optimal for DP-CD (blue), DP-CD with privately estimated coordinatewise smoothness constants (green), DP-SGD (orange) and DP-SCD (red, only applicable to the smooth case) on two imbalanced problems. The number of passes is tuned separately for each algorithm to achieve lowest error. We report min/mean/max values over 10 runs.</p><p>for DP-CD, we do not use the closed-form formula of Theorem 3.1 but rather numerically evaluate the tighter Rényi DP formula given in Appendix B.</p><p>For DP-SGD, we use constant step sizes and standard gradient clipping. For DP-CD, we adapt the coordinatewise clipping thresholds from one hyperparameter, as described in Section 5.1. Similarly, coordinate-wise step sizes are set to γ j = γ/M j , where γ is a hyperparameter. When the coordinate-wise smoothness constants are not all equal, we also consider DP-CD with privately computed M j 's, as described in Section 5.2. For each dataset and each algorithm, we simultaneously tune the clipping threshold, the number of passes over the dataset and, for DP-CD and DP-SGD, the step sizes. After tuning these parameters, we report the relative error to the (non-private) optimal objective value. The complete tuning procedure is described in Appendix G.1, where we also give the best error for various numbers of passes for each algorithm and dataset. The code used to obtain all our results is available in a public repository 6 and in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Imbalanced Datasets</head><p>In the Electricity and California datasets, features are naturally imbalanced. DP-CD can exploit this through the use of coordinate-wise smoothness constants. We also consider a variant of DP-CD (DP-CD-P) which dedicates 10% of the privacy budget to estimate these constants (see Section 5.2) from a crude upper bound on each feature (twice their maximal absolute value). It then uses the resulting private smoothness constants in step sizes and clipping thresholds. Figure <ref type="figure" target="#fig_4">1</ref> shows that DP-CD outperforms DP-SGD and DP-SCD by an order of magnitude on both datasets, even when the smoothness constants are estimated privately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Balanced Datasets</head><p>To assess the performance of DP-CD when coordinate-wise smoothness constants are balanced, we standardize the Electricity and California datasets (see Section 5.3). As standardization is done for all algorithms, we do not account for it in the privacy budget. On standardized datasets, coordinate-wise smoothness constants are all equal, removing the need of estimating them privately. We report the results in Figure <ref type="figure">2</ref>. Although our theory suggests that DP-CD may do worse than DP-SGD in balanced regimes, we observe that it still improves over DP-SGD (and DP-SCD) in practice. Similar observations hold in our challenging Sparse LASSO problem, where DP-SGD is barely able to make any progress. We believe these results are in part due to the beneficial effect of clipping in DP-CD, and the fact that DP-SGD relies on amplification by Figure <ref type="figure">2</ref>: Relative error to non-private optimal for DP-CD (blue), DP-SGD (orange) and DP-SCD (red, only applicable to the smooth case) on three balanced problems. The number of passes is tuned separately for each algorithm to achieve lowest error. We report min/mean/max values over 10 runs.</p><p>subsampling, for which privacy accounting is not perfectly tight. Additionally, CD methods are known to perform well on fitting linear models: our results show that this transfers well to private optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Running Time</head><p>The results above showed that DP-CD yields better utility than DP-SGD. We also observe that DP-CD tends to reach these results in up to 10 times fewer passes on the data than DP-SGD (see Appendix G.1 for detailed results). Additionally, when accounting for running time, DP-CD significantly outperforms DP-SGD: we refer to Appendix G.2 for the counterparts of Figure <ref type="figure" target="#fig_4">1</ref> and 2 as a function of the running time instead of the number of passes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>DP-ERM. Differentially Private Empirical Risk Minimization was first studied by <ref type="bibr" target="#b13">Chaudhuri et al. (2011)</ref>, using output perturbation (adding noise to the solution of the non-private ERM problem) and objective perturbation (adding noise to the ERM objective itself). <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> then proposed DP-SGD and proved its near-optimality. <ref type="bibr" target="#b55">Wang et al. (2017)</ref> obtained faster convergence rates using a DP version of the SVRG algorithm <ref type="bibr" target="#b28">(Johnson and Zhang, 2013;</ref><ref type="bibr" target="#b58">Xiao and Zhang, 2014)</ref>. DP-SGD has become the standard approach to DP-ERM. In our work, we show that coordinate-wise updates can have lower sensitivity than DP-SGD updates and propose a DP-CD algorithm achieving competitive results. A private variant of the Frank-Wolfe algorithm (DP-FW) was also proposed to solve constrained DP-ERM problems <ref type="bibr" target="#b49">(Talwar et al., 2015)</ref>. Although these algorithms achieve a good privacy-utility trade-off in theory, we are not aware of any empirical evaluation. DP-FW algorithms access gradients indirectly through a linear optimization oracle over a constrained set. Restricting to a constrained set is not necessary in DP-CD, allowing its use for a different family of problems. Coordinate descent. Coordinate descent (CD) algorithms have a long history in optimization. <ref type="bibr" target="#b35">Luo and Tseng (1992)</ref>, <ref type="bibr" target="#b53">Tseng (2001)</ref>, and <ref type="bibr" target="#b52">Tseng and Yun (2009)</ref> have shown convergence results for (block) CD algorithms for nonsmooth optimization. <ref type="bibr" target="#b39">Nesterov (2012)</ref> later proved a global non-asymptotic 1/k convergence rate for CD with random choice of coordinates for a convex, smooth objective. Parallel, proximal variants were developed by <ref type="bibr" target="#b44">Richtárik and Takáč (2014)</ref> and <ref type="bibr" target="#b22">Fercoq and Richtárik (2015)</ref>, while <ref type="bibr" target="#b25">Hanzely et al. (2018)</ref> further considered non-separable non-smooth parts. Shalev-Shwartz and Zhang (2013) introduced Dual CD algorithms for smooth ERM, showing performance similar to SVRG. We refer to <ref type="bibr" target="#b57">Wright (2015)</ref> and <ref type="bibr" target="#b47">Shi et al. (2017)</ref> for detailed reviews on CD. Inexact CD was studied by <ref type="bibr" target="#b50">Tappenden et al. (2016)</ref>, but their analysis requires updates not to increase the objective, which is hardly compatible with DP. We obtain tighter results for inexact CD with noisy gradients (see Remark 3.4).</p><p>Private coordinate descent. <ref type="bibr" target="#b14">Damaskinos et al. (2021)</ref> introduced a CD method to privately solve the dual problem associated with generalized linear models with 2 regularization. Dual CD is tightly related to SGD, as each coordinate in the dual is associated with one data point. The authors briefly mention the possibility of performing primal coordinate descent but discard it on account of the seemingly large sensitivity of its updates. We show that primal DP-CD is in fact quite effective, and can be used to solve more general problems than considered by <ref type="bibr" target="#b14">Damaskinos et al. (2021)</ref>. Primal CD was successfully used by <ref type="bibr" target="#b8">Bellet et al. (2018)</ref> to privately learn personalized models from decentralized datasets. For the smooth objective they consider, each coordinate depends only on a subset of the full dataset, which directly yields low coordinate-wise sensitivity updates. In contrast, we introduce a general algorithm for composite DP-ERM, for which a novel utility analysis was required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Discussion</head><p>We presented the first differentially private proximal coordinate descent algorithm for composite DP-ERM.</p><p>Using an original approach to analyze proximal CD with perturbed gradients, we derived optimal upper bounds on the privacy-utility trade-off achieved by DP-CD. We also prove new lower bounds under a component-Lipschitzness assumption, and showed that DP-CD matches these bounds. Our results demonstrate that DP-CD strongly outperforms DP-SGD when gradients' coordinates are imbalanced. Numerical experiments show that DP-CD also performs very well in balanced regimes. The choice of coordinate-wise clipping thresholds is crucial for DP-CD to achieve good utility in practice, and we provided a simple rule to set them.</p><p>Although DP-CD already achieves good utility when most coordinates have small sensitivity, our lower bounds suggest that even better utility could be achieved by dynamically allocating more privacy budget to coordinates with largest sensitivities. A promising direction is to design DP-CD algorithms that leverage active set methods <ref type="bibr" target="#b59">(Yuan et al., 2010;</ref><ref type="bibr" target="#b33">Lewis and Wright, 2016;</ref><ref type="bibr" target="#b40">Nutini et al., 2017;</ref><ref type="bibr" target="#b15">De Santis et al., 2016;</ref><ref type="bibr" target="#b36">Massias et al., 2018)</ref>, which could provide practical alternatives to recent DP-SGD approaches that use a subspace assumption <ref type="bibr" target="#b60">(Zhou et al., 2021;</ref><ref type="bibr" target="#b30">Kairouz et al., 2021)</ref>. Finally, we believe that adaptive clipping techniques <ref type="bibr" target="#b43">(Pichapati et al., 2019;</ref><ref type="bibr" target="#b51">Thakkar et al., 2021)</ref> may help to further improve the practical performance of DP-CD when coordinate-wise smoothness constants are more balanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Lemmas on Sensitivity</head><p>In this section, we let X be the universe where the data is drawn from. To upper bound the sensitivities of a function's gradient, we start by recalling in Lemma A.1 that (coordinate) gradients are bounded by (coordinate-wise-)Lipschitz constants. We then link this upper bound with gradients' sensitivities in Lemma A.2.</p><p>Lemma A.1. Let : R p ×X → R be convex and differentiable in its first argument, Λ &gt; 0 and L 1 , . . . , L p &gt; 0.</p><formula xml:id="formula_21">1. If (•; d) is Λ-Lipschitz for all d ∈ X , then ∇ (w; d) 2 ≤ Λ for all w ∈ R p and d ∈ X . 2. If (•; d) is L-component-Lipschitz for all d ∈ X , then |∇ j (w; d)| ≤ L j for all w ∈ R p , d ∈ X and j ∈ [p].</formula><p>Proof. Let d ∈ X . We start by proving the first statement. First, if ∇ (w; d) = 0, ∇ (w; d) 2 = 0 ≤ Λ and the result holds. Second, we focus on the case where ∇ (w; d) = 0. The convexity of gives, for w ∈ R p , d ∈ X :</p><formula xml:id="formula_22">(w + ∇ (w; d); d) ≥ (w; d) + ∇ (w; d), ∇ (w; d) = (w; d) + ∇ (w; d) 2 2 ,<label>(7)</label></formula><p>then, reorganizing the terms and using Λ-Lipschitzness of yields</p><formula xml:id="formula_23">∇ (w; d) 2 2 ≤ (w + ∇ (w; d); d) − (w; d) ≤ | (w + ∇ (w; d); d) − (w; d)| ≤ Λ ∇ (w; d) 2 ,<label>(8)</label></formula><p>and the result follows after dividing by ∇ (w; d) 2 . To prove the second statement, we set j ∈ [p], and w ∈ R p , and remark that if ∇ j (w; d) = 0, then |∇ j (w; d)| ≤ L j . When ∇ j (w; d) = 0, the convexity of yields</p><formula xml:id="formula_24">(w + ∇ j (w; d)e j ; d) ≥ (w; d) + ∇ (w; d), ∇ j (w; d)e j = (w; d) + ∇ j (w; d) 2 . (<label>9</label></formula><formula xml:id="formula_25">)</formula><p>Reorganizing the terms and using L-component-Lipschitzness of gives Lemma A.2. Let : R p × X → R be convex and differentiable in its 1st argument, Λ &gt; 0 and L 1 , . . . , L p &gt; 0.</p><formula xml:id="formula_26">1. If (•; d) is Λ-Lipschitz for all d ∈ X , then ∆(∇ ) ≤ 2Λ. 2. If (•; d) is L-component-Lipschitz for all d ∈ X , then ∆(∇ j ) ≤ L j for all j ∈ [p].</formula><p>Proof. We start by proving the first statement. Let w, w ∈ R p , d, d ∈ X . From the triangle inequality and Lemma A.1, we get the following upper bounds:</p><formula xml:id="formula_27">∇ (w; d) − ∇ (w ; d ) 2 ≤ |∇ (w; d)| + |∇ (w ; d )| ≤ 2Λ ,<label>(11)</label></formula><p>which is the claim of the first statement. To prove the second statement, we proceed similarly: the triangle inequality and Lemma A.1 give the following upper bounds:</p><formula xml:id="formula_28">|∇ j (w; d) − ∇ j (w ; d )| ≤ |∇ j (w; d)| + |∇ j (w ; d )| ≤ 2L j ,<label>(12)</label></formula><p>which is the desired result.</p><p>We obtain the inequality (2) stated in Section 2 as a corollary.</p><formula xml:id="formula_29">Corollary A.3. Let L 1 , . . . , L p &gt; 0. Let (•; d) : R p → R be a convex, L-component-Lipschitz function for all d ∈ X . Then ∆ M −1 (∇ ) = p j=1 1 M j ∆(∇ j ) 2 1 2 ≤ p j=1 4 M j L 2 j 1 2 = 2 L M −1 .<label>(13)</label></formula><p>B Proof of Theorem 3.1</p><p>To track the privacy loss of an adaptive composition of K Gaussian mechanisms, we use Rényi Differential Privacy <ref type="bibr">(Mironov, 2017, RDP)</ref>. We note that similar results are obtained with zero Concentrated Differential Privacy <ref type="bibr" target="#b9">(Bun and Steinke, 2016)</ref>. This flavor of differential privacy, gives tighter privacy guarantees in that setting, as it reduces the noise variance by a multiplicative factor of log(K/δ) in comparison to the usual advanced composition theorem of differential privacy <ref type="bibr">(Dwork et al., 2006)</ref>. Importantly, RDP can be translated back to differential privacy.</p><p>In this section, we recall the definition and main properties of zCDP. We denote by D the set of all datasets over a universe X and by F the set of possible outcomes of the randomized algorithms we consider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Rényi Differential Privacy</head><p>We will use the Rényi divergence (Definition B.1), which gives a distribution-oriented vision of privacy. </p><formula xml:id="formula_30">D α (Y ||Z) = 1 α − 1 log C Pr [Y = z] α Pr [Z = z] 1−α dz . (<label>14</label></formula><formula xml:id="formula_31">)</formula><p>We now define RDP in Definition B.2. RDP provides a strong privacy guarantee that can be converted to classical differential privacy (Lemma B. </p><formula xml:id="formula_32">(α) + log(1/δ) α − 1 . (<label>16</label></formula><formula xml:id="formula_33">)</formula><p>We can now restate in Theorem B.5 the composition theorem of RDP, which is key in designing private iterative algorithms.</p><formula xml:id="formula_34">Theorem B.5 (Mironov 2017, Proposition 1). Let A 1 , . . . , A K : D → F be K &gt; 0 randomized algorithms, such that for 1 ≤ k ≤ K, A k is (α, k (α))-RDP</formula><p>, where these algorithms can be chosen adaptively (i.e., A k can use to the output of</p><formula xml:id="formula_35">A k for all k &lt; k). Let A : D → F K such that for D ∈ D, A(D) = (A 1 (D), . . . , A K (D)).</formula><p>Then A is α,</p><formula xml:id="formula_36">K k=1 k (α) -RDP.</formula><p>Finally, we define the Gaussian mechanism (Definition B.6), as used in Algorithm 1, and restate in Lemma B.7 the privacy guarantees that it satisfies in terms of RDP.</p><p>Definition B.6 (Gaussian mechanism). Let f : D → R p , σ &gt; 0, and D ∈ D. The Gaussian mechanism for answering the query f is defined as:</p><formula xml:id="formula_37">M Gauss f (D; σ) = f (D) + N 0, σ 2 I p . (<label>17</label></formula><formula xml:id="formula_38">)</formula><p>Lemma B.7 (Mironov 2017, Corollary 3). The Gaussian mechanism with noise σ 2 is (α, ∆(f ) 2 α 2σ 2 )-RDP, where ∆(f ) = sup D,D f (D) − f (D ) 2 (for neighboring D, D ) is the sensitivity of f . Proof. The function h = f ∆(f ) has sensitivity 1, thus for any s &gt; 0, the Gaussian mechanism</p><formula xml:id="formula_39">M Gauss h (•; s) is (α, α 2σ 2 )-RDP (Mironov, 2017, Corollary 1). As f = ∆(f )×h, we have M Gauss f (•; σ) = ∆(f )×M Gauss h (•; σ ∆(f ) ). This mechanism is thus (α, ∆(f ) 2 α 2σ 2 )-RDP. Corollary B.8. Let 0 &lt; ≤ 1, 0 &lt; δ &lt; 1 3 . If a randomized algorithm A : D → F is (α, γα<label>2σ</label></formula><p>2 )-RDP with γ &gt; 0 and σ = √ 3γ log(1/δ) for all α &gt; 1, it is also ( , δ)-DP.</p><p>Proof. From Remark B.4 it holds that A is ( , δ)-DP with = min α&gt;1 γα</p><formula xml:id="formula_40">2σ 2 + log(1/δ) α−1</formula><p>. This minimum is attained when the derivative of the objective is zero, which is the case when</p><formula xml:id="formula_41">γ 2σ 2 = log(1/δ) (α−1) 2 , resulting in α = 1 + 2 log(1/δ)σ 2 γ . A is thus ( , δ)-DP with = γ 2σ 2 + γ log(1/δ) √ 2σ + γ log(1/δ) √ 2σ = γ 2σ 2 + 2γ log(1/δ) σ . (<label>18</label></formula><formula xml:id="formula_42">) Choosing σ = √ 3γ log(1/δ) now gives = 2 6 log(1/δ) + 2/3 ≤ (1/6 + 2/3) ≤ ,<label>(19)</label></formula><p>where the first inequality comes from ≤ 1, thus 2 ≤ and δ &lt; 1/3 thus 1 log(1/δ) ≤ 1. The second inequality follows from 1/6 + 2/3 ≈ 0.983 &lt; 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Proof of Theorem 3.1</head><p>We are now ready to prove Theorem 3.1. From the privacy perspective, Algorithm 1 adaptively releases and post-processes a series of gradient coordinates protected by the Gaussian mechanism. We thus start by proving Lemma B.9, which gives an ( , δ)-differential privacy guarantee for the adaptive composition of K Gaussian mechanisms. Lemma B.9. 0 &lt; ≤ 1, δ &lt; 1/3, K &gt; 0, p &gt; 0, and {f k : R p → R} k=K k=1 a family of K functions. The adaptive composition of K Gaussian mechanisms, with the k-th mechanism releasing f k with noise scale</p><formula xml:id="formula_43">σ k = ∆(f k ) √ 3K log(1/δ) is ( , δ)-differentially private.</formula><p>Proof. Let σ &gt; 0. Lemma B.7 guarantees that the k-th Gaussian mechanism with noise scale</p><formula xml:id="formula_44">σ k = ∆(f k )σ &gt; 0 is (α, α<label>2σ</label></formula><p>2 )-RDP. Then, the composition of these K is, according to Theorem B.5, (α, kα 2σ 2 )-RDP. This can be converted to ( , δ)-DP via Corollary B.8 with γ = K, which gives</p><formula xml:id="formula_45">σ k = ∆(f k ) √ 3k log(1/δ) for k ∈ [K].</formula><p>We now restate Theorem 3.1 and prove it.</p><formula xml:id="formula_46">Theorem 3.1. Assume (•; d) is L-component-Lipschitz ∀d ∈ X . Let &lt; 1 and δ &lt; 1/3. If σ 2 j = 12L 2 j T K log(1/δ) n 2 2</formula><p>for all j ∈ [p], then Algorithm 1 satisfies ( , δ)-DP.</p><p>Proof. For j ∈ [1, p], ∇ j f in Algorithm 1 is released using the Gaussian mechanism with noise variance σ 2 j . The sensitivity of</p><formula xml:id="formula_47">∇ j f is ∆(∇ j f ) = ∆(∇j ) n ≤ 2Lj</formula><p>n . Note that T K gradients are released, and</p><formula xml:id="formula_48">σ 2 j = 12L 2 j T K log(1/δ) n 2 2 for j ∈ [1, p] ,</formula><p>thus by Lemma B.9 and the post-processing property of DP, Algorithm 1 is ( , δ)-differentially private.</p><p>C Proof of Utility (Theorem 3.3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Problem Statement</head><p>Let D ∈ X n be a dataset of n elements drawn from a universe X . Recall that we consider the following composite empirical risk minimization problem:</p><formula xml:id="formula_49">w * ∈ arg min w∈R p F (w; D) = 1 n n i=1 (w; d i ) =:f (w;D) +ψ(w) ,<label>(20)</label></formula><p>where (•, d) is convex, L-component-Lipschitz, and M -component-smooth for all d ∈ X , and ψ(w) = p j=1 ψ j (w j ) is convex and separable. We denote by F the complete objective function, and by f its smooth part. For readability, we omit the dependence on their second argument (i.e., the data) in the rest of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Proof of Theorem 3.3</head><p>In this section, we prove our central theorem that guarantees the utility of the DP-CD algorithm. To this end, we start by proving a lemma that upper bounds the expected value of F (θ k+1 ) in Algorithm 1. Using this lemma, we prove sub-linear convergence for the inner loop of DP-CD. This gives the sub-linear convergence of our algorithm for convex losses. Under the additional hypothesis that F is strongly convex, we show that iterates of the outer loop of DP-CD converge linearly towards the (unique) minimum of F . We recall that in Algorithm 1, iterates of the inner loop are denoted by θ 1 , . . . , θ K , and those of the outer loop by w1 , . . . , wT , with wt = 1 K K k=1 θ k for t &gt; 0. Algorithm 1 is randomized in two ways: when choosing the coordinate to update and when drawing noise. For convenience, we denote by E j [•] the expectation w.r.t. the choice of coordinate, by E η [•] the one w.r.t. the noise, and by E j,η [•] the expectation w.r.t. both. When no subscript is used, the expectation is taken over all random variables. We will also use the notation E j,η [•|θ k ] for the conditional expectation of a random variable, given a realization of θ k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2.1 Descent Lemma</head><p>We begin by proving Lemma C.1, which decomposes the change of a function F when updating its argument θ ∈ R p , in relation to a vector w ∈ R p , into two parts: one that remains corresponding to the unchanged entries of θ, and a second part corresponding to the objective decrease due to the update. At this point, the vector w is arbitrary, but we will later choose w to be a minimizer of F , that is a solution to (20).</p><p>Lemma C.1. Let , f, ψ, and F be defined as in Section C.1. Take a random variable θ ∈ R p and two arbitrary vectors w, g ∈ R p . Let a random variable j, taking its values uniformly randomly in [p], Choose γ 1 , . . . , γ p &gt; 0 and Γ = diag(γ 1 , . . . , γ p ). It holds that</p><formula xml:id="formula_50">E j [F (θ − γ j g j e j ) − F (w)|θ] − p − 1 p (F (θ) − F (w)) ≤ 1 p f (θ) − f (w) + ∇f (θ), −Γg + 1 2 Γg 2 M + ψ(θ − Γg) − ψ(w) . (<label>21</label></formula><formula xml:id="formula_51">)</formula><p>Remark C.2. To avoid notational clutter, we will write γ j g j instead of γ j g j e j throughout this section.</p><p>Proof. We start the proof by finding an upper bound on E j [F (θ − γ j g j e j ) − F (w)|θ], using the M -componentsmoothness of f :</p><formula xml:id="formula_52">E j [F (θ − γ j g j e j ) − F (w)|θ] = p j=1 1 p (F (θ − γ j g j ) − F (w))<label>(22)</label></formula><formula xml:id="formula_53">F =f +ψ = 1 p p j=1 f (θ − γ j g j ) − f (w) + ψ(θ − γ j g j ) − ψ(w) (23) f smooth ≤ 1 p p j=1 f (θ) + ∇f (θ), −γ j g j + 1 2 γ j g j 2 M − f (w) + ψ(θ − γ j g j ) − ψ(w) (24) = f (θ) − f (w) + 1 p p j=1 ∇f (θ), −γ j g j + 1 2 γ j g j 2 M + (ψ(θ − γ j g j ) − ψ(w)) (25) = f (θ) − f (w) + 1 p ∇f (θ), −Γg + 1 2p Γg 2 M + 1 p p j=1 (ψ(θ − γ j g j ) − ψ(w)) .<label>(26)</label></formula><p>The regularization terms can now be reorganized using the separability of ψ, as done by Richtárik and Takáč, 2014. Indeed, we notice that</p><formula xml:id="formula_54">p j=1 (ψ(θ − γ j g j ) − ψ(w)) = p j=1 ψ j (θ j − γ j g j ) − ψ j (w j ) + j =j ψ j (θ j ) − ψ(w j ) (27) = ψ(θ − Γg) − ψ(w) + (p − 1)(ψ(θ) − ψ(w)) .<label>(28)</label></formula><p>Plugging ( <ref type="formula" target="#formula_54">28</ref>) in ( <ref type="formula" target="#formula_53">26</ref>) results in the following:</p><formula xml:id="formula_55">E j [F (θ − γ j g j e j ) − F (w)|θ] ≤ f (θ) − f (w) + 1 p ∇f (θ), −Γg + 1 2p Γg 2 M + 1 p (ψ(θ − Γg) − ψ(w)) + p − 1 p (ψ(θ) − ψ(w)) (29) = 1 p f (θ) − f (w) + ∇f (θ), −Γg + 1 2 Γg 2 M + ψ(θ − Γg) − ψ(w) + p − 1 p (f (θ) + ψ(θ) − f (w) − ψ(w)) ,<label>(30)</label></formula><p>which gives the lemma since F = f + ψ.</p><p>To exploit this result, we need to upper bound the right hand side of ( <ref type="formula" target="#formula_50">21</ref>) for the realizations of θ k in Algorithm 1. This is where our proof differs from classical convergence proofs for coordinate descent methods. Namely, we rewrite the right hand side of ( <ref type="formula" target="#formula_50">21</ref>) so as to obtain telescopic terms plus a bias term resulting the addition of noise, as shown in Lemma C.3.</p><p>Lemma C.3. Let , f, ψ, and F defined as in Section C.1. For k &gt; 0, let θ k and k+1 be two consecutive iterates of the inner loop of Algorithm 1, γ 1 = 1 M1 , . . . , γ p = 1 Mp &gt; 0 the coordinate-wise step sizes (where M j are the coordinate-wise smoothness constants of f ), and g j = 1 γj (θ k+1 j − θ k j ). Let w ∈ R p an arbitrary vector</p><p>where we factorized the norm to obtain the last inequality. We can rewrite (42) as an expectation over the random choice of the coordinate j (drawn uniformly in [p]), given the realizations of θ k and of the noise η (which determines g):</p><p>where each inequality comes from the triangle inequality. The non-expansiveness property of the proximal operator (see <ref type="bibr" target="#b42">Parikh and Boyd (2014)</ref>, Section 2.3) is now key to our result, as it yields</p><formula xml:id="formula_56">| g j − g j | = γ −1 j prox γj ψj (θ k j − γ j (∇ j f (θ k ))) − prox γj ψj (θ k j − γ j (∇ j f (θ k ) + η j )) ≤ |η j | ,<label>(55)</label></formula><p>which directly gives, as E η η 2 j = σ 2 j (and</p><formula xml:id="formula_57">σ 2 Γ = p j=1 γ j σ 2 j ), p j=1 γ j E η |η j | | g j − g j | θ k ≤ p j=1 γ j E η [|η j | |η j |] = p j=1 γ j E η η 2 j = σ 2 Γ . (<label>56</label></formula><formula xml:id="formula_58">)</formula><p>We now have everything to prove the lemma by plugging ( <ref type="formula" target="#formula_57">56</ref>) and ( <ref type="formula">53</ref>) into expected value of ( <ref type="formula">52</ref>), and then ( <ref type="formula">52</ref>) and ( <ref type="formula">42</ref>) back into (38) to obtain, after using the Tower property of conditional expectations:</p><formula xml:id="formula_59">1 p E j,η f (θ k ) − f (w) + ∇f (θ k ), −Γg + 1 2 Γg 2 M + ψ(θ k − Γg) − ψ(w) θ k (57) ≤ 1 p ("descent" term + "noise" term) (58) ≤ 1 2 θ k − w 2 Γ −1 − 1 2 E j,η θ k+1 − w 2 Γ −1 θ k + 1 p σ 2 Γ ,<label>(59)</label></formula><p>which is the result of the lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2.2 Convergence Lemma</head><p>Lemma C.3 allows us to prove a result on the mean of K consecutive noisy coordinate-wise gradient updates, by simply summing it and rewriting the terms. This gives Lemma C.4, which is the key lemma of our proof.</p><formula xml:id="formula_60">Lemma C.4. Assume (•, d) is convex, L-component-Lipschitz and M -component-smooth for all d ∈ X , ψ</formula><p>is convex and separable, such that F = f + ψ and w * is a minimizer of F . For t ∈ [T ], consider the K successive iterates θ 1 , . . . , θ K computed from the inner loop of Algorithm 1 starting from the point wt , with step sizes γ j = 1 Mj and noise scales σ j . Letting wt+1 = 1</p><formula xml:id="formula_61">K K k=1 θ k , it holds that E F ( wt+1 ) − F (w * ) ≤ p( wt − w * 2 M + 2(F ( wt ) − F (w * ))) 2K + σ 2 M −1 . (<label>60</label></formula><formula xml:id="formula_62">)</formula><p>Remark C.5. The term F ( wt ) − F (w * ) essentially remains in the inequality due to the composite nature of</p><formula xml:id="formula_63">F . When ψ = 0, M -component-smoothness of f (•; d) (for d ∈ X ) gives f ( wt ) ≤ f (w * ) + ∇f (w * ), wt − w * + 1 2 wt − w * 2 M = f (w * ) + 1 2 wt − w * 2 M ,<label>(61)</label></formula><p>and the result of Lemma C.4 further simplifies as:</p><formula xml:id="formula_64">E F ( wt+1 ) − F (w * ) ≤ p wt − w * 2 M K + σ 2 M −1 . (<label>62</label></formula><formula xml:id="formula_65">)</formula><p>Proof. Summing Lemma C.3 for k = 0 to k = K and w = w * , taking expectation with respect to all choices of coordinate and random noise and using the tower property gives:</p><formula xml:id="formula_66">K−1 k=0 E F (θ ) − F (w * ) − p − 1 p K−1 k=0 E (F (θ k ) − F (w * )) ≤ K−1 k=0 1 2 E θ k − w * 2 Γ −1 − 1 2 E θ k+1 − w * 2 Γ −1 + 1 p σ 2 Γ (63) = 1 2 E w0 − w * 2 Γ −1 − 1 2 E θ K − w * 2 Γ −1 + K p σ 2 Γ . (<label>64</label></formula><formula xml:id="formula_67">) Remark that K−1 k=0 E F (θ k ) − F (w * ) = K k=1 E F (θ k ) − F (w * ) + (F ( w0 ) − F (w * )) − E F (θ K ) − F (w * ) , then as E F (θ K ) − F (w * ) ≥ 0,</formula><p>we obtain a lower bound on the left hand side of (64):</p><formula xml:id="formula_68">K−1 k=0 E F (θ k+1 ) − F (w * ) − p−1 p K−1 k=0 E (F (θ k ) − F (w * )) ≥ 1 p K k=1 E F (θ k ) − F (w * ) − (F ( w0 ) − F (w * )) . (65) As wt+1 = 1 K K k=1 θ k , the convexity of F gives F ( wt+1 ) ≤ 1 K K k=1 F (θ k ) − F (w * ).</formula><p>Plugging this inequality into (65) and combining the result with (64) gives</p><formula xml:id="formula_69">F ( wt+1 ) − F (w * ) ≤ p( 1 2 w0 − w * 2 Γ −1 + F ( w0 ) − F (w * )) K + σ 2 Γ . (<label>66</label></formula><formula xml:id="formula_70">)</formula><p>We conclude the proof by using the fact that</p><formula xml:id="formula_71">Γ j = M −1 j for all j ∈ [p], thus • Γ = • M −1 and • Γ −1 = • M . C.2.3 Convex Case Theorem 3.3 (Convex case). Let w * be a minimizer of F and R 2 M = max( w0 − w * 2 M , F ( w0 ) − F (w * )).</formula><p>The output w priv of DP-CD (Algorithm 1), starting from w0 ∈ R p with T = 1, K &gt; 0 and the σ j 's as in Theorem 3.1, satisfies:</p><formula xml:id="formula_72">F (w priv ) − F (w * ) ≤ 3pR 2 M 2K + 12 L 2 M −1 K log(1/δ) n 2 2 . (<label>67</label></formula><formula xml:id="formula_73">)</formula><formula xml:id="formula_74">Setting K = R M √ pn L M −1 √ 8 log(1/δ) yields: F (w priv ) − F (w * ) ≤ 9 √ p L M −1 R M log(1/δ) n = O √ pR M L M −1 n . (<label>68</label></formula><formula xml:id="formula_75">)</formula><p>Proof. In the convex case, we iterate only once in the inner loop (since T = 1). As such, w priv = w1 , and applying Lemma C.4 with wt+1 = w1 , w t = w0 and σ j chosen as in Theorem 3.1 gives the result. Taking</p><formula xml:id="formula_76">K = R M √ pn L M −1 √ 8 log(1/δ) then gives F ( wt+1 1 ) − F (w * ) ≤ 2 8p log(1/δ) L M −1 R M n + 12 p log(1/δ) L M −1 R M √ 8n ,<label>(69)</label></formula><p>and the result follows from 2 √ 8 + 12 √ 8 ≈ 8.48 &lt; 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2.4 Strongly Convex Case</head><p>Theorem 3.3 (Strongly-convex case). Let F be µ M -strongly convex w.r.t. • M and w * be the minimizer of F . The output w priv of DP-CD (Algorithm 1), starting from w0 ∈ R p with T &gt; 0, K = 2p(1 + 1/µ M ) and the σ j 's as in Theorem 3.1, satisfies:</p><formula xml:id="formula_77">F (w priv ) − F (w * ) ≤ F ( w0 ) − F (w * ) 2 T + 24p(1 + 1/µ M )T L 2 M −1 log(1/δ) n 2 2 . (<label>70</label></formula><formula xml:id="formula_78">)</formula><formula xml:id="formula_79">Setting T = log 2 32n 2 2 (F ( w0 )−F (w * )) p(1+1/µ M ) L 2 M −1 log(1/δ)</formula><p>yields:</p><formula xml:id="formula_80">E F (w priv ) − F (w * ) ≤ 1 + log 2 (F ( w0 ) − F (w * ))n 2 2 24p(1 + 1/µ M ) L 2 M −1 log(1/δ) 24p(1 + 1/µ M ) L 2 M −1 log(1/δ) n 2 2 (71) = O p L 2 M −1 log(1/δ) µ M n 2 2 log 2 (F ( w0 ) − F (w * ))n M p L M −1 log(1/δ) . (<label>72</label></formula><formula xml:id="formula_81">)</formula><p>Proof. As F is µ M -strongly-convex with respect to norm • M , we obtain for any w ∈ R p , that</p><formula xml:id="formula_82">F (w) ≥ F (w * )+ µ M 2 w − w * 2 M . Therefore, F ( w0 ) − F (w * ) ≤ 2 µ M w0 − w * 2 M and Lemma C.4 gives, for 1 ≤ t ≤ T − 1, F ( wt+1 ) − F (w * ) ≤ (1 + 1/µ M )p(F ( wt ) − F (w * )) K + σ 2 M . (<label>73</label></formula><formula xml:id="formula_83">)</formula><p>It remains to set</p><formula xml:id="formula_84">K = 2p(1 + 1/µ M ) to obtain F ( wt+1 ) − F (w * ) ≤ F ( wt ) − F (w * ) 2 + σ 2 M . (<label>74</label></formula><formula xml:id="formula_85">)</formula><p>Recursive application of this inequality gives</p><formula xml:id="formula_86">E F ( wT ) − F (w * ) ≤ F ( w0 ) − F (w * ) 2 T + T −1 t=0 1 2 t σ 2 M ≤ F ( w0 ) − F (w * ) 2 T + 2 σ 2 M ,<label>(75)</label></formula><p>where we upper bound the sum by the value of the complete series. It remains to replace σ 2 M by its value to obtain the result.</p><formula xml:id="formula_87">Taking T = log 2 (F ( w0 )−F (w * ))n 2 2 24p(1+1/µ M ) L 2 M −1 log(1/δ) then gives E F ( wT ) − F (w * ) ≤ 1 + log 2 (F ( w0 ) − F (w * ))n 2 2 24p(1 + 1/µ M ) L 2 M −1 log(1/δ) 24p(1 + 1/µ M ) L 2 M −1 log(1/δ) n 2 2 (76) = O p L 2 M −1 log(1/δ) µ M n 2 2 log 2 (F ( w0 ) − F (w * ))n µ M p L M −1 log(1/δ) ,<label>(77)</label></formula><p>which is the result of our theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Proof of Remark 1</head><p>We recall the notations of <ref type="bibr" target="#b50">Tappenden et al. (2016)</ref>.</p><formula xml:id="formula_88">For θ ∈ R p , t ∈ R and j ∈ [p], let V j (θ, t) = ∇ j (θ)t + Mj 2 |t| 2 +ψ j (θ k j +t). For η ∈ R, we also define its noisy counterpart, V η j (θ, t) = (∇ j (θ)+η)t+ Mj 2 |t| 2 +ψ j (θ k j +t)</formula><p>. We aim at finding δ j such that for any θ k ∈ R p used in the inner loop of Algorithm 1:</p><formula xml:id="formula_89">E ηj V j (θ k , −γ j g j ) ≤ min g∈R V j (θ k , −γ j g) + δ j ,<label>(78)</label></formula><p>where the expectation is taken over the random noise η j , and −γ j g j = prox γj ψj (θ</p><formula xml:id="formula_90">k j − γ j (∇ j f (θ k ) + η j )) − θ k j</formula><p>as defined in the analysis of Algorithm 1. We need to link the proximal operator we use in DP-CD with the V ηj j that we just defined:</p><formula xml:id="formula_91">prox γj ψj (θ k j − γ j (∇ j f (θ k ) + η j )) = arg min v∈R 1 2 v − θ k j + γ j (∇ j f (θ k ) + η j ) 2 2 (79) = arg min v∈R γ j (∇ j f (θ k j ) + η j ), v − θ k j + 1 2 v − θ k j 2 2 + γ j ψ j (v) (80) = arg min v∈R ∇ j f (θ k ) + η j , v − θ k j + M j 2 v − θ k j 2 2 + ψ j (v)<label>(81)</label></formula><formula xml:id="formula_92">= θ k j + arg min t∈R ∇ j f (θ k ) + η j , t + M j 2 t 2 2 + ψ j (θ k j + t) .<label>(82)</label></formula><p>Which means that −γ j g j = prox γj ψj (θ</p><formula xml:id="formula_93">k j − γ j (∇ j f (θ k ) + η j )) − θ k j ∈ arg min t∈R V ηj j (θ k , t). Let −γ j g * j = prox γj ψj (θ k j − γ j ∇ j (θ k )) − θ k j be the non-noisy counterpart of −γ j g j . Since −γ j g j is a minimizer of V ηj j (θ k , •), it holds that V ηj j (θ k , −γ j g j ) ≤ ∇ j f (θ k ) + η j , −γ j g * j + M j 2 −γ j g * j 2 2 + ψ j (θ k j + −γ j g * j )<label>(83)</label></formula><formula xml:id="formula_94">= min t V j (θ k , t) + η j , −γ j g * j ,<label>(84)</label></formula><p>which can be rewritten as</p><formula xml:id="formula_95">V j (θ k , −γ j g j ) ≤ min t V j (θ k , t) + η j , γ j (g j − g * j )</formula><p>. Taking the expectation yields</p><formula xml:id="formula_96">E ηj V j (θ k , −γ j g j ) ≤ min t V j (θ k , t) + E ηj η j , γ j (g j − g * j ) .<label>(85)</label></formula><p>Finally, we remark that g j − g * j ≤ |γ j η j | and the non-expansiveness of the proximal operator gives</p><formula xml:id="formula_97">E ηj j (θ k , −γ j g j ) ≤ min t V j (θ k , t) + γ j σ 2 j ,<label>(86)</label></formula><p>which implies an upper bound on the expectation of δ j :</p><formula xml:id="formula_98">E j,ηj [δ j ] = 1 p p j=1 E ηj [δ j ] ≤ 1 p p j=1 γ j σ 2 j = 1 p p j=1 σ 2 j /M j , when γ j = 1/M j .</formula><p>In the formalism of <ref type="bibr" target="#b50">Tappenden et al. (2016)</ref>, this amounts to setting α = 0</p><formula xml:id="formula_99">and β = 1 p σ 2 M −1 .</formula><p>Convex functions. When the objective function F is convex, we use Lemma C.4 to obtain, since σ</p><formula xml:id="formula_100">2 M −1 = βp, F (w 1 ) − F (w * ) ≤ 2pR 2 M K + σ 2 M −1 = 2pR 2 M K + βp .<label>(87)</label></formula><p>Therefore, when F is convex, we get F (w 1 ) − F (w * ) ≤ ξ, for ξ &gt; βp, as long as</p><formula xml:id="formula_101">2pR 2 M K ≤ ξ − βp, that is K ≥ 2pR 2 M ξ−βp .</formula><p>In comparison, <ref type="bibr">Tappenden et al. (2016, Theorem 5.1 therein)</ref> </p><formula xml:id="formula_102">gives convergence to ξ &gt; 2pR 2 M β when K ≥ 2pR 2 M ξ− √ 2pR 2 M β</formula><p>. We thus gain a factor βp/2R 2 M in utility. Importantly, our utility upper bound does not depend on initialization in that setting, whereas the one of <ref type="bibr" target="#b50">Tappenden et al. (2016)</ref> does.</p><p>Strongly-convex functions. When the objective function F is µ M -strongly-convex w.r.t. to • M , then from (75) we obtain, as long as</p><formula xml:id="formula_103">K ≥ 4/µ M , that E F (w T ) − F (w * ) ≤ F (w 0 ) − F (w * ) 2 T + 2βp .<label>(88)</label></formula><p>This proves that E F (w</p><formula xml:id="formula_104">T ) − F (w * ) ≤ ξ for ξ &gt; 2βp when F (w 0 )−F (w * ) 2 T ≤ ξ −2βp that is T ≥ log F (w 0 )−F (w * ) ξ−2βp and T K ≥ 4p µ M log F (w 0 )−F (w * ) ξ−2βp</formula><p>. In comparison, <ref type="bibr">Tappenden et al. (2016, Theorem 5.2 therein)</ref> shows</p><formula xml:id="formula_105">convergence to ξ &gt; βp µ M for K ≥ p µ M log F (w 0 )−F (w * )− βp µ M ξ− βp µ M</formula><p>. We thus gain a factor µ M /2 in utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Comparison with DP-SGD</head><p>In this section, we provide more details on the arguments of Section 3.4, where we suppose that is Lcomponent-Lipschitz and Λ-Lipschitz. To ease the comparison, we assume that R M = w 0 − w * M , which is notably the case in the smooth setting with ψ = 0 (see Remark C.2).</p><p>Balanced. We start by the scenario where coordinate-wise smoothness constants are balanced and all equal to</p><formula xml:id="formula_106">M = M 1 = • • • = M p . We observe that L M −1 = p j=1 1 M j L 2 j = 1 M p j=1 L 2 j = 1 √ M L 2 . (<label>89</label></formula><formula xml:id="formula_107">)</formula><p>We then consider the convex and strongly-convex functions separately:</p><formula xml:id="formula_108">• Convex functions: it holds that R M = √ M R , which yields the equality L M −1 R M = L 2 R I . • Strongly convex functions: if f is µ M -strongly-convex with respect to • M , then for any x, y ∈ R p , f (y) ≥ f (x) + ∇f (x), y − x + µ M 2 y − x 2 M = f (x) + ∇f (x), y − x + M µ M 2 y − x 2 2 ,<label>(90)</label></formula><p>which means that f is M µ M -strongly-convex with respect to • 2 . This gives</p><formula xml:id="formula_109">L 2 M −1 µ M = L 2 2 /M µ I /M = L 2 2 µ I .</formula><p>In light of the results summarized in Table <ref type="table" target="#tab_0">1</ref>, it remains to compare L 2 = p j=1 L 2 j with Λ, for which it holds that Λ ≤ p j=1 L 2 j ≤ √ pΛ, which is our result.</p><p>Unbalanced. When smoothness constants are disparate, we discuss the case where</p><p>• one coordinate of the gradient dominates the others: we assume without loss of generality that the dominating coordinate is the first one. It holds that M 1 =: M max M min =: M j , for all j = 1 and</p><formula xml:id="formula_110">L 1 =: L max L min =: L j , for all j = 1 such that L 2 1 M1 j =1 L 2 j Mj .</formula><p>As L 1 dominates the other component-Lipschitz constants, most of the variation of the loss comes from its first coordinate. This implies that L 1 is close to the global Lipschitz constant Λ of . As such, it holds that</p><formula xml:id="formula_111">L 2 M −1 = p j=1 L 2 j M j ≈ L 2 1 M 1 ≈ Λ 2 M max .<label>(91)</label></formula><p>• the first coordinate of w0 is already very close to its optimal value so that</p><formula xml:id="formula_112">M 1 w0 1 − w * 1 j =1 M j w0 j − w * j . Under this hypothesis, R 2 M ≈ j =1 M j w 0 j − w * j 2 = M min j =1 w 0 j − w * j 2 ≈ M min R 2 I .<label>(92)</label></formula><p>We can now easily compare DP-CD with DP-SGD in this scenario. First, if is convex, then</p><formula xml:id="formula_113">L M −1 R M ≈ Mmin Mmax ΛR I .</formula><p>Second, when is strongly-convex, we observe that for x, y ∈ R p ,</p><formula xml:id="formula_114">f (y) ≥ f (x) + ∇f (x), y − x + µ M 2 y − x 2 M ≥ f (x) + ∇f (x), y − x + M min µ M 2 y − x 2 2 ,<label>(93)</label></formula><p>which implies that when f is µ M strongly-convex with respect to • M , it is M min µ M strongly-convex with respect to • 2 . This yields, under our hypotheses,</p><formula xml:id="formula_115">L 2 M −1 µ M ≈ Λ 2 /Mmax µ I /Mmin = Mmin Mmax Λ 2 µ I .</formula><p>In both cases, DP-CD can get arbitrarily better than DP-SGD, and gets better as the ratio M max /M min increases.</p><p>The two hypotheses we describe above are of course very restrictive. However, it gives some insight about when and why DP-CD can outperform DP-SGD. Our numerical experiments in Section 6 confirm this analysis, even in less favorable cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof of Lower Bounds</head><p>To prove lower bounds on the utility of L-component-Lipschitz functions, we extend the proof of <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> to our setting (that is, L-component-Lipschitz functions and unconstrained composite optimization). There are three main difficulties in adapting their proof:</p><p>• First, the optimization problem (1) is not constrained. We stress that while convex constraints can be enforced using the regularizer ψ (using the characteristic function of a convex set), its separable nature only allows box constraints. In contrast, <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> rely on an 2 -norm constraint to obtain their lower bounds.</p><p>• Second, Lemma 5.1 of <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> must be extended to our L-component-Lipschitz setting. To do so, we consider datasets with points in p j=1 {−L j , L j } rather than {−1/ √ p, 1/ √ p} p , and carefully adapt the construction of the dataset D so that</p><formula xml:id="formula_116">n i=1 d i 2 = Ω(min(n L 2 , √ p L 2 /</formula><p>)), which is essential to prove our lower bounds.</p><p>• Third, the lower bounds of <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> rely on fingerprinting codes, and in particular on the result of <ref type="bibr" target="#b10">Bun et al. (2014)</ref> which uses such codes to prove that (when n is smaller than some n * we describe later) differential privacy is incompatible with precisely and simultaneously estimating all p counting queries defined over the columns of the dataset D. In our construction, since all columns of D now have different scales, we need an additional hypothesis on the repartition of the L j 's, (i.e., that j∈J L 2 j = Ω( L 2 ) for all J ⊆ [p] of a given size), which is not required in existing lower bounds (where all columns have equal scale).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Counting Queries and Accuracy</head><p>We start our proof by recalling and extending to our setting the notions of counting queries (Definition E.1) and accuracy (Definition E.2), as described by <ref type="bibr" target="#b10">Bun et al. (2014)</ref>. The main feature of our definitions is that we allow the set X to have different scales for each of its coordinates, and that we account for this scale in the definition of accuracy. We denote by conv(X ) the convex hull of a set X . Definition E.1 (Counting query). Let n &gt; 0. A counting query on X is a function q : X n → conv(X ) defined using a predicate q : X → X . The evaluation of the query q over a dataset D ∈ X n is defined as the arithmetic mean of q on D:</p><formula xml:id="formula_117">q(D) = 1 n n i=1 q(d ) . (<label>94</label></formula><formula xml:id="formula_118">)</formula><p>Definition E.2 (Accuracy). Let n, p ∈ N, α, β ∈ [0, 1], L 1 , . . . , L p &gt; 0, and X = p j=1 {−L j ; L j } or X = {0, L j } p . Let Q = {q 1 , . . . , q p } be a set of p counting queries on X and D ∈ X n a dataset of n elements. A sequence of answers a = (a 1 , . . . , a p ) is said (α, β)-accurate for</p><formula xml:id="formula_119">Q if |q j (D) − a j | ≤ L j α for at least a 1 − β fraction of indices j ∈ [p]. A randomized algorithm : X n → R |Q| is said (α, β)-accurate for Q on X if for every D ∈ X n , Pr [A(D) is (α, β)-accurate for Q] ≥ 2/3 . (<label>95</label></formula><formula xml:id="formula_120">)</formula><p>In our proof, we will use a specific class of queries: one-way marginals (Definition E.3), that compute the arithmetic mean of a dataset along one of its column.</p><p>Definition E.3 (One-way marginals). Let X = p j=1 {−L j ; L j } or X = {0, L j } p . The family of one-way marginals on X is defined by queries with predicates q j (x) = x j for x ∈ X . For a dataset D ∈ X n of size n, we thus have q j (D) = 1 n n i=1 d i,j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Lower Bound for One-Way Marginals</head><p>We can now restate a key result from <ref type="bibr" target="#b10">Bun et al. (2014)</ref>, which shows that there exists a minimal number n * of records needed in a dataset to allow achieving both accuracy and privacy on the estimation of one-way marginals on X = ({0, 1} p ) n . This lemma relies on the construction of re-identifiable distribution (see <ref type="bibr">Bun et al. 2014, Definition 2.10)</ref>. One can then use this distribution to find a dataset on which a private algorithm can not be accurate (see <ref type="bibr">Bun et al. 2014, Lemma 2.11)</ref>.</p><p>Lemma E.4 <ref type="bibr">(Bun et al. Corollary 3.6)</ref>. For &gt; 0 and p &gt; 0, there exists a number n * Ω( √ p ) such that for all n ≤ n * , there exists no algorithm that is both (1/3, 1/75)-accurate and ( , o 1 n )-differentially private for the estimation of one-way marginals on ({0, 1} p ) n .</p><p>To leverage this result in our setting of private empirical risk minimization, we start by extending it to queries on X = p j=1 {−L j ; L j }. Before stating the main theorem of this section (Theorem E.5), we describe a procedure χ L : ({0, 1} p ) n → X 3n (with L 1 , . . . , L p &gt; 0), that takes as input a dataset D ∈ ({0, 1} p ) n and outputs an augmented and rescaled version. This procedure is crucial to our proof and is defined as follows. First, it adds 2n rows filled with 1's to D, which ensures that the sum of each column of D is Θ(n) (which gives the lower bound on M in Theorem E.5). Then it rescales each of these columns by subtracting 1/2 to each coefficient and multiplying the j-th column of D (j ∈ [p]) by 2L j . The resulting dataset D aug L = χ L (D) is a set of 3n points with values in X = p j=1 {−L j , L j }, with the property that, for all j ∈ [p], 3nL j ≥ n i=1 (D aug L ) i,j ≥ nL j . For D ∈ ({0, 1} p ) n , we show how to reconstruct q j (χ L (D)) from q j (D) in Claim 1.</p><p>Claim 1. Let n ∈ N, j ∈ [p], L j &gt; 0 and q j the j-th one-way marginal on datasets D with p columns such that for d i ∈ D, q j (d i ) = d i,j . Let D aug L = χ L (D). It holds that</p><formula xml:id="formula_121">q j (D aug L ) = 2L j 3 q j (D) + L j 3 ,<label>(96)</label></formula><p>where we use the slight abuse of notation by denoting the one-way marginals q j : X 3n → conv(X ) and q j : ({0, 1} p ) n → [0, 1] p in the same way.</p><p>Proof. Let D ∈ ({0, 1} p ) n , and let D aug ∈ ({0, 1} p ) 3n constructed by adding 2n rows of 1's at the end of D. Let D aug L = χ L (D). We remark that</p><formula xml:id="formula_122">q j (D aug ) = 1 3n 3n i=1 D aug i,j = 1 3 1 n n i=1 D aug i,j + 1 3n 3n i=n+1 1 = 1 3 q j (D) + 2 3 ∈ [0, 1] .<label>(97)</label></formula><p>Then, we link q j (D aug ) with q j (D aug L ):</p><formula xml:id="formula_123">q j (D aug L ) = 1 3n 3n i=1 (D aug L ) i,j = 1 3n 3n i=1 2L j ((D aug ) i,j − 1/2) = 2L j (q j (D aug ) − 1/2) ∈ [−L j , L j ] ,<label>(98)</label></formula><p>combining ( <ref type="formula" target="#formula_122">97</ref>) and ( <ref type="formula" target="#formula_123">98</ref>) gives the result.</p><p>Theorem E.5. Let n, p ∈ N, and L 1 , . . . , L p &gt; 0. Assume that for all subsets J ⊆ [p] of size at least p 75 , j∈J L 2 j = Ω( L 2 ). Define X = p j=1 {−L j ; +L j }, and let q j : X → {−L j , L j } be the predicate of the j-th one-way marginal on X . Take &gt; 0 and δ = o( 1 n ). There exists a number M = Ω min n L 2 , √ p L 2 such that for every ( , δ)-differentially private algorithm A, there exists a dataset D = {d 1 , . . . , d n } ∈ X n with n i=1 d i 2 ∈ [M − 1, M + 1] such that, with probability at least 1/3 over the randomness of A:</p><formula xml:id="formula_124">A(D) − q(D) 2 = Ω min L 2 , √ p L 2 n . (99) Proof. Let M = Ω min n L 2 , √ p L 2</formula><p>, and define the set of queries Q composed of p queries q j = 1 n n i=1 d i,j for j ∈ [p]. Let A be a , δ)-differentially-private randomized algorithm. Let α, β ∈ [0, 1]. We will show that there exists a dataset D such that</p><formula xml:id="formula_125">n i=1 d i 2 ∈ [M − 1, M + 1] for which A(D) is not (α, β)-accurate.</formula><p>When n ≤ n * . Assume, for the sake of contradiction, that A :</p><formula xml:id="formula_126">X 3n → conv(X ) is ( 1 3 α, β)-accurate for Q. Then, for each dataset D ∈ X 3n , we have Pr ∃J ⊆ [p] such that |J | ≥ (1 − β)p and ∀j ∈ J , |A j (D ) − q j (D )| &lt; 2L j 3 α ≥ 2/3 .<label>(100)</label></formula><p>Importantly, for all D ∈ ({0, 1}) p ) n , the randomized algorithm A satisfies (100) for the dataset</p><formula xml:id="formula_127">D aug L = χ L (D) ∈ X 3n . We now construct the mechanism A : ({0, 1} p ) n → [0, 1] p that takes a dataset D ∈ ({0, 1} p ) n , constructs D aug L = χ L (D) and runs A on it. It then outputs A(D) such that, for j ∈ [p], A j (D) = 3 2Lj A j (D aug L ) − Lj 3 .</formula><p>Using Claim 1, the results of A and be linked to the ones of A, as</p><formula xml:id="formula_128">A(D) − q j (D) = 3 2L j A j (D aug L ) − L j 3 − 3 2L j q j (D aug L ) + L j 3 = 3 2L j |A j (D aug L ) − q j (D aug L )| .<label>(101)</label></formula><p>Therefore, if A satisfies ( <ref type="formula" target="#formula_126">100</ref>) and ( <ref type="formula" target="#formula_128">101</ref>), then A :</p><formula xml:id="formula_129">({0, 1} p ) n → [0, 1] p satisfies, for all D ∈ ({0, 1} p ) n , Pr ∃J ⊆ [p] such that |J | ≥ (1 − β)p and ∀j ∈ J , A j (D) − q j (D) &lt; α ≥ 2/3 ,<label>(102)</label></formula><p>which is exactly the definition of (α, β)-accuracy for A. Remark that since A is only a post-processing of A, without additional access to the dataset itself, A is itself ( , δ)-differentially-private. We have thus constructed an algorithm that is both accurate and private for n ≤ n * , which contradicts the result of Lemma E.4 when β = 1 75 . This proves the existence of a dataset D ∈ ({0, 1} p ) n such that for D aug L = χ L (D), A(D aug L ) is not ( 1 3 α, β)-accurate on Q, which means that with probability at least 1/3, there exists a subset J ⊆</p><formula xml:id="formula_130">[p] of cardinal |J | ≥ βp such that A(D aug L ) − q(D aug L ) 2 (100) ≥ j∈J 4L 2 j 9 ≥ Ω( L 2 ) ,<label>(103)</label></formula><p>where the second inequality comes from the fact that |J | ≥ βp = p 75 and our hypothesis on j∈J L 2 j . Notice that when L</p><formula xml:id="formula_131">1 = • • • = L p = 1</formula><p>√ p , we recover the result of <ref type="bibr" target="#b7">Bassily et al. (2014)</ref>, since L 2 = 1 it holds with probability at least 1/3 that</p><formula xml:id="formula_132">A(D aug L ) − q(D aug L ) 2 (100) ≥ j∈J 4L 2 j 9 ≥ 4 9 × 75 L 2 ≥ 2 27 ,<label>(104)</label></formula><p>and in that case, since all L j 's are equal, it indeed holds that j∈J L 2 j = Ω( L 2 ). Finally, we remark that the sum of each column of D aug L is n i=1 d i,j ≥ nL j , and as such, we have</p><formula xml:id="formula_133">n i=1 d i 2 = p j=1 ( n i=1 d i,j ) 2 ≥ p j=1 n 2 L 2 j = n L 2 .</formula><p>When n &gt; n * . We get the result in that case by augmenting the dataset D * that we constructed in the first part of this proof. To do so, we follow the steps described by <ref type="bibr" target="#b7">Bassily et al. (2014)</ref>  Remark E.6. Without the assumption on the distribution of the L j 's, we can still get an inequality that resembles (103):</p><formula xml:id="formula_134">A(D aug L ) − q(D aug L ) 2 (100) ≥ j∈J 4L 2 j 9 ≥ 2 27 Lmin</formula><p>Lmax L 2 , with probability at least 1/3, and we get a result similar to Theorem E.5, except with an additional multiplicative factor L min /L max . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Lower Bound for Convex Functions</head><formula xml:id="formula_135">w * = arg min w∈R p F (w; D) = − 1 n w, n i=1 d i + n i=1 d i 2 βn w 2 2 ,<label>(105)</label></formula><p>To find the solution of (105), we look for w * so that the objective's gradient is zero, that is</p><formula xml:id="formula_136">w * = β n i=1 d i 2 n i=1 d i ,<label>(106)</label></formula><formula xml:id="formula_137">so that w * 2 = β n i=1 di 2 n i=1 d i 2 = β.</formula><p>To prove the lower bound, we remark that</p><formula xml:id="formula_138">F (w; D) − F (w * ; D) = − 1 n w − w * , n i=1 d i + n i=1 d i 2βn ( w 2 − w * 2 2 ) (107) = − 1 n w − w * , n i=1 d i β w * + n i=1 d i 2βn ( w 2 2 − w * 2 2 ) (108) = n i=1 d i βn w * − w, w * + 1 2 w 2 2 − 1 2 w * 2 2 (109) = n i=1 d i βn − w, w * + 1 2 w 2 2 + 1 2 w * 2 2 (110) = n i=1 d i 2βn w − w * 2 2 . (<label>111</label></formula><formula xml:id="formula_139">)</formula><p>At this point, we can proceed similarly to <ref type="bibr" target="#b7">Bassily et al. (2014)</ref> to relate this quantity to private estimation of one-way marginals. We let M = Ω(min(n L 2 , L 2 √ p/ )) and A be an ( , δ)-differentially private mechanism that outputs a private solution w priv to (105). Suppose, for the sake of contradiction, that for every dataset D with</p><formula xml:id="formula_140">n i=1 d i 2 ∈ [M − 1; M + 1],</formula><p>it holds with probability at least 2/3 that</p><formula xml:id="formula_141">w priv − w * = Ω(β) .<label>(112)</label></formula><p>We now derive from A a mechanism A to estimate one-way marginals. To do this, A runs A to obtain w priv and outputs M nβ w priv . We obtain that with probability at least 2/3,</p><formula xml:id="formula_142">A(D) − q(D) 2 = M nβ w priv − β M n i=1 d i 2 = Ω M n = Ω min L 2 , L 2 √ p n .<label>(113)</label></formula><p>where q(D) = 1 n n i=1 d i . This is in contradiction with Theorem E.5. We thus proved that w priv − w * = Ω(β), with probability at least 1/3. As a consequence, we now obtain that with probability at least 1/3,</p><formula xml:id="formula_143">F (w priv ; D) − F (w * ; D) = n i=1 d i 2βn w priv − w * 2 2 = Ω min L 2 β, β L 2 √ p n ,<label>(114)</label></formula><p>which gives the desired result on the expectation of F (w priv ; D) − F (w * ; D).</p><p>Finally, if we do not make any hypothesis on the L j 's distribution, we can directly use the non-augmented dataset constructed by <ref type="bibr" target="#b10">Bun et al. (2014)</ref> to prove Lemma E.4 (that is the dataset from Theorem E.5, rescaled but not augmented). The 2 -norm of the sum of this dataset is</p><formula xml:id="formula_144">n i=1 d j 2 = [M − 1, M + 1] with M = Ω min Lmin Lmax n L 2 , Lmin Lmax √ p L 2</formula><p>. This holds since four columns of this dataset out of five have sum of ±nL j (for some j's), but no lower bound on the sum of the remaining columns can be derived. Thus, assuming (112) holds, then (113) can be rewritten as</p><formula xml:id="formula_145">A(D) − q(D) 2 = M nβ w priv − β M n i=1 d i 2 = Ω M n = Ω min L min L max L 2 , L min L max L 2 √ p n ,<label>(115)</label></formula><p>with probability at least 1/3, which is in contradiction with Remark E.6. We thus get an additional factor of L min /L max in lower bound:</p><formula xml:id="formula_146">F (w priv ; D) − F (w * ; D) = n d i 2βn w priv − w * 2 2 = Ω min L min L max L 2 β, L min L max β L 2 √ p n .<label>(116)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Lower Bound for Strongly-Convex Functions</head><p>To prove a lower bound for strongly-convex functions, we let µ I &gt; 0, L 1 , . . . , L p &gt; 0, W =  thresholds as well (see Section 5.1). For DP-SGD, the step size is given by γ/β, where γ is the hyperparameter and β is the problem's global smoothness constant (which we consider given), and the clipping threshold is used directly to clip gradients along their 2 -norm.</p><p>We simultaneously tune these three hyperparameters for each algorithm across the following grid:</p><p>• step size: 10 logarithmically-spaced values between 10 −6 and 1 for DP-SGD, and between 10 −2 and 10 for DP-CD. 7</p><p>• clipping threshold: 100 values, between 10 −3 and 10 6 .</p><p>• number of passes: 5 values (2, 5, 10, 20 and 50).</p><p>We run each algorithm on each dataset 5 times on each combination of hyperparameter values. We then keep the set of hyperparameters that yield the lowest value of the objective at the last iterate, averaged across the 5 runs.</p><p>In Table <ref type="table" target="#tab_1">2</ref>, we report the best relative error (in comparison to optimal objective value) at the last iterate, averaged over five runs, for each dataset, algorithm, and total number of passes on the data. As such, each cell of this table corresponds to the best value obtained after tuning the step size and clipping hyperparameters for a given number of passes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 Running Time</head><p>In this section, we report the running times of DP-CD and DP-SGD. We implemented DP-CD and DP-SGD in C++, with Python bindings 8 . The design matrix and the labels are kept in memory as dense matrices of the Eigen library. No special code optimization nor tricks is applied to the algorithms, except for the update of residuals at each iteration of DP-CD, which prevents from accessing the complete dataset at each step. All experiments were run on a laptop with 16GB of RAM and an Intel(R) Core(TM) i7-10610U CPU @ 1.80GHz.</p><p>Figure <ref type="figure">3</ref> shows the same experiments as in Figure <ref type="figure" target="#fig_4">1</ref> and Figure <ref type="figure">2</ref>, but as a function of the running time. In our implementation, DP-CD runs about 4 times as fast as DP-SGD for a given of iterations (see Figure <ref type="figure">3a</ref> and Figure <ref type="figure">3b</ref> for 50 iterations). On the three other plots, Figure <ref type="figure">3c</ref>, Figure <ref type="figure">3d</ref> and Figure <ref type="figure">3e</ref>, DP-CD yields better results in less iterations. DP-CD is thus particularly valuable in these scenarios: combined with its faster running time, it provides accurate results extremely fast. For completeness, we provide in Table <ref type="table" target="#tab_2">3</ref> Relative Error to Non-Private Opt Figure <ref type="figure">3</ref>: Relative error to non-private optimal for DP-CD (blue, round marks), DP-CD with privately estimated coordinate-wise smoothness constants (green, + marks) and DP-SGD (orange, triangle marks) on five problems. We report average, minimum and maximum values over 10 runs for each algorithm, as a function of the algorithm running time (in seconds).</p><p>the full table of running time, corresponding to Table <ref type="table" target="#tab_2">2 and Figure 3</ref>. These results show that, for a given number of passes on the data, DP-CD consistently runs about 5 times faster than DP-SGD. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>DP-SCO.Recent work has also studied algorithms and utility guarantees for stochastic convex optimization under differential privacy constraints, a problem very similar to DP-ERM.<ref type="bibr" target="#b4">Bassily et al. (2019)</ref> (following work from<ref type="bibr" target="#b26">Hardt et al., 2016;</ref><ref type="bibr" target="#b3">Bassily et al., 2020)</ref> extended results known for DP-ERM to this setting, showing that the population risk of DP-SCO is asymptotically equivalent to the one of non-private SCO. Efficient algorithms for DP-SCO were proposed by<ref type="bibr" target="#b21">Feldman et al. (2020)</ref> and<ref type="bibr" target="#b56">Wang et al. (2022), and</ref><ref type="bibr" target="#b1">Asi et al. (2021)</ref> and<ref type="bibr" target="#b5">Bassily et al. (2021)</ref> studied stochastic variants of DP-FW. As detailed by<ref type="bibr" target="#b17">Dwork et al. (2015)</ref>,<ref type="bibr" target="#b6">Bassily et al. (2016), and</ref><ref type="bibr" target="#b29">Jung et al. (2021)</ref> results from DP-ERM can be converted to DP-SCO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>∇</head><label></label><figDesc>j (w; d) 2 ≤ (w + ∇ j (w; d)e j ; d) − (w; d) ≤ | (w + ∇ j (w; d)e j ; d) − (w; d)| ≤ L j |∇ j (w; d)| , (10) and we get the result after dividing by |∇ j (w; d)|.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition B. 1 (</head><label>1</label><figDesc>Rényi divergence, van Erven and Harremoës 2014). For two random variables Y and Z with values in the same domain C, the Rényi divergence is, for α &gt; 1,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>3 and Corollary B.8). Definition B.2 (Rényi Differential Privacy, Mironov 2017). A randomized algorithm A : D → F is (α, )-Rényi-differentially private (RDP) if, for all all datasets D, D ∈ D differing on at most one element, D α (A(D)||A(D )) ≤ . (15) Lemma B.3 (Mironov 2017, Proposition 3). If a randomized algorithm A : D → F is (α, )-RDP, then it is ( + log(1/δ) α−1 , δ)-differentially private for all 0 &lt; δ &lt; 1. Remark B.4. The above (α, )-RDP guarantees hold for multiple values of α, . As such, = (α) can be seen as a function of α, and Lemma B.3 ensures that the algorithm is ( , δ)-DP for = min α&gt;1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>in the proof of their Lemma 5.1. The construction consists in choosing a c ∈ X , and adding n−n * 2 rows with c, and n−n * 2 rows with −c to the dataset D * . This results in a dataset D such that n i=1d i = Ω(n * L 2 ) = Ω( √ p L 2 ),since the contributions of rows −c and c (almost) cancel out. The theorem follows from observing that ( n * n α, β)-accuracy on this augmented dataset implies (α, β)-accuracy on the original dataset. As such, if an algorithm is both private and ( n * n α, β)-accurate on the dataset D , we get a contradiction, which gives the theorem as n * n =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>To prove a lower bound for our problem in the convex case, we let L 1 , • • • , L p &gt; 0 and define a dataset D = {d 1 , . . . , d n } taking its values in a set X = p j=1 {±L j }. For β &gt; 0, we consider the problem (1) with the convex, smooth and L-component-Lipschitz loss function (w; d) = − w, d and the convex, separable regularizer ψ(w) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>F</head><label></label><figDesc>and D = {d 1 , . . . , d n } ∈ p j=1 {± Lj 2µ I }. We consider the following problem, which fits in our setting: w * = arg min w∈R p i W is the (separable) characteristic function of the set W. Since ψ = i W is the characteristic function of a box-set, the proximal operator is equal to the projection on W and DP-CD iterates are thus guaranteed to remain in W. Therefore, regularity assumptions on f only need to hold on W, as pointed out in Remark 2.1. The loss function (w; d i ) = µ I 2 w − d i 2 2 is L-component-Lipschitz on W since, for w ∈ W and j ∈ [p], the triangle inequality gives: |∇ j (w; d i )| ≤ µ I (|w j | + |d i,j |) ≤ µ I also µ I -strongly convex w.r.t. -norm since for w, w ∈ W, (w; d i ) = µ w − d i , w − w + w − w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Utility guarantees for DP-CD, DP-SGD, and DP-SVRG for L-component-Lipschitz, Λ-Lipschitz loss.</figDesc><table><row><cell>Convex</cell><cell>Strongly-convex</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Relative error to non-private optimal value of the objective function for different number of passes on the data. Results are reported for each dataset and for DP-CD and DP-SGD, after tuning step size and clipping hyperparameters. A star indicates the lowest error in each row.</figDesc><table><row><cell></cell><cell>Passes on data</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell>Electricity (imbalanced)</cell><cell>DP-CD</cell><cell>0.1458 ± 6e-04</cell><cell>0.0842 ± 1e-03</cell><cell>0.0436 ± 2e-03</cell><cell>0.0147 ± 2e-03</cell><cell>0.0020 ± 1e-03*</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.2047 ± 2e-02</cell><cell>0.1804 ± 2e-02</cell><cell>0.1766 ± 2e-02</cell><cell>0.1644 ± 2e-02</cell><cell>0.1484 ± 1e-02*</cell></row><row><cell>Electricity (balanced)</cell><cell>DP-CD</cell><cell>0.0186 ± 4e-04</cell><cell>0.0023 ± 4e-04</cell><cell>0.0013 ± 6e-04*</cell><cell>0.0013 ± 4e-04</cell><cell>0.0019 ± 8e-04</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0391 ± 1e-02</cell><cell>0.0189 ± 5e-03</cell><cell>0.0123 ± 4e-03</cell><cell>0.0106 ± 3e-03</cell><cell>0.0040 ± 2e-03*</cell></row><row><cell>California (imbalanced)</cell><cell>DP-CD</cell><cell>0.1708 ± 7e-03</cell><cell>0.1232 ± 1e-02</cell><cell>0.0598 ± 1e-02</cell><cell>0.0287 ± 5e-03</cell><cell>0.0124 ± 7e-03*</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.2799 ± 9e-02</cell><cell>0.1863 ± 2e-02</cell><cell>0.1476 ± 2e-02</cell><cell>0.1094 ± 2e-02</cell><cell>0.1068 ± 2e-02*</cell></row><row><cell>California (balanced)</cell><cell>DP-CD</cell><cell>0.0007 ± 3e-04*</cell><cell>0.0011 ± 6e-04</cell><cell>0.0012 ± 5e-04</cell><cell>0.0010 ± 1e-04</cell><cell>0.0017 ± 1e-03</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0351 ± 2e-02</cell><cell>0.0226 ± 8e-03</cell><cell>0.0125 ± 3e-03</cell><cell>0.0087 ± 2e-03</cell><cell>0.0042 ± 1e-03*</cell></row><row><cell>Sparse LASSO</cell><cell>DP-CD</cell><cell>0.2498 ± 4e-02*</cell><cell>0.4702 ± 9e-02</cell><cell>0.5982 ± 4e-02</cell><cell>0.7160 ± 2e-02</cell><cell>0.7551 ± 0e+00</cell></row><row><cell>= 10, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.7551 ± 0e+00</cell><cell>0.7551 ± 3e-09*</cell><cell>0.7551 ± 0e+00</cell><cell>0.7551 ± 0e+00</cell><cell>0.7551 ± 0e+00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Time of execution (in seconds) for different number of passes on the data (averaged over 10 runs). Results are reported for each dataset and for DP-CD and DP-SGD, after tuning step size and clipping hyperparameters.</figDesc><table><row><cell></cell><cell>Passes on data</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>50</cell></row><row><cell>Electricity (imbalanced)</cell><cell>DP-CD</cell><cell>0.0128 ± 1e-03</cell><cell>0.0274 ± 1e-03</cell><cell>0.0500 ± 1e-03</cell><cell>0.0980 ± 7e-04</cell><cell>0.2457 ± 2e-03</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0663 ± 2e-03</cell><cell>0.1722 ± 1e-02</cell><cell>0.3321 ± 1e-02</cell><cell>0.6729 ± 1e-02</cell><cell>1.8588 ± 2e-01</cell></row><row><cell>Electricity (balanced)</cell><cell>DP-CD</cell><cell>0.0121 ± 7e-04</cell><cell>0.0281 ± 3e-03</cell><cell>0.0529 ± 2e-03</cell><cell>0.1062 ± 6e-03</cell><cell>0.2577 ± 2e-03</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0686 ± 4e-03</cell><cell>0.1768 ± 1e-02</cell><cell>0.3578 ± 2e-02</cell><cell>0.6787 ± 2e-02</cell><cell>1.6766 ± 2e-02</cell></row><row><cell>California (imbalanced)</cell><cell>DP-CD</cell><cell>0.0029 ± 9e-05</cell><cell>0.0065 ± 8e-05</cell><cell>0.0130 ± 1e-04</cell><cell>0.0258 ± 1e-04</cell><cell>0.0647 ± 2e-04</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0269 ± 1e-03</cell><cell>0.0665 ± 1e-03</cell><cell>0.1318 ± 2e-03</cell><cell>0.2628 ± 3e-03</cell><cell>0.6476 ± 8e-03</cell></row><row><cell>California (balanced)</cell><cell>DP-CD</cell><cell>0.0031 ± 2e-04</cell><cell>0.0065 ± 2e-04</cell><cell>0.0132 ± 1e-04</cell><cell>0.0262 ± 2e-04</cell><cell>0.0649 ± 3e-04</cell></row><row><cell>= 1, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0261 ± 7e-04</cell><cell>0.0641 ± 5e-04</cell><cell>0.1295 ± 2e-03</cell><cell>0.2592 ± 4e-03</cell><cell>0.6469 ± 7e-03</cell></row><row><cell>Sparse LASSO</cell><cell>DP-CD</cell><cell>0.0244 ± 6e-04</cell><cell>0.0760 ± 6e-04</cell><cell>0.1614 ± 4e-03</cell><cell>0.3213 ± 5e-04</cell><cell>0.6598 ± 1e-02</cell></row><row><cell>= 10, δ = 1/n 2</cell><cell>DP-SGD</cell><cell>0.0718 ± 3e-03</cell><cell>0.1788 ± 4e-03</cell><cell>0.3654 ± 7e-03</cell><cell>0.7292 ± 2e-02</cell><cell>1.8110 ± 3e-02</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In fact, our privacy guarantees hold even if all intermediate iterates are released (not just the final model).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://gitlab.inria.fr/pmangold1/private-coordinate-descent/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Recall that step sizes for CD algorithms are coordinate-wise, and thus larger than in SGD algorithms. We empirically verify that the best step size always lies strictly inside the considered interval for both DP-CD and DP-SGD.8 The code is available at https://gitlab.inria.fr/pmangold1/private-coordinate-descent/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers who provided useful feedback on previous versions of this work, which helped to improve the paper. This work was supported in part by the Inria Exploratory Action FLAMED and by the French National Research Agency (ANR) through grant ANR-20-CE23-0015 (Project PRIDE) and ANR-20-CHIA-0001-01 (Chaire IA CaMeLOt).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">(46)</ref> <p>Upper bounding the "noise" term. We now upper bound the "noise" term in <ref type="bibr">(38)</ref>. We first recall the definition of the noisy proximal update g j (line 7 of Algorithm 1), and define its non-noisy counterpart gj :</p><p>For an update of the coordinate j ∈ [p], the optimality condition of the proximal operator gives, for η j the realization of the noise drawn at the current iteration when coordinate j is chosen:</p><p>As such, there exists a real number v j ∈ ∂ψ j (θ k j − γ j g j ) such that g j = − 1 γj (θ k+1 j − θ k j ) = ∇ j f (θ k ) + η j + v j . We denote by v ∈ R p the vector having this v j as j-th coordinate. Recall that ψ is separable, therefore v ∈ ∂ψ(θ k − Γg). The "noise" term of (38) can be thus be rewritten using v:</p><p>and we now separate this term in two using g:</p><p>It is now time to consider the expectation with respect to the noise of these terms. First, as g j is not dependent on the noise anymore, it simply holds that</p><p>The last step of our proof now takes care of the following term:</p><p>which is exactly µ I -strong convexity since (w ;</p><p>The minimum of the objective function in ( <ref type="formula">117</ref>) is attained at w</p><p>It remains to apply Theorem E.5 to obtain that, with probability at least 1/3,</p><p>which gives the lower bound on the expected value of F (w priv ; D) − F (w * ). Note that without the additional assumption on the distribution of the L j 's, Remark E.6 directly gives the result with an additional multiplicative factor (L min /L max ) 2 :</p><p>with probability at least 1/3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Private Estimation of Smoothness Constants</head><p>In this section, we explain how a fraction of the budget of DP can be used to estimate the coordinate-wise smoothness constants, which are essential to the good performance of DP-CD on imbalanced problems. Let f be defined as the average loss over the dataset D as in problem (1). We denote by M (i) j</p><p>the j-th component-smoothness constant of (•, d i ), where d i is the i-th point in D. The j-th smoothness constant of the function f is thus the average of all these constants:</p><p>Assuming that the practitioner knows an approximate upper bound b j over the M (i) j 's, they can enforce it by clipping M (i) j to b j for each i ∈ [n]. The sensitivity of the average of the clipped M (i) j 's is thus 2b j /n. One can then compute an estimate of M 1 , . . . , M p under -DP using the Laplace mechanism as follows:</p><p>where the factor p in noise scale comes from using the simple composition theorem Dwork and Roth, 2014, and Lap(λ) is a sample drawn in a Laplace distribution of mean zero and scale λ. computed constant can then directly be used in DP-CD, allocating the remaining budget − to the optimization procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Additional Experimental Details and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Hyperparameter Tuning</head><p>DP-SGD and DP-CD both depend on three hyperparameters: step size, clipping threshold and number of passes on data. For DP-CD, step sizes are adapted from a parameter as described in Section 6, and clipping</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
				<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
	<note>Deep Learning with Differential Privacy</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization: Optimal Rates in 1 Geometry</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="393" to="403" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gaboardi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4381" to="4391" />
			<date type="published" when="2020">2020</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization with Optimal Rates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guha Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Non-Euclidean Differentially Private Stochastic Convex Optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<editor>COLT. PMLR</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="474" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algorithmic Stability for Adaptive Data Analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Forty-Eighth Annual ACM Symposium on Theory of Computing. STOC &apos;16</title>
				<meeting>the Forty-Eighth Annual ACM Symposium on Theory of Computing. STOC &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="1046" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 55th Annual Symposium on Foundations of Computer Science</title>
				<meeting><address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014-10">Oct. 2014. 2014</date>
			<biblScope unit="page" from="464" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Personalized and Private Peer-to-Peer Machine Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taziki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics. PMLR</title>
				<imprint>
			<date type="published" when="2018-03">Mar. 2018</date>
			<biblScope unit="page" from="473" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography</title>
				<editor>
			<persName><forename type="first">M</forename><surname>Hirt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="635" to="658" />
		</imprint>
	</monogr>
	<note>Lecture Notes in Computer Science</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fingerprinting Codes and the Price of Approximate Differential Privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">STOC</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Enhancing Sparsity by Reweighted l 1 Minimization</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Wakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Fourier Anal. Applicat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="877" to="905" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coordinate Descent Method for Large-Scale L2-Loss Linear Support Vector Machines</title>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1369" to="1398" />
			<date type="published" when="2008-06">June 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differentially Private Empirical Risk Minimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res. 12</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Differentially Private Stochastic Coordinate Descent</title>
		<author>
			<persName><forename type="first">G</forename><surname>Damaskinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mendler-Dünner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Parnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021-05">May 2021</date>
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Fast Active Set Block Coordinate Descent Algorithm for 1 -Regularized Least Squares</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Santis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lucidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rinaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="781" to="809" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differential Privacy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">; M</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bugliesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Preneel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sassone</surname></persName>
		</author>
		<author>
			<persName><surname>Wegener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, Languages and Programming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Preserving Statistical Validity in Adaptive Data Analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing. STOC &apos;15</title>
				<meeting>the Forty-Seventh Annual ACM Symposium on Theory of Computing. STOC &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Calibrating Noise to Sensitivity in Private Data Analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>Theory of Cryptography. Ed. by S. Halevi and T. Rabin</editor>
		<imprint>
			<biblScope unit="page" from="265" to="284" />
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Algorithmic Foundations of Differential Privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>3-4</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m">Electricity Dataset</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization: Optimal Rates in Linear Time</title>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing</title>
				<meeting>the 52nd Annual ACM SIGACT Symposium on Theory of Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020-06">June 2020</date>
			<biblScope unit="page" from="439" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accelerated, parallel and proximal coordinate descent</title>
		<author>
			<persName><forename type="first">O</forename><surname>Fercoq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1997" to="2013" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Regularization Paths for Generalized Linear Models via Coordinate Descent</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Variance Reduced Coordinate Descent with Acceleration: New Method With a Surprising Application to Finite-Sum Problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="4039" to="4048" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SEGA: Variance Reduction via Gradient Sketching</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mishchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems. NIPS&apos;18</title>
				<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018-12">Dec. 2018</date>
			<biblScope unit="page" from="2086" to="2097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Train Faster, Generalize Better: Stability of Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<editor>ICML. PMLR</editor>
		<imprint>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robust regression using iteratively reweighted least-squares</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics -Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="813" to="827" />
			<date type="published" when="1977-01">Jan. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Accelerating Stochastic Gradient Descent Using Predictive Variance Reduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A New Analysis of Differential Privacy&amp;#x2019;s Generalization Guarantees (Invited Paper)</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharifi-Malvajerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing</title>
				<meeting>the 53rd Annual ACM SIGACT Symposium on Theory of Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nearly) Dimension Independent Private ERM with AdaGrad Rates via Publicly Estimated Subspaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning Research. PMLR</title>
				<editor>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kpotufe</surname></persName>
		</editor>
		<meeting>Machine Learning Research. PMLR</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="2717" to="2746" />
		</imprint>
		<respStmt>
			<orgName>COLT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient Greedy Coordinate Descent for Composite Problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koloskova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics. PMLR</title>
				<imprint>
			<date type="published" when="2019-04">Apr. 2019</date>
			<biblScope unit="page" from="2887" to="2896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sparse spatial autoregressions</title>
		<author>
			<persName><forename type="first">Kelley</forename><surname>Pace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Proximal Method for Composite Minimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="501" to="546" />
			<date type="published" when="2016-07">July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Blockwise Coordinate Descent Procedures for the Multi-Task Lasso, with Applications to Neural Semantic Basis Discovery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="649" to="656" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the convergence of the coordinate descent method for convex differentiable minimization</title>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl. 72</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7" to="35" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Celer: a Fast Solver for the Lasso with Dual Extrapolation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Massias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="3315" to="3324" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Renyi Differential Privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.07476</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 30th Computer Security Foundations Symposium (CSF)</title>
				<imprint>
			<date type="published" when="2017-08">Aug. 2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">R\&apos;enyi Differential Privacy of the Sampled Gaussian Mechanism</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10530</idno>
		<imprint>
			<date type="published" when="2019-08">Aug. 2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Efficiency of coordinate descent methods on huge-scale optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="341" to="362" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Let&apos;s Make Block Coordinate Descent Go Fast: Faster Greedy Rules, Message-Passing, Active-Set Complexity, and Superlinear Convergence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nutini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.08859</idno>
		<imprint>
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
	<note>math</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nutini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Friedlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Koepke</surname></persName>
		</author>
		<idno>ICML. PMLR</idno>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="1632" to="1641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Proximal Algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Optimization</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="239" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">AdaCliP: Adaptive Clipping for Private SGD</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pichapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07643</idno>
		<imprint>
			<date type="published" when="2019-10">Oct. 2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Iteration Complexity of Randomized Block-Coordinate Descent Methods for Minimizing a Composite Function</title>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takáč</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Block Coordinate Relaxation Methods for Nonparametric Wavelet Denoising</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="379" />
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Stochastic Dual Coordinate Ascent Methods for Regularized Loss</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res. 14</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="567" to="599" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">A Primer on Coordinate Descent Algorithms</title>
		<author>
			<persName><forename type="first">H.-J</forename><forename type="middle">M</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00040</idno>
		<imprint>
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
	<note>math, stat</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<title level="m">Membership Inference Attacks Against Machine Learning Models</title>
				<imprint>
			<date type="published" when="2017-05">May 2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
	<note>2017 IEEE Symposium on Security and Privacy (SP)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Nearly Optimal Private LASSO</title>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Guha</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Inexact Coordinate Descent: Complexity and Preconditioning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tappenden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gondzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="144" to="176" />
			<date type="published" when="2016-07">July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Differentially Private Learning with Adaptive Clipping</title>
		<author>
			<persName><forename type="first">O</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Block-coordinate gradient descent method for linearly constrained nonsmooth separable optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">513</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Convergence of a block coordinate descent method for nondifferentiable minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="475" to="494" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rényi Divergence and Kullback-Leibler Divergence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Van Erven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Harremoës</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3797" to="3820" />
			<date type="published" when="2014-07">July 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Differentially Private Empirical Risk Minimization Revisited: Faster and More General</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Differentially Private SGD with Non-Smooth Losses</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="306" to="336" />
			<date type="published" when="2022-01">Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Coordinate Descent Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="34" />
			<date type="published" when="2015-06">June 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A Proximal Stochastic Gradient Method with Progressive Variance Reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2057" to="2075" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A Comparison of Optimization Methods and Software for Large-Scale L1-Regularized Linear Classification</title>
		<author>
			<persName><forename type="first">G.-X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3183" to="3234" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Bypassing the Ambient Dimension: Private SGD with Gradient Subspace Identification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
