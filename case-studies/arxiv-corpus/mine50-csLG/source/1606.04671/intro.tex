\section{Introduction}

Finetuning remains the method of choice for transfer learning with neural
networks: a model is pretrained on a source domain (where data is often
abundant), the output layers of the model are adapted to the target domain, and the
network is finetuned via backpropagation. This approach was
pioneered in \cite{hinton2006science} by transferring knowledge from a
generative to a discriminative model, and has since been generalized
with great success \cite{UTLC+LISA-2011}.  Unfortunately, the approach has drawbacks
which make it unsuitable for transferring across \textit{multiple tasks}: if we
wish to leverage knowledge acquired over a sequence of experiences, which model
should we use to initialize subsequent models? This seems to require not only a
learning method that can support transfer learning without catastrophic forgetting, but also
foreknowledge of task similarity. Furthermore, while finetuning may allow us to
recover expert performance in the target domain, it is a destructive process
which discards the previously learned function. One could copy each model before
finetuning to explicitly remember all previous tasks, but the issue of
selecting a proper initialization remains.  While distillation
\cite{Hinton2015distil} offers one potential solution to multitask learning
\cite{Rusu15}, it requires a reservoir of persistent training data for all tasks,
an assumption which may not always hold.

This paper introduces \textit{progressive networks}, a novel model architecture
with explicit support for transfer across sequences of tasks. While finetuning
incorporates prior knowledge only at initialization, progressive networks
retain a pool of pretrained models throughout training, and learn lateral connections
from these to extract useful features for the new task.  By combining previously
learned features in this
manner, progressive networks achieve a richer compositionality, in which prior
knowledge is no longer transient and can be integrated at each layer of the
feature hierarchy. Moreover, the addition of new capacity alongside pretrained
networks gives these models the flexibility to both reuse old computations and learn new ones.
As we will show, progressive networks naturally accumulate experiences and
are immune to catastrophic forgetting by design, making them an ideal
springboard for tackling long-standing problems of continual or lifelong
learning.

The contributions of this paper are threefold. While many of the individual
ingredients used in progressive nets can be found in the literature, their
combination and use in solving complex sequences of tasks is novel. Second,
we extensively evaluate the model in complex reinforcement learning domains.
In the process, we also evaluate alternative approaches to transfer
(such as finetuning) within the RL domain. In particular, we show that
progressive networks provide comparable (if not slightly better) transfer
performance to traditional finetuning, but without the destructive
consequences. Finally, we develop a novel analysis based on
Fisher Information and perturbation which allows us to analyse in
detail how and where transfer occurs across tasks.
