\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

% \usepackage{nips_2016}
% \usepackage[nonatbib]{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{hyperref}
\usepackage{amsmath}        % math package
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{graphicx}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{subfig}      % multiple captions and labels in a single figure
\usepackage{amsmath}
\usepackage[font={footnotesize}]{caption}
\usepackage{enumitem}

\usepackage{rotating}
\usepackage{array}

\setlist{nosep}


\usepackage{color}
\newcommand{\razp}[1]{\textcolor{blue}{#1}}

\title{Progressive Neural Networks}


\author{Andrei A. Rusu*, \ Neil C. Rabinowitz*, \ Guillaume Desjardins*, \ Hubert Soyer,\\
\textbf{James Kirkpatrick, \ Koray Kavukcuoglu, \ Razvan Pascanu, \ Raia Hadsell} \\
\small{* These authors contributed equally to this work}
\vspace{0.15 cm}
\\
Google DeepMind \\
London, UK
\vspace{0.15 cm}
\\
\small\texttt{\{andreirusu, ncr, gdesjardins, soyer, kirkpatrick, korayk, razp, raia\}@google.com} \\
}
\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
Learning to solve complex sequences of tasks---while both leveraging transfer and
avoiding catastrophic forgetting---remains a key obstacle to achieving human-level
intelligence. The \emph{progressive networks} approach represents a step forward in this direction:
they are immune to forgetting and can leverage prior knowledge via lateral
connections to previously learned features. We evaluate this architecture
extensively on a wide variety of reinforcement learning tasks (Atari and 3D
maze games), and show that it outperforms common baselines based on pretraining
and finetuning. Using a novel sensitivity measure, we demonstrate
that transfer occurs at both low-level sensory and high-level control layers of the learned policy.
\end{abstract}

\input{intro}
\input{progressive}
\input{method_transfer}
\input{related_work}
\input{experiment_setup}
\input{infinite_pong}
\input{two_columns}
\input{atari_analysis}
\input{labyrinth}
\input{discussion}

\newpage
\footnotesize
\setlength{\bibsep}{5pt}
\bibliographystyle{plain}
\bibliography{progressive}

\newpage

\appendix
\pagenumbering{arabic}

{\Large{\textbf{Supplementary Material}}}

\input{app_perturbation}
\input{app_compression}
\input{app_setup}
\input{app_curves}
\input{app_lab}

\end{document}
