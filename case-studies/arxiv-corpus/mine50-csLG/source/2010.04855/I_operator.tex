\section{Conditional expectation operator proof}\label{sec:operator}

In this supplement, we prove Proposition~\ref{theorem:conditional}, improving the rate of \cite{singh2019kernel} from $n^{-(c-1)/\{2(c+1)\}}$ to $n^{-(c-1)/\{2(c+1/b)\}}$. Our consideration of Hilbert--Schmidt norm departs from \cite{park2020measure,talwai2022sobolev}, who study surrogate risk and operator norm, respectively. Our assumptions also depart from \cite{singh2019kernel,park2020measure,talwai2022sobolev}. Instead, we directly generalize the assumptions of \cite{fischer2017sobolev} from the standard kernel ridge regression to the generalized kernel ridge regression that we use to estimate a conditional mean embedding. Our rate matches the minimax optimal rate shown in contemporaneous work of  \cite{li2022optimal}, who also study the misspecified case. We focus on the well specified case for reasons described in Section~\ref{sec:detail}, and employ a simpler proof strategy.

To lighten notation, we suppress the indexing of conditional expectation operators and conditional mean embeddings by $\ell$. Furthermore, to lighten notation, we abbreviate $\mathcal{L}_2=\mathcal{L}_2(\mathcal{H}_{\mathcal{A}},\mathcal{H}_{\mathcal{B}})$. In the simplified notation,
\begin{align*}
    E_0&=\argmin_{E\in\mathcal{L}_2}\mathcal{E}(E),\quad \mathcal{E}(E)=E[\{\phi(A)-E^*\phi(B)\}^2]; \\
    E_{\lambda}&=\argmin_{E\in\mathcal{L}_2}\mathcal{E}(E)+\lambda\|E\|^2_{\mathcal{L}_2};\\
    \hat{E}&=\argmin_{E\in\mathcal{L}_2}\hat{\mathcal{E}}(E),\quad \hat{\mathcal{E}}(E)=n^{-1}\sum_{i=1}^n\{\phi(A_{i})-E^*\phi(B_{i})\}^2+\lambda\|E\|^2_{\mathcal{L}_2}.
\end{align*}

\subsection{Bias}

\begin{proposition}[Conditional expectation operator bias; Theorem 6 of \cite{singh2019kernel}]\label{prop:bias}
Suppose Assumptions~\ref{assumption:RKHS},~\ref{assumption:original}, and the source condition in~\ref{assumption:smooth_op} hold. Then with probability one,
$$
\|E_{\lambda}-E_{0}\|_{\mathcal{L}_2} \leq \lambda^{\frac{c-1}{2}}\zeta^{1/2},
$$
where $\zeta$ is defined in Lemma~\ref{lemma:alt}.
\end{proposition}

\subsection{Variance}

\begin{lemma}[Helpful bounds]\label{lemma:bounds}
Suppose Assumptions~\ref{assumption:RKHS},~\ref{assumption:original}, and~\ref{assumption:smooth_op} hold. Let $\mu^{\lambda}_{a}(b)=E_{\lambda}^*\phi(b)$. We adopt the language of \cite{caponnetto2007optimal}.
\begin{enumerate}
    %\item The generalized residual is $\mathcal{A}(\lambda)=E[\|\mu^{\lambda}_a(B)-\mu_a(B)\|^2_{\mathcal{H}_{\mathcal{A}}}]\leq \lambda^c \zeta^{1/2}$.
    \item The generalized reconstruction error is $\mathcal{B}(\lambda)=\sup_{b\in\mathcal{B}}\|\mu^{\lambda}_a(b)-\mu_a(b)\|^2_{\mathcal{H}_{\mathcal{A}}} \leq \kappa^2_b \zeta \cdot \lambda^{c-1}$.
   % \item $\|E[(\mu^{\lambda}_a(B)-\mu_a(B))\otimes (\mu^{\lambda}_a(B)-\mu_a(B))]\|_{op}\leq \zeta \lambda^c$.
    \item The generalized effective dimension is $\mathcal{N}(\lambda)=\text{\normalfont tr}\{(T+\lambda I)^{-1}T\}\leq C (\pi/b) \{\sin(\pi/b)\}^{-1}\lambda^{-1/b}$.
\end{enumerate}
\end{lemma}

\begin{proof}
%The first result follows from \cite[Remark B]{talwai2022sobolev}, since the source condition in Assumption~\ref{assumption:smooth_op} implies \cite[Assumption 3]{talwai2022sobolev}. 
The first result is a corollary of Proposition~\ref{prop:bias}. 
%The third result follows from \cite[eq. 8]{talwai2022sobolev}. 
The second result follows from \cite[eq. f]{sutherland2017fixing}, appealing to the effective dimension condition in Assumption~\ref{assumption:smooth_op}.
\end{proof}

\begin{lemma}[Decomposition of variance]\label{lemma:decomp}
Let $T_{AB}=E\{\phi(A)\otimes \phi(B)\}$ and let $E_n(\cdot)=n^{-1}\sum_{i=1}^n(\cdot)$. The following bound holds:
\begin{align*}
    \|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2}
    &\leq \|\{\hat{T}_{AB}-T_{AB}(T_{BB}+\lambda I)^{-1}(\hat{T}_{BB}+\lambda I)\}(T_{BB}+\lambda I)^{-1/2}\|_{\mathcal{L}_2} \\
    &\quad \cdot \|(T_{BB}+\lambda I)^{1/2}(\hat{T}_{BB}+\lambda I)^{-1}(T_{BB}+\lambda I)^{1/2}\|_{op} \\
    &\quad \cdot \|(T_{BB}+\lambda I)^{-1/2}\|_{op}.
\end{align*}
Moreover, in the first factor,
\begin{align*}
    &\hat{T}_{AB}-T_{AB}(T_{BB}+\lambda I)^{-1}(\hat{T}_{BB}+\lambda I) \\
    &=E_n[\{\phi(A)-\mu^{\lambda}_a(B)\}\otimes \phi(B)]-E[\{\phi(A)-\mu^{\lambda}_a(B)\}\otimes \phi(B)].
\end{align*}
\end{lemma}

\begin{proof}
The result mirrors \cite[eq. 44]{fischer2017sobolev} and \cite[eq. 34]{talwai2022sobolev},
strengthening the RKHS norm to Hilbert--Schmidt norm via \cite[Proposition 22]{singh2019kernel}.
\end{proof}

\begin{lemma}[Bounding the first factor]\label{lemma:1}
Suppose Assumptions~\ref{assumption:RKHS} and~\ref{assumption:original} hold. Then with probability $1-\delta/2$, the first factor in Lemma~\ref{lemma:decomp} is bounded as 
\begin{align*}
  &\|\{\hat{T}_{AB}-T_{AB}(T_{BB}+\lambda I)^{-1}(\hat{T}_{BB}+\lambda I)\}(T_{BB}+\lambda I)^{-1/2}\|_{\mathcal{L}_2} \\
  &\leq 
    4\log(4/\delta) \left\{\frac{\kappa_a\kappa_b}{n\lambda^{1/2}}+\frac{\kappa_b\mathcal{B}(\lambda)^{1/2}}{n\lambda^{1/2}}+\frac{\kappa_a \mathcal{N}(\lambda)^{1/2}}{n^{1/2}}+\frac{\mathcal{B}(\lambda)^{1/2}\mathcal{N}(\lambda)^{1/2}}{n^{1/2}}\right\}.
\end{align*}
\end{lemma}

\begin{proof}
We verify the conditions of Lemma~\ref{lemma:prob}. Let
$$
\xi_i= [\{\phi(A_i)-\mu^{\lambda}_a(B_i)\} \otimes\phi(B_i)] (T_{BB}+\lambda I)^{-1/2}.
$$
We proceed in steps.
\begin{enumerate}
    \item First moment.
    
    Observe that 
\begin{align*}
    \|\xi_i\|_{\mathcal{L}_2}
    &=\|[\{\phi(A_i)-\mu^{\lambda}_a(B_i)\} \otimes\phi(B_i)] (T_{BB}+\lambda I)^{-1/2}\|_{\mathcal{L}_2} \\
    &=\| (T_{BB}+\lambda I)^{-1/2} [\phi(B_i)  \otimes \{\phi(A_i)-\mu^{\lambda}_a(B_i)\}] \|_{\mathcal{L}_2} \\
    &=\| (T_{BB}+\lambda I)^{-1/2} \phi(B_i) \|_{\mathcal{H}_{\mathcal{B}}} \cdot \|\phi(A_i)-\mu^{\lambda}_a(B_i)\|_{\mathcal{H}_{\mathcal{A}}}.
\end{align*}
Moreover
$$
\| (T_{BB}+\lambda I)^{-1/2} \phi(B_i) \|_{\mathcal{H}_{\mathcal{B}}} \leq \|(T_{BB}+\lambda I)^{-1/2}\|_{op} \| \phi(B_i) \|_{\mathcal{H}_{\mathcal{B}}}\leq \frac{\kappa_b}{\lambda^{1/2}}
$$
and
$$
\|\phi(A_i)-\mu^{\lambda}_a(B_i)\|_{\mathcal{H}_{\mathcal{A}}} \leq \|\phi(A_i)-\mu_a(B_i)\|_{\mathcal{H}_{\mathcal{A}}}+\|\mu_a(B_i)-\mu^{\lambda}_a(B_i)\|_{\mathcal{H}_{\mathcal{A}}} \leq 2\kappa_a+\mathcal{B}(\lambda)^{1/2}.
$$
In summary,
$$
\|\xi_i\|_{\mathcal{L}_2} \leq \frac{\kappa_b}{\lambda^{1/2}} \left\{2\kappa_a+\mathcal{B}(\lambda)^{1/2}\right\}.
$$
    \item Second moment.
    
    Next, write
    \begin{align*}
   &E(\|\xi_i\|^2_{\mathcal{L}_2}) \\
   &= \int \text{\normalfont tr}( [\{\phi(a)-\mu^{\lambda}_a(b)\} \otimes \phi(b)](T_{BB}+\lambda I)^{-1} [\phi(b)  \otimes \{\phi(a)-\mu^{\lambda}_a(b)\}]) \mathrm{d}\text{\normalfont pr}(a,b) \\
   &=\int \text{\normalfont tr}[ \{\phi(a)-\mu^{\lambda}_a(b)\} \langle \phi(b), (T_{BB}+\lambda I)^{-1} \phi(b)\rangle_{\mathcal{H}_{\mathcal{B}}} \langle \{\phi(a)-\mu^{\lambda}_a(b)\},\cdot \rangle_{\mathcal{H}_{\mathcal{A}}}] \mathrm{d}\text{\normalfont pr}(a,b)  \\
   &=\int \text{\normalfont tr}[ \langle \phi(b), (T_{BB}+\lambda I)^{-1} \phi(b)\rangle_{\mathcal{H}_{\mathcal{B}}} \langle \{\phi(a)-\mu^{\lambda}_a(b)\} ,\{\phi(a)-\mu^{\lambda}_a(b)\} \rangle_{\mathcal{H}_{\mathcal{A}}}] \mathrm{d}\text{\normalfont pr}(a,b)  \\
   &\leq \sup_{a,b} \|\phi(a)-\mu^{\lambda}_a(b)\|^2_{\mathcal{H}_{\mathcal{A}}} \cdot \int \text{\normalfont tr}\{ \langle \phi(b), (T_{BB}+\lambda I)^{-1} \phi(b)\rangle_{\mathcal{H}_{\mathcal{B}}}\} \mathrm{d}\text{\normalfont pr}(b).
    \end{align*}
    Focusing on the former factor,
    $$
     \|\phi(a)-\mu^{\lambda}_a(b)\|_{\mathcal{H}_{\mathcal{A}}}  \leq  \|\phi(a)-\mu_a(b)\|_{\mathcal{H}_{\mathcal{A}}}+\|\mu_a(b)-\mu^{\lambda}_a(b)\|_{\mathcal{H}_{\mathcal{A}}} \leq 2\kappa_a+\mathcal{B}(\lambda)^{1/2}.
    $$
    Therefore
    $$
    \sup_{a,b} \|\phi(a)-\mu^{\lambda}_a(b)\|^2_{\mathcal{H}_{\mathcal{A}}} \leq \left\{2\kappa_a+\mathcal{B}(\lambda)^{1/2}\right\}^2.
    $$
    Focusing on the latter factor, 
    \begin{align*}
        \int \text{\normalfont tr}\{ \langle \phi(b), (T_{BB}+\lambda I)^{-1} \phi(b)\rangle_{\mathcal{H}_{\mathcal{B}}}\} \mathrm{d}\text{\normalfont pr}(b)
        &=\int \text{\normalfont tr}[(T_{BB}+\lambda I)^{-1} \{\phi(b)\otimes\phi(b)\}] \mathrm{d}\text{\normalfont pr}(b) \\
        &= \text{\normalfont tr}\{(T_{BB}+\lambda I)^{-1} T_{BB}\} \\
        &=\mathcal{N}(\lambda).
    \end{align*}
    In summary,
    $$
    E(\|\xi_i\|^2_{\mathcal{L}_2}) \leq \mathcal{N}(\lambda)\left\{2\kappa_a+\mathcal{B}(\lambda)^{1/2}\right\}^2.
    $$
    \item Concentration.
    
    Therefore with probability $1-\delta/2$,
    \begin{align*}
        &\|E_n(\xi)-E(\xi)\|_{\mathcal{L}_2}  \\
        &\leq \frac{2 \log(4/\delta)}{n} \frac{\kappa_b}{\lambda^{1/2}} \left\{2\kappa_a+\mathcal{B}(\lambda)^{1/2}\right\} + \left[\frac{2 \log(4/\delta)}{n} \mathcal{N}(\lambda)\left\{2\kappa_a+\mathcal{B}(\lambda)^{1/2}\right\}^2\right]^{1/2} \\
        &\leq 4\log(4/\delta) \left\{\frac{\kappa_a\kappa_b}{n\lambda^{1/2}}+\frac{\kappa_b\mathcal{B}(\lambda)^{1/2}}{n\lambda^{1/2}}+\frac{\kappa_a \mathcal{N}(\lambda)^{1/2}}{n^{1/2}}+\frac{\mathcal{B}(\lambda)^{1/2}\mathcal{N}(\lambda)^{1/2}}{n^{1/2}}\right\}.
     \end{align*}
    
    
\end{enumerate}

\end{proof}

\begin{remark}[Sufficiently large $n$]\label{remark:big_n}
In the finite sample, we assume a certain inequality holds when bounding the second factor: 
\begin{equation}\label{eq:n_big}
  n\geq 8\kappa_b^2 \log(4/\delta) \cdot \lambda \cdot 
\log
\left\{ 2e\cdot \mathcal{N}(\lambda)\frac{\|T\|_{op}+\lambda}{\|T\|_{op}}
\right\}.  
\end{equation}
Ultimately, we will choose $\lambda=n^{-1/(c+1/b)}$ in Proposition~\ref{theorem:conditional}. This choice of $\lambda$ together with the bound on generalized effective dimension $\mathcal{N}(\lambda)$ in Lemma~\ref{lemma:bounds} imply that there exists an $n_0$ such that for all $n\geq n_0$,~\eqref{eq:n_big} holds, as argued by \cite[Proof of Theorem 1]{fischer2017sobolev}. We use the phrase ``$n$ sufficiently large'' when we appeal to this logic, and we summarize the final bound using $O(\cdot)$ notation.
\end{remark}

\begin{lemma}[Bounding the second factor]\label{lemma:2}
Suppose Assumptions~\ref{assumption:RKHS} and~\ref{assumption:original} hold. Further assume~\eqref{eq:n_big} holds. Then probability $1-\delta/2$, the second factor in Lemma~\ref{lemma:decomp} is bounded as 
$$
\|(T_{BB}+\lambda I)^{1/2}(\hat{T}_{BB}+\lambda I)^{-1}(T_{BB}+\lambda I)^{1/2}\|_{op} \leq 3.
$$
\end{lemma}


\begin{proof}
The result follows from \cite[eq. 44b, 47]{fischer2017sobolev}. In particular, our assumptions suffice for the properties used in \cite[Lemma 17]{fischer2017sobolev} to hold. Separability of $\mathcal{B}$ together with boundedness of the kernel $k_{\mathcal{B}}$ imply that $\mathcal{H}_{\mathcal{B}}$ is separable \cite[Lemma 4.33]{steinwart2008support}. Next, we verify the assumptions called EMB, EVD, and SRC. Boundedness of the kernel implies EMB with $a=1$. EVD is the assumption we call effective dimension, parametrized by $b\geq 1$. SRC is the assumption we call the source condition, parametrized by $c\in(1,2]$ in our case. 
\end{proof}


\begin{lemma}[Bounding the third factor]\label{lemma:3}
With probability one, the third factor in Lemma~\ref{lemma:decomp} is bounded as
$$
    \|(T_{BB}+\lambda I)^{-1/2}\|_{op} \leq \lambda^{-1/2}.
$$
\end{lemma}

\begin{proof}
The result follows from the definition of operator norm.
\end{proof}

\begin{proposition}[Conditional expectation operator variance]\label{prop:variance}
Suppose Assumptions~\ref{assumption:RKHS},~\ref{assumption:original}, and~\ref{assumption:smooth_op} hold. Further assume~\eqref{eq:n_big} holds and $\lambda\leq 1$. Then with probability $1-\delta$,
$$
\|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2} \leq C\log(4/\delta)\left\{ \frac{1}{n\lambda}+\frac{1}{n^{1/2}\lambda^{1/(2b)+1/2}}\right\}.
$$
\end{proposition}

\begin{proof}
We combine the previous lemmas. By Lemmas~\ref{lemma:decomp},~\ref{lemma:1},~\ref{lemma:2}, and~\ref{lemma:3}, if~\eqref{eq:n_big} holds, then with probability $1-\delta$
\begin{align*}
    \|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2} 
    &\leq \frac{12\log(4/\delta) }{\lambda^{1/2}} \left\{\frac{\kappa_a\kappa_b}{n\lambda^{1/2}}+\frac{\kappa_b\mathcal{B}(\lambda)^{1/2}}{n\lambda^{1/2}}+\frac{\kappa_a \mathcal{N}(\lambda)^{1/2}}{n^{1/2}}+\frac{\mathcal{B}(\lambda)^{1/2}\mathcal{N}(\lambda)^{1/2}}{n^{1/2}}\right\}.
\end{align*}
Next, recall the bounds in Lemma~\ref{lemma:bounds}. When $\lambda\leq 1$,
     $$
     \mathcal{B}(\lambda)^{1/2} \leq \kappa_b \zeta^{1/2} \lambda^{\frac{c-1}{2}} \leq \kappa_b \zeta^{1/2}.
     $$
     For brevity, write
     $$
     \mathcal{N}(\lambda)^{1/2}\leq C'\lambda^{-\frac{1}{2b}}.
     $$
     Therefore when $\lambda\leq 1$ the bound simplifies as
     \begin{align*}
         \|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2} 
    \leq C\log(4/\delta) \left\{\frac{1}{n\lambda}+\frac{1}{n^{1/2}\lambda^{1/(2b)+1/2}}\right\}.
     \end{align*}
\end{proof}

\subsection{Collecting results}

\begin{proof}[Proof of Proposition~\ref{theorem:conditional}]
We combine and simplify Propositions~\ref{prop:bias} and~\ref{prop:variance}. Take $\lambda=n^{-1/(c+1/b)}$. For sufficiently large $n$,~\eqref{eq:n_big} holds and $\lambda\leq 1$ as explained in Remark~\ref{remark:big_n}. By triangle inequality, with probability $1-\delta$,
\begin{align*}
    \|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2} &\leq  \|\hat{E}-E_{\lambda}\|_{\mathcal{L}_2}+ \|E_{\lambda}-E_0\|_{\mathcal{L}_2} \\
    &\leq  C\log(4/\delta) \left\{\frac{1}{n\lambda}+\frac{1}{n^{1/2}\lambda^{1/(2b)+1/2}}\right\}+C\lambda^{\frac{c-1}{2}}.
\end{align*}
Each term on the RHS simplifies as follows:
\begin{align*}
    &n^{-1}\lambda^{-1}
    =n^{-1}n^{1/(c+1/b)}
    =n^{1/(c+1/b)-1}
    =n^{\frac{1-c-1/b}{c+1/b}}
    =n^{-\frac{1}{2}\frac{2(c+1/b-1)}{c+1/b}} 
    \leq n^{-\frac{1}{2} \frac{c-1}{c+1/b}}; \\
    &n^{-1/2}\lambda^{-1\{1/(2b)+1/2\}}
    =n^{-1/2} n^{\frac{\{1/(2b)+1/2\}}{(c+1/b)}} 
    =n^{-\frac{1}{2}(1-\frac{1/b+1}{c+1/b})}
    =n^{-\frac{1}{2}(\frac{c+1/b-1/b-1}{c+1/b})}
    = n^{-\frac{1}{2}\frac{c-1}{c+1/b}};\\
    &\lambda^{\frac{c-1}{2}}
    = n^{-\frac{1}{c+1/b}\frac{c-1}{2}} =n^{-\frac{1}{2}\frac{c-1}{c+1/b}}.
\end{align*}
\end{proof}