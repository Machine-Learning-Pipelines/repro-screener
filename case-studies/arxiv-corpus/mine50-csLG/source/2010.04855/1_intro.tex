\section{Introduction}\label{sec:intro}

\subsection{Motivation}

Program evaluation aims to measure the counterfactual relationship between treatment $D$ and outcome $Y$, which may vary for different subpopulations: if we intervened on treatment, setting $D=d$, what would be the expected counterfactual outcome $Y^{(d)}$ for individuals with characteristics $V=v$? When treatment is binary, the causal parameter is a function $\theta_0(v)=E\{Y^{(1)}-Y^{(0)} \mid V=v\}$ called the heterogeneous treatment effect; when treatment is continuous, it is a function $\theta_0(d,v)=E\{Y^{(d)} \mid V=v\}$ that we call a heterogeneous response curve. Assuming selection on observable covariates $(V,X)$, the causal function $\theta_0(d,v)$ can be recovered by integrating the regression function $\gamma_0(d,v,x)=E(Y \mid D=d,V=v,X=x)$ according to the conditional distribution $\text{\normalfont pr}(x \mid v)$: $\theta_0(d,v)=\int \gamma_0(d,v,x)\mathrm{d}\text{\normalfont pr}(x \mid v)$ \cite{rosenbaum1983central,robins1986new}, which may be complex when there are many covariates. 

The same is true for other causal functions such as dose
%$\theta_0(d,v)=E[Y^{(d)} \mid V=v]$ 
and incremental response curves, 
%$\theta_0(d)=E[\nabla_d Y^{(d)}]$, 
and even counterfactual distributions, albeit with different regressions and reweightings. Therefore nonparametric estimation of a causal function involves three challenging steps: estimating a nonlinear regression, with possibly many covariates; estimating the distribution for reweighting, which may be conditional; and using the nonparametric distribution to integrate the nonparametric regression. For this reason, flexible estimation of nonparametric causal functions, such as $\theta_0(d,v)$, is often deemed too computationally demanding to be practical for program evaluation. %See Section~\ref{sec:related} for a discussion of related work.

%\cite{kennedy2017nonparametric,semenova2021debiased,nie2021quasi,kallus2018policy,chernozhukov2018global,fan2019estimation,zimmert2019nonparametric,colangelo2020double} 

% Additional nuanced questions can be asked. Is the causal relationship between treatment and outcome learned in one population externally valid in another? For the subpopulation who received one treatment value, what would have been their outcome had they instead received another? Are treatment effects heterogeneous with respect to some interpretable subcovariate $V\subset X$ such as age, race, or gender? Such empirical questions are ubiquitous in policy evaluation across economics, statistics, and epidemiology.

Our key insight is that the reproducing kernel Hilbert space (RKHS), a popular nonparametric setting in machine learning, is precisely the class of functions for which the steps of nonparametric causal estimation can be separated. This decomposition follows almost immediately from the definition of the RKHS, and it is a specific strength of our framework; random forests, for example, do not allow such decoupling. Our key insight follows from a more fundamental one. Evaluation of a causal function is generally not a bounded functional over all of $\mathbb{L}^2$ \cite{van1991differentiable,newey1994asymptotic}. We prove that the evaluation of a causal function is a bounded functional over the RKHS $\mathcal{H}$, which is a subset of $\mathbb{L}^2$. By the classic Riesz representation theorem of functional analysis, a bounded functional over a Hilbert space admits a decoupled inner product representation within the Hilbert space. We show how to use this representation to separate the steps of nonparametric causal estimation. This insight appears to be original.

We adapt kernel ridge regression, a classic machine learning algorithm that generalizes splines \cite{wahba1990spline}, to address the computational challenges of estimating causal functions such as dose, heterogeneous, and incremental response curves. Nonparametric estimation with kernels is quite simple: the nonlinear regression with many covariates can be estimated by simple matrix operations; the conditional distribution can be expressed as a regression problem and estimated by simple matrix operations as well; and the step of integration can be performed by taking the product of the results. The final nonparametric estimator for the causal function has a one line, closed form solution, unlike previous work. This simplicity makes the family of estimators highly practical. The proposed estimators are substantially simpler yet outperform some leading alternatives in nonlinear simulations with many covariates; see Supplement~\ref{sec:experiments}. As extensions, we generalize our new algorithmic techniques to counterfactual distributions in Supplement~\ref{sec:distribution} as well as causal functions and distributions identified by front and back door criteria in Supplement~\ref{sec:graphical}.

Theoretically, our statistical guarantees rely on smoothness of the causal function and spectral decay of the covariance operator rather than the explicit dimension of treatment and covariates. In economic modelling, many variables may matter for labor market decisions, yet economic theory suggests that the effect of different intensities of job training should be well approximated by smooth functions. The emphasis on smoothness in the causal interpretation of RKHS assumptions generalizes standard Sobolev assumptions, and it differs from the emphasis on sparsity in lasso-type assumptions. Our causal function estimators are uniformly consistent with rates that combine minimax optimal rates for smooth nonparametric regressions. En route to our main results, we prove an improved rate for conditional expectation operators. Our main results are nonasymptotic and imply asymptotic uniform validity.% over large classes of models.

\subsection{Contribution}

Conceptually, we illustrate how to use RKHS techniques in order to separate the steps of nonparametric causal estimation. In doing so, we provide a template for researchers to develop simple kernel estimators for complex causal estimands. Specifically, we clarify five assumptions under which we derive our various results: (i) identification, from the social scientific problem at hand; (ii) basic regularity conditions on the kernels, which are satisfied by all of the kernels typically used in practice; (iii) basic regularity on the  outcome, treatment, and covariates, allowing them to be discrete or continuous variables that take values in general spaces (even texts, images, or graphs); (iv) smoothness of the causal estimand; and (v) spectral decay of the covariance operator. We combine these five assumptions to estimate causal functions, providing insight into the meaning and applicability of RKHS approximation assumptions for causal inference.

Statistically, we prove uniform consistency: our estimators converge to causal functions in $\sup$ norm, which encodes caution about worst case scenarios when informing policy decisions. Our finite sample rates of convergence explicitly account for each source of error at any finite sample size. Our rates do not directly depend on the data dimension, but rather the smoothness of the causal estimand and spectral decay of the covariance operator. The rates may indirectly depend on dimension; see Section~\ref{sec:consistency} for discussion in the context of the Sobolev space, which is a special case of an RKHS. Of independent interest, we provide a technical innovation to justify our main results: relative to previous work, we prove faster rates of convergence in Hilbert--Schmidt norm for conditional expectation operators. We generalize our main results to prove convergence in distribution for counterfactual distributions. The analysis of uniform confidence bands for our causal function estimators is an open question that we pose for future research, since uniform inference for kernel ridge regression remains an open question in statistics.

Computationally, we demonstrate state-of-the-art performance in nonlinear simulations with many covariates, despite the relative simplicity of our proposal compared to existing machine learning approaches. In order to simplify the causal estimation problem, we assume that underlying conditional expectation functions are elements in an RKHS. We propose a family of global estimators with closed form solutions, avoiding density estimation and sampling even for complex integrals. Throughout, the only hyperparameters are kernel hyperparameters and ridge regression penalties. The former have well established tuning procedures, and the latter are easily tuned using the closed form solution for generalized cross validation (which is asymptotically optimal) or leave-one-out cross validation (which we derive). In practice, the tunings are similar, and the asymptotically optimal choice aligns with our statistical theory.

Empirically, our kernel ridge regression approach allows for simple yet flexible estimation of nuanced causal estimands. Such estimands provide meaningful insights about the Job Corps, the largest job training program for disadvantaged youth in the US. Our key statistical assumption is that different intensities of job training have smooth effects on counterfactual employment, and those effects are smoothly modified by age. In our program evaluation in Supplement~\ref{sec:experiments}, we find that the effect of job training on employment substantially varies by class hours and by age; a targeted policy will be more effective. Our program evaluation confirms earlier findings while also uncovering meaningful heterogeneity. 
%In this case study, 
 We demonstrate how kernel methods for causal functions are a practical addition to the empirical economic toolkit.

% The structure of the paper is as follows. Section~\ref{sec:related} describes related work. Section~\ref{sec:problem} defines our class of causal functions. Section~\ref{sec:algorithm} proposes kernel methods for this class, which Section~\ref{sec:detail} compares to kernel methods for causal scalars. Section~\ref{sec:consistency} presents our theoretical guarantees of uniform consistency. Section~\ref{sec:experiments} conducts nonlinear simulations as well as a real world program evaluation of the US Job Corps. Section~\ref{sec:conclusion} concludes. We extend our analysis to counterfactual distributions in Appendix~\ref{sec:distribution}, and to causal functions and counterfactual distributions identified by Pearl's front and back door criteria in Appendix~\ref{sec:graphical}.