\begin{thebibliography}{33}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Arase and Tsujii(2017)}]{arase:emnlp2017}
Yuki Arase and Jun'ichi Tsujii. 2017.
\newblock \href {http://aclweb.org/anthology/D17-1001} {Monolingual phrase
  alignment on parse forests}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1--11, Copenhagen, Denmark.

\bibitem[{Cer et~al.(2017)Cer, Diab, Agirre, Lopez-Gazpio, and
  Specia}]{cer-etal-2017-semeval}
Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia.
  2017.
\newblock \href {https://doi.org/10.18653/v1/S17-2001} {{S}em{E}val-2017 task
  1: Semantic textual similarity multilingual and crosslingual focused
  evaluation}.
\newblock In \emph{Proceedings of the International Workshop on Semantic
  Evaluation (SemEval)}, pages 1--14, Vancouver, Canada.

\bibitem[{Chen et~al.(2017)Chen, Zhu, Ling, Wei, Jiang, and Inkpen}]{P17-1152}
Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si~Wei, Hui Jiang, and Diana Inkpen.
  2017.
\newblock \href {https://doi.org/10.18653/v1/P17-1152} {Enhanced lstm for
  natural language inference}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL)}, pages 1657--1668, Vancouver, Canada.

\bibitem[{Conneau et~al.(2017)Conneau, Kiela, Schwenk, Barrault, and
  Bordes}]{D17-1070}
Alexis Conneau, Douwe Kiela, Holger Schwenk, Lo{\"i}c Barrault, and Antoine
  Bordes. 2017.
\newblock \href {https://doi.org/10.18653/v1/D17-1070} {Supervised learning of
  universal sentence representations from natural language inference data}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 670--680, Copenhagen, Denmark.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova}]{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
\newblock \href {https://www.aclweb.org/anthology/N19-1423} {{BERT}:
  Pre-training of deep bidirectional transformers for language understanding}.
\newblock In \emph{Proceedings of the Annual Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL-HLT)}, pages 4171--4186.

\bibitem[{Dolan et~al.(2004)Dolan, Quirk, and
  Brockett}]{dolan-quirk-brockett:2004:COLING}
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
\newblock \href {http://aclweb.org/anthology/C/C04/C04-1051.pdf} {Unsupervised
  construction of large paraphrase corpora: Exploiting massively parallel news
  sources}.
\newblock In \emph{Proceedings of the International Conference on Computational
  Linguistics (COLING)}, pages 350--356, Geneva, Switzerland.

\bibitem[{Edunov et~al.(2018)Edunov, Ott, Auli, and Grangier}]{D18-1045}
Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018.
\newblock \href {http://aclweb.org/anthology/D18-1045} {Understanding
  back-translation at scale}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 489--500, Brussels, Belgium.

\bibitem[{He and Lin(2016)}]{N16-1108}
Hua He and Jimmy Lin. 2016.
\newblock \href {https://doi.org/10.18653/v1/N16-1108} {Pairwise word
  interaction modeling with deep neural networks for semantic similarity
  measurement}.
\newblock pages 937--948, San Diego, California.

\bibitem[{Kauchak(2013)}]{P13-1151}
David Kauchak. 2013.
\newblock \href {http://aclweb.org/anthology/P13-1151} {Improving text
  simplification language modeling using unsimplified text data}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL)}, pages 1537--1546, Sofia, Bulgaria.

\bibitem[{Kingma and Ba(2015)}]{adam}
Diederik~P. Kingma and Jimmy Ba. 2015.
\newblock \href {http://arxiv.org/abs/1412.6980} {Adam: {A} method for
  stochastic optimization}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}.

\bibitem[{Kiros et~al.(2015)Kiros, Zhu, Salakhutdinov, Zemel, Urtasun,
  Torralba, and Fidler}]{NIPS2015_5950}
Ryan Kiros, Yukun Zhu, Ruslan~R Salakhutdinov, Richard Zemel, Raquel Urtasun,
  Antonio Torralba, and Sanja Fidler. 2015.
\newblock \href {http://papers.nips.cc/paper/5950-skip-thought-vectors.pdf}
  {Skip-thought vectors}.
\newblock In \emph{Proceedings of Conference on Neural Information Processing
  Systems (NeurIPS)}, pages 3294--3302.

\bibitem[{Lan et~al.(2017)Lan, Qiu, He, and Xu}]{D17-1126}
Wuwei Lan, Siyu Qiu, Hua He, and Wei Xu. 2017.
\newblock \href {https://doi.org/10.18653/v1/D17-1126} {A continuously growing
  dataset of sentential paraphrases}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1224--1234, Copenhagen, Denmark.

\bibitem[{Liu et~al.(2019)Liu, He, Chen, and Gao}]{bigbird}
Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019.
\newblock \href {https://arxiv.org/abs/1901.11504} {Multi-task deep neural
  networks for natural language understanding}.
\newblock \emph{arXiv}, 1901.11504.

\bibitem[{Logeswaran and Lee(2018)}]{logeswaran2018an}
Lajanugen Logeswaran and Honglak Lee. 2018.
\newblock \href {https://openreview.net/forum?id=rJvJXZb0W} {An efficient
  framework for learning sentence representations}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}.

\bibitem[{Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer}]{elmo}
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer. 2018.
\newblock \href {https://doi.org/10.18653/v1/N18-1202} {Deep contextualized
  word representations}.
\newblock In \emph{Proceedings of the Annual Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL-HLT)}, pages 2227--2237, New Orleans, Louisiana.

\bibitem[{Phang et~al.(2019)Phang, F\'evry, and Bowman}]{phang-arxiv-2018}
Jason Phang, Thibault F\'evry, and Samuel~R. Bowman. 2019.
\newblock \href {https://arxiv.org/abs/1811.01088} {Sentence encoders on
  {STILTs}: Supplementary training on intermediate labeled-data tasks}.
\newblock \emph{arXiv}, 1811.01088.

\bibitem[{Prabhumoye et~al.(2018)Prabhumoye, Tsvetkov, Salakhutdinov, and
  Black}]{P18-1080}
Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan~W Black.
  2018.
\newblock \href {http://aclweb.org/anthology/P18-1080} {Style transfer through
  back-translation}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL)}, pages 866--876, Melbourne, Australia.

\bibitem[{Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever}]{opeai-gpt}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018.
\newblock \href
  {https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf}
  {Improving language understanding by generative pre-training}.
\newblock Technical report, OpenAI.

\bibitem[{Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever}]{opeai-gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever. 2019.
\newblock \href
  {https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
  {Language models are unsupervised multitask learners}.
\newblock Technical report, OpenAI.

\bibitem[{Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and
  Liang}]{rajpurkar-etal-2016-squad}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.
\newblock \href {https://doi.org/10.18653/v1/D16-1264} {{SQ}u{AD}: 100,000+
  questions for machine comprehension of text}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 2383--2392, Austin, Texas.

\bibitem[{Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts}]{socher-EtAl:2013:EMNLP}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts. 2013.
\newblock \href {http://www.aclweb.org/anthology/D13-1170} {Recursive deep
  models for semantic compositionality over a sentiment treebank}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1631--1642, Seattle, Washington,
  USA.

\bibitem[{Subramanian et~al.(2018)Subramanian, Trischler, Bengio, and
  Pal}]{subramanian2018learning}
Sandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher~J Pal.
  2018.
\newblock \href {https://openreview.net/forum?id=B18WgG-CZ} {Learning general
  purpose distributed sentence representations via large scale multi-task
  learning}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}.

\bibitem[{Swayamdipta et~al.(2018)Swayamdipta, Thomson, Lee, Zettlemoyer, Dyer,
  and Smith}]{swabha:emnlp2018}
Swabha Swayamdipta, Sam Thomson, Kenton Lee, Luke Zettlemoyer, Chris Dyer, and
  Noah~A. Smith. 2018.
\newblock \href {http://aclweb.org/anthology/D18-1412} {Syntactic scaffolds for
  semantic structures}.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 3772--3782.

\bibitem[{Tai et~al.(2015)Tai, Socher, and
  Manning}]{tai-socher-manning:2015:ACL-IJCNLP}
Kai~Sheng Tai, Richard Socher, and Christopher~D. Manning. 2015.
\newblock \href {http://www.aclweb.org/anthology/P15-1150} {Improved semantic
  representations from tree-structured long short-term memory networks}.
\newblock In \emph{ACL-IJCLNLP}, pages 1556--1566, Beijing, China.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock \href
  {http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf} {Attention
  is all you need}.
\newblock In \emph{Proceedings of Conference on Neural Information Processing
  Systems (NeurIPS)}, pages 5998--6008.

\bibitem[{Wang et~al.(2019)Wang, Singh, Michael, Hill, Levy, and Bowman}]{glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
  Samuel~R. Bowman. 2019.
\newblock \href {https://openreview.net/forum?id=rJ4km2R5t7} {{GLUE}: A
  multi-task benchmark and analysis platform for natural language
  understanding}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}.

\bibitem[{Warstadt et~al.(2018)Warstadt, Singh, and
  Bowman}]{warstadt2018neural}
Alex Warstadt, Amanpreet Singh, and Samuel~R Bowman. 2018.
\newblock Neural network acceptability judgments.
\newblock \emph{arXiv}.

\bibitem[{Wieting and Gimpel(2018)}]{P18-1042}
John Wieting and Kevin Gimpel. 2018.
\newblock \href {http://aclweb.org/anthology/P18-1042} {{ParaNMT-50M}: Pushing
  the limits of paraphrastic sentence embeddings with millions of machine
  translations}.
\newblock In \emph{Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL)}, pages 451--462, Melbourne, Australia.

\bibitem[{Williams et~al.(2018)Williams, Nangia, and
  Bowman}]{williams-etal-2018-broad}
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.
\newblock \href {https://doi.org/10.18653/v1/N18-1101} {A broad-coverage
  challenge corpus for sentence understanding through inference}.
\newblock pages 1112--1122, New Orleans, Louisiana.

\bibitem[{Wu et~al.(2018)Wu, Wang, Liu, and Ma}]{D18-1408}
Wei Wu, Houfeng Wang, Tianyu Liu, and Shuming Ma. 2018.
\newblock \href {http://aclweb.org/anthology/D18-1408} {Phrase-level
  self-attention networks for universal sentence encoding}.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 3729--3738, Brussels, Belgium.

\bibitem[{Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, Macherey, Krikun,
  Cao, Gao, Macherey, Klingner, Shah, Johnson, Liu, Kaiser, Gouws, Kato, Kudo,
  Kazawa, Stevens, Kurian, Patil, Wang, Young, Smith, Riesa, Rudnick, Vinyals,
  Corrado, Hughes, and Dean}]{wordpiece}
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc~V. Le, Mohammad Norouzi, Wolfgang
  Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner,
  Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws,
  Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian,
  Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick,
  Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016.
\newblock \href {http://arxiv.org/abs/1609.08144} {{Google}'s neural machine
  translation system: Bridging the gap between human and machine translation}.
\newblock \emph{arXiv}, 1810.04805.

\bibitem[{Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and
  Le}]{xlnet}
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime~G. Carbonell, Ruslan Salakhutdinov,
  and Quoc~V. Le. 2019.
\newblock \href {http://arxiv.org/abs/1906.08237} {{XLNet}: Generalized
  autoregressive pretraining for language understanding}.
\newblock \emph{arXiv}, 1906.08237.

\bibitem[{Zhu et~al.(2015)Zhu, Kiros, Zemel, Salakhutdinov, Urtasun, Torralba,
  and Fidler}]{Zhu_2015_ICCV}
Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun,
  Antonio Torralba, and Sanja Fidler. 2015.
\newblock \href
  {https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhu_Aligning_Books_and_ICCV_2015_paper.pdf}
  {Aligning books and movies: Towards story-like visual explanations by
  watching movies and reading books}.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, pages 19--27.

\end{thebibliography}
