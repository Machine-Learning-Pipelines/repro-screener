\section{Computation of Hessian Eigenvalues and Eigenvectors}
\label{sec:appendix_eigencomp}
For Hessian approximated using Kronecker factorization, we compute $\E[\mM]$ and $\E[\vx\vx^T]$ explicitly. Let $\vm$ and $\vv$ be an eigenvector of $\E[\mM]$ and $\E[\vx\vx^T]$ respectively, with corresponding eigenvalues $\lambda_\vm$ and $\lambda_\vv$. Since both matrices are positive semi-definite, $\vm \otimes \vv$ is an eigenvector of $\E[\mM] \otimes \E[\vx\vx^T]$ with eigenvalue $\lambda_\vm\lambda_\vv$. In this way, since $\E[\mM]$ has $m$ eigenvectors and $\E[\vx\vx^T]$ has $n$ eigenvectors, we can approximate all $mn$ eigenvectors for the layer-wise Hessian. All these calculation can be done directly.

However, it is almost prohibitive to calculate the true Hessian explicitly. Thus, we use numerical methods with automatic differentiation \citep{paszke2017automatic} to calculate them. The packages we use is \citet{hessian-eigenthings} and we use the Lanczos method in most of the calculations. We also use package in \citet{yao2019pyhessian} as a reference.

For layer-wise Hessian, we modified the \citet{hessian-eigenthings} package. In particular, the package relies on the calculation of Hessian-vector product $\mH\vv$, where $\vv$ is a vector with the same size as parameter $\theta$. To calculate eigenvalues and eigenvectors for layer-wise Hessian at the $p$-th layer, we cut the $\vv$ into different layers. Then, we only leave the part corresponding to weights of the $p$-th layer and set all other entries to 0. Note that the dimension does not change. We let the new vector be $\vv^{(p)}$ and get the value of $\vu = \mH\vv^{(p)}$ using auto differentiation. Then, we do the same operation to $\vu$ and get $\vu^{(p)}$.