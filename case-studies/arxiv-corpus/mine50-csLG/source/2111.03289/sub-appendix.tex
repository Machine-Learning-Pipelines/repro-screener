


\section{Proofs for VOFUL2}

\subsection{Proof of Lemma \ref{lem:epc}}

\begin{proof}
  Let $W_t = V_0 + \sum_{s\in J,s\le t} x_s x_s^\T$.
  Then,
  \begin{align*}
    \del{\fr{d\tau + X^2|J|}{d} }^d
    &\ge \del{\fr{\tr(W_t)}{d} }^d 
    \\&\ge |W_t|   \tag{AM-GM ineq.}
    \\&= |V_0| \prod_{s\in J} (1 + \|x_s\|^2_{W_{s-1}^{-1} } ) \tag{rank-1 update equality for det.}
    \\&\ge |V_0| \prod_{s\in J} (1 + \|x_s\|^2_{V_{s-1}^{-1} } ) \tag{$W_{s-1} \preceq V_{s-1}$}
    \\&\ge \tau^d 2^{|J|}
    \\  \implies 
    |J| &\le \fr{d}{\ln(2)}\ln\del{1+\fr{X^2|J|}{d\tau} } 
  \end{align*}
  
  Let us generalize it so that we compute the number of times $\|x_s\|_{V_{t-1}^{-1}}^2 \ge q$ is true rather than $\|x_s\|_{V_{t-1}^{-1}}^2 \ge 1$ in which case we have
  \begin{align} \label{eq:20210425-01} 
    |J| &\le \fr{d}{\ln(1+q)}\ln\del{1+\fr{X^2|J|}{d\tau} } =: {A} \ln (1 + {B} |J|)
  \end{align}
  We want to solve it for $|J|$.
  We observe the following:
  \begin{align}
    |J| 
    \le A \ln(1 + B |J|) 
    &= A\del{\ln\del{\fr{|J|}{2A} } + \ln\del{2A(\fr{1}{|J|} + B) } } 
    \\&\le \fr{|J|}{2} + A \ln\del{\fr{2A}{e} \del{\fr{1}{|J|} + B } } 
    \\  \implies |J| &\le 2A \ln\del{\fr{2A}{e} \del{\fr{1}{|J|} + B } }  =  \fr{2}{\ln(1+q)} d \ln\del{\fr{2d}{e\ln(1+q)}\del{\fr 1 {|J|}  + \frac{ X^2}{ d\tau}}  }  \label{eq:20210425-03}
  \end{align}
  
  
  %
  %
  %With the usual technique, one can show that $\ln(a + b X) \le c X + f(X)$ for some $c$ and a function $f$, which leads to
  %\begin{align}\label{eq:20210425-2}
  %  |J| 
  %  &\le   \fr{2}{\ln(2)} d \ln\del{\fr{2}{e\ln(2)}\del{\fr d {|J|}  + \fr 1 \tau}  } 
  %  %  \\&\le cd \vee  \fr{2}{\ln(2)} d \ln\del{\fr{2}{e \ln(2)}\del{\fr 1 {c}  + \fr 1 \tau}  } \tag{case study with $|J|\le cd$ for any $c>0$}
  %  %  \\&\le \fr{2}{\ln(2)} d \ln\del{e + \fr{2}{e \ln(2) \tau}   } \tag{choose $c = \tfr{2}{e^2\ln(2)}$ }
  %\end{align}
  We fix $c>0$ and consider two cases:
  \begin{itemize}
    \item Case 1: $|J| < c d$ \\
    In this case, from~\eqref{eq:20210425-01}, we have $|J| \le \fr{d}{\ln(1+q)} \ln\del{1 + \fr{cX^2}{\tau} }  $ 
    \item Case 2: $|J| \ge cd$\\
    In this case, from~\eqref{eq:20210425-03} we have $ |J| \le  \fr{2}{\ln(1+q)} d \ln\del{\fr{2}{e \ln(1+q)}\del{\fr 1 {c}  + \fr {X^2} {\tau}}  }$
  \end{itemize}
  We set $c = \fr{2}{e \ln(1+q)}$ to obtain
  $   |J| \le \frac{2}{\ln(1+q)} d \ln \del{1 + \fr{2/e}{\ln(1+q)}\fr {X^2} {\tau}}  $.
  We remark that one can make the constant in front of the log to be $\frac{d}{\ln(1+q)}$ by plugging this bound into the RHS of~\eqref{eq:20210425-01}. 
\end{proof}

\subsection{Proof of Lemma \ref{lem:confset}}
\begin{proof}
  Let $\blue{\eps_s} := \eps_s(\th^*) = r_s - x^\T\th^*$.
  It suffices to show that the following is true w.p. at least $1 - \dt$, 
  \begin{align*}
      \forall \ell\in[L], k\in[K], \mu\in \cB_2^d(2), ~ \lt|\sum_{s=1}^{k} \clip{x_s^\T \mu }_\ell \eps_s\rt| \le  \sqrt{\sum_{s=1}^{k} \clip{x_s^\T\mu }_\ell^2 \eps^2_s \iota } +  2^{-\ell}\iota ~.
  \end{align*}
  To show this, we define ${\hcB_\ell}$ to be a ${\xi_\ell}$-net over $\mathbb{B}_2^d(2)$.
  with cardinality at most $\del{\fr{12}{\xi_\ell} }^d$.
  Such a net exists due to Lemma 4.1~\cite{pollard1990empirical}.
  Let us assume the following event, which happens with probability at least $1-6K\log_2(K)\sum_{\ell=1}^L |\hcB_\ell|$ by Lemma ~\ref{lem:du-thm4}:
  \begin{align}\label{eq:lem-conf}
    %\forall \ell\in[L], k\in[K],\mu'\in \hcB_\ell 
    \lt|\sum_{s=1}^{k} \clip{x_s^\T\mu' }_\ell \eps_s\rt| 
    \le 8\sqrt{\sum_{s=1}^{k} \clip{x_s^\T \mu' }_\ell^2 \eps_s^2 \ln(1/\dt)} +  16\cd 2^{-\ell}\ln(1/\dt)~. \tag{$\cE$}
  \end{align} 
  
  Let us fix $\ell \in [L]$, $k\in[K]$, and $\mu\in \mathbb{B}_2^d(2)$.
  Choose $\mu'\in \hcB_\ell$ such that $\|\mu - \mu'\|_2 \le\xi_\ell$.
  Then,
  \begin{align*}
    |\sum_{s=1}^{k} \clip{x_s^\T\mu} \eps_s|
    &\le  |\sum_{s=1}^{k} (\clip{x_s^\T\mu} - \clip{x_s^\T\mu'}) \eps_s| + |\sum_{s=1}^{k} \clip{x_s^\T\mu'} \eps_s|
    \\&\le \sum_{s=1}^{k} |\clip{x_s^\T\mu} - \clip{x_s^\T\mu'}| + |\sum_{s=1}^{k} \clip{x_s^\T\mu'} \eps_s| \tag{$|\eps_s|\le 1$}
    \\&\sr{(a)}{\le} k\xi_\ell + |\sum_{s=1}^{k} \clip{x_s^\T \mu'} \eps_s|
    \\&\le           k\xi_\ell + 8\sqrt{\sum_{s=1}^k \clip{x_s^\T\mu'}^2 \eps_s^2\ln(1/\dt)} + 16\cd 2^{-\ell}\ln(1/\dt)  \tag{by~\eqref{eq:lem-conf}}
    \\&\le k\xi_\ell + 8\sqrt{2\sum_{s=1}^k\del{ \clip{x_s^\T\mu}^2+\xi_\ell^2}\eps_s^2\ln(1/\dt)} + 16\cd 2^{-\ell}\ln(1/\dt)
    \\&\le k\xi_\ell +  \xi_\ell \cd 8\sqrt{2k\ln(1/\dt)} + 8\sqrt{2\sum_{s=1}^k \clip{x_s^\T\mu}^2\eps_s^2\ln(1/\dt)} + 16\cd 2^{-\ell}\ln(1/\dt)
    \\&\le           2^{-\ell}+2^{-\ell}\cd 8\sqrt{2\ln(1/\dt)} + 8\sqrt{2\sum_{s=1}^k \clip{x_s^\T\mu}^2\eps_s^2\ln(1/\dt)} + 16\cd 2^{-\ell}\ln(1/\dt)  \tag{choose $\xi_\ell = 2^{-\ell}/K$}
    \\&\le                       8\sqrt{2\sum_{s=1}^k \clip{x_s^\T\mu}^2\eps_s^2\ln(1/\dt)} + 32\cd 2^{-\ell}\ln(1/\dt) 
    \tag{by $1 \le \ln(1/\dt)$ }
  \end{align*}
  where $(a)$ follows from the fact that $|x_s^\top(\mu - \mu')|\le\eps$ and the observation that the clipping operation applied to two real values $z$ and $z'$ only makes them closer.
  It remains to adjust the confidence level.
  Note that
  \begin{equation*}
      \sum_{\ell=1}^L |\hcB_\ell|K = \sum_{\ell=1}^L (12K2^\ell)^dK\le 2(12K)^d \cd \frac{2^{Ld}}{2^d}\cd K \le (12K2^L)^{d+1}.
  \end{equation*}
  Thus,
  \begin{align*}
      6\log_2(K)\sum_{\ell=1}^L |\hcB_\ell|K \le (12K2^L)^{d+2}~.
  \end{align*}
  Replacing $\dt$ with $\dt/(12K2^L)^{d+2} $ and setting $\iota=128\ln((12K2^L)^{d+2}/\dt)$, we conclude the proof.
  We remark that we did not optimize the constants in this proof. 
\end{proof}




\subsection{Proof of Lemma \ref{lem:concreg-emp}}
\def\const{\mathsf{const}}
\begin{proof}
  Throughout the proof, every clipping operator $\clip{.}$ is a shorthand of $\clip{.}_\ell$. 
  For \ref{item:concreg-emp-1}, we note that
    \begin{align*}
    2^{-\ell}  \|\mu_k\|^{2} + \sum_{s=1}^{k} \clip{x_s^\top\mu_k}_\ell x_s^\top\mu_k 
    &= 2^{-\ell}  \|\mu_k\|^{2} + \sum_{s=1}^{k} \del{\del{1\wedge \fr{2^{-\ell}}{|x_s^\T\mu_k| } } x_s}^\top\mu_k x_s^\top\mu_k 
    \\&= \mu_k^\top\del{2^{-\ell}\lam I {+} \sum_{s=1}^{k} \del{1\wedge \fr{2^{-\ell}}{|x_s^\T\mu_k| } } x_s x_s^\top }\mu_k 
    \\&= \|\mu_k\|^2_{W_{\ell,k-1}}~.
  \end{align*} 
  Then,
  \begin{align*}
    &\|\mu_k\|_{(W_{\ell,k-1} - 2^{-\ell}  I )}^2 
    \\&= \sum_{s=1}^{k-1} \clip{x_s^\T\mu_k} x_s^\T\mu_k 
    \\&= \sum_{s=1}^{k-1} \clip{x_s^\T\mu_k} (x_s\th_k - r_k + r_k - x_s\th^*) 
    \\&= \sum_{s=1}^{k-1} \clip{x_s^\T\mu_k} (-\eps_s(\th_k) + \eps_s(\th^*)) 
    \\&\le  \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 \eps^2_s(\th_k) \iota}  + 2^{-\ell} \iota + \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 \eps_s^2(\th^*) \iota} + 2^{-\ell} \iota  
    \\&\sr{(a)}{\le} \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 2(x_s^\T\mu_k)^2 \iota}  + 2 \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 2\eps_s^2(\th^*) \iota} + 2 \cd 2^{-\ell} \iota
    \\&\le \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 2(x_s^\T\mu_k)^2 \iota}  + 2^{-\ell}\sqrt{4\del{ \sum_{s=1}^{k-1} 8\sig_s^2 + 4 \ln(\fr{4 K (\log_2(K) + 2)}{\dt}) } \iota} + 2\cd2^{-\ell} \iota
        \tag{By $\cE_2$}
    \\&\le \sqrt{\sum_{s=1}^{k-1} \clip{x_s^\T\mu_k}^2 2(x_s^\T\mu_k)^2 \iota}  +  2^{-\ell}\sqrt{32 \sum_{s=1}^{k-1} \sig_s^2 \iota } + 3\cd 2^{-\ell} \iota 
    \\&\le \sqrt{4\sum_{s=1}^{k-1} 2^{-\ell} \clip{x_s^\T\mu_k} (x_s^\T\mu_k) \iota}  + 2^{-\ell}\sqrt{ 32 \sum_{s=1}^{k-1} \sig_s^2 \iota } + 3\cd 2^{-\ell} \iota          \tag{$|x_s^\T\mu_k |\le 2, \clip{\cd} \le 2^{-\ell}$  }
    \\&= \sqrt{4\cd 2^{-\ell} \|\mu\|_{(W_{\ell,k-1} - 2^{-\ell}  I )}^{2}  \iota}  + 2^{-\ell}\sqrt{32 \sum_{s=1}^{k-1} \sig_s^2 \iota } + 3\cd2^{-\ell} \iota
  \end{align*}
  where $(a)$ follows from $\eps^2_s(\th_k) = (r_s - x_s\th_k)^2 = (x_s^\top(\th_* - \th_k) + \eps_s^2(\th^*)) \le 2(x_s^\T\mu_k)^2 + 2\eps_s^2$.
  We now have $\|\mu\|_{(W_{\ell,k-1} - 2^{-\ell}  I )}^{2}$ on both sides.
  Using $X \le A + \sqrt{B X} \le A + (B/2) + (X/2) \implies X \le 2A + B$, we have
  \begin{align*}
    \|\mu_k\|_{(W_{\ell,k-1} - 2^{-\ell}  I )}^2 
    &\le 2^{-\ell}\sqrt{128\sum_{s=1}^{k-1} \sig_s^2 \iota}   + 8\cd 2^{-\ell}\iota
    \\\implies     \|\mu_k\|_{W_{\ell,k-1}}^2 
    &\le 4\cd 2^{-\ell} + 2^{-\ell}\sqrt{128\sum_{s=1}^{k-1} \sig_s^2 \iota}   + {8}\cd 2^{-\ell}\iota.
  \end{align*}
  Since $1 \le \ln(1/\dt)$, we have $4 \cd 2^{-\ell}  \le 4 \cd 2^{-\ell} \ln(1/\dt) \le 2^{-\ell}\iota$, which concludes the proof of \ref{item:concreg-emp-1}.
 
  
  For \ref{item:concreg-emp-2}, let $c$ be an absolute constant that may be different every time it is used.
  We apply Cauchy-Schwarz inequality to obtain
  \begin{align*}
    (x_k^\T\mu_k)^2
    &\le \|x_k\|^2_{W_{\ell,k-1}^{-1}}  \|\mu_k\|^2_{W_{\ell,k-1}} 
    \\&\le \|x_k\|^2_{W_{\ell,k-1}^{-1}}  \cd c \cd \del{2^{-\ell}\sqrt{\sum_{s=1}^{k-1}\sig_s^2 \iota} + 2^{-\ell}\iota  }
    \\&\le \|x_k\|^2_{W_{\ell,k-1}^{-1}}  \cd c \cd x_k^\T\mu_k \del{\sqrt{\sum_{s=1}^{k-1}\sig_s^2 \iota} + \iota  }  \tag{$2^{-\ell}\le x_k^\T\mu_k \le 2^{-\ell + 1}$  }
  \end{align*}
  Dividing both sides by $x_k^\T\mu_k$ concludes the proof.
\end{proof}


\subsection{$d\sqrt{K}$ regret bound of VOFUL2}
\label{sec:dsqrtK}

Let us slightly modify the algorithm so we now add $\Theta_k^{\ell}$ with $\ell=0$:
\begin{align*}
  \Theta_k = \cap_{\ell=0}^{L} \Theta_k^\ell~.
\end{align*}
Let us call this algorithm VOFUL3.
Note that this slight change will not alter the order of the regret bound of VOFUL2 reported in Theorem~\ref{main-thm-bandit}.

Let $\lam>0$ be an analysis parameter to be determined later.
Let $X_k \in \RR^{k\times d}$ be the design matrix where row $s$ is $x_s^\T$ and define $y_k := (r_1,\ldots,r_k)^\T$, $\eta_k := (\eps_1,\ldots,\eps_k)^\T$.
Let $V_k := \lam I + X_k^\T X_k$ and 
\begin{align}\label{eq:ridge}
  \hth_k := V_k^{-1} X_k^\T y_k
\end{align}
We claim that
\begin{align*}
  \Theta_k  \subseteq \cbr{\th \in \BB_2^d(1):   \norm{\hth_k - \th}_{V_k}^2 \le \beta_k } =: \mathring{\Th}_k
\end{align*}
for some $\beta_k = \tilde O(d + \ln(1/\dt))$.
This suffices to show that the VOFUL2 has regret bound of $\tilde O(d\sqrt{K})$ since the proof technique of OFUL~\cite{ay11improved} can be immediately applied since the UCB computed based on $\Th_k$ is bounded above by the UCB computed with $\mathring{\Th}_k$.
Thus, VOFUL3 has regret bound of
\begin{align*}
  \mathcal{R}^K =\tilde O\del{d\sqrt{K \ln(1/\dt)},~ d^{1.5} \sqrt{\sum_{k=1}^K \sig_k^2\ln(1/\dt)} + d^2 \ln(1/\dt)} ~.
\end{align*}

To see why the claim above is true, let $\th \in \Theta_k$.
Then, using $\eps_s^2(\th) \le 4$, we have, $\forall \mu \in \BB_2^d(2)$,
\begin{align*}
  |\sum_s \mu^\T x_s(y_s - x_s^\T\th)| \le \norm{\mu}_{\sum_{s=1}^k x_s x_s^\T} \cd \sqrt{4\iota} + \iota
\end{align*}
Let us drop the subscript $k$ from $\cbr{\hth_k, V_k, X_k, y_k, \eta_k}$ for brevity.
The display above can be rewritten as
\begin{align*}
  \mu^\T (X^\T y - X^\T X \th)
  = \mu^\T V(\hth - \th) + \lam \mu^\T \th 
  &\le \norm{\mu}_{X^\T X} \cd \sqrt{4\iota}   + \iota
  \\\implies
  \mu^\T V(\hth - \th) \le \norm{\mu}_{V} \cd \sqrt{4\iota}   + \iota + 2\lam \tag{$\|\th\|_2 \le 1, |\mu^\T\th|\le 2$ }
\end{align*}
We can choose $\mu = \fr{1}{2}(\hth - \th)$ since $\fr{1}{2}\|\hth - \th\|_2 \le \fr12 (\|\hth\|_2 + \|\th\|_2)\le 2$ by Lemma~\ref{lem:rls_norm_bound}  and the choice of $\lam$ therein.
Then,
\begin{align*}
  \norm{\hth - \th}_V^2 &\le \norm{\hth - \th}_V \sqrt{4\iota}  + 2\iota + 4\lam
  \\ \implies
  \norm{\hth - \th}_V^2 &\le 8\iota + 8\lam  \tag{AM-GM ineq. on $\norm{\hth - \th}_V \sqrt{4\iota}$}
  \\&= \tilde O(d + \ln(1/\dt))
\end{align*}



\begin{lemma}\label{lem:rls_norm_bound}
  Take the assumptions for the linear bandit problem in Section~\ref{sec:prelim}. % except that $\|\th^*\|_2 \le S$ for some $S$.
  Consider $\hth_k$ defined in~\eqref{eq:ridge} with  $\lam = d\ln(1+\fr{K}{d}) + 2 \ln(1/\dt)$.
  Let $K \ge (e-1)d$.
  Then, with probability at least $1-\dt$, we have, 
  \begin{align*}
    \forall k \le K, \|\hth_k\|_2 \le 3.
  \end{align*}
\end{lemma}
\begin{proof}
  Let us drop the subscript $k$ from $\cbr{\hth_k, V_k, X_k, y_k, \eta_k}$.
  Then,
  \begin{align*}
    \|\hth\|_2
    &\le \|\hth - \th^*\|_2 + \|\th^*\|_2~.
  \end{align*}
  Note that $\norm{\th^*}_2 \le 1$.
  We can further bound the first term:
  \begin{align*}
    \|\hth - \th^*\|_2
    &=   \|V^{-1}(X^\T\eta - \lam \th^*) \|_2
    \\&\le \|V^{-1}X^\T \eta\|_2 + \lam \| V^{-1} \th^*\|_2~.
  \end{align*}
  Note that 
  \begin{align*}
    \lam \|V^{-1}\th^*\|_2 = \lam \sqrt{{\th^*}^\T V^{-2} \th^*} 
    \le \lam \sqrt{{\th^*}^\T (\fr1{\lam^2} I) \th^* } 
    \le \|\th^*\|_2 \le 1~.
  \end{align*}
  It remains to bound $ \|V^{-1}X^\T \eta\|_2$.
  To see this,
  \begin{align*}
    \|V^{-1}X^\T \eta\|_2 
    &= \sqrt{\eta^\T X V^{-2} X^\T \eta} 
    \\&= \sqrt{\eta^\T X V^{-1} (\fr1\lam \cd \lam I)  V^{-1} X^\T \eta} 
    \\&\le \sqrt{\eta^\T X V^{-1} (\fr1\lam \cd V)  V^{-1} X^\T \eta} 
    \\&= \fr{1}{\sqrt{\lam} } \|X^\T\eta\|_{V^{-1}}
    \\&\le \fr{1}{\sqrt{\lam} } \del{ \sqrt{d\ln(1+\fr{k}{d\lam}) + 2 \ln(1/\dt)} } \tag{\citet[Theorem 1]{ay11improved}}
    %    \\&\le \fr{1}{\sqrt{\lam} } \sqrt{d\ln(1+\fr{k}{d\lam}) + 2 \ln(1/\dt)}
    \\&\sr{(a)}{\le} 1
  \end{align*}
  where $(a)$ is by choosing $\lam = d\ln(1+\fr{K}{d}) + 2 \ln(1/\dt)$ and then using  $\lam \ge 1$ (due to $K \ge (e-1)d$).
\end{proof}


\subsection{Miscellaneous Lemmas}

For completeness, we state the lemmas borrowed from prior work.
\begin{lemma}\label{lem:du-thm4}(\citet[Lemma 9]{zhang21variance})
  Let $\left\{\mathcal{F}_{i}\right\}_{i=0}^{n}$ be a filtration. Let $\left\{X_{i}\right\}_{i=1}^{n}$ be a sequence of real-valued random variables such that $X_{i}$ is $\mathcal{F}_{i}$-measurable. We assume that $\mathbb{E}\left[X_{i} \mid \mathcal{F}_{i-1}\right]=0$ and that $\left|X_{i}\right| \le b$ almost surely. For $\delta<e^{-1}$, we have
  \begin{align*}
    \PP\del{|\sum_{i=1}^{^n} X_i| \le 8 \sqrt{\sum_{i=1}^{n}X_i^2 \ln(1/\dt)} + 16 b \ln(1/\dt) }  \ge 1 - 6\dt \log_2(n)
  \end{align*}
\end{lemma}

\begin{lemma}
  \label{lem:du-lem10}(\citet[Lemma 10]{zhang21variance})
  Let $\left\{\mathcal{F}_{i}\right\}_{i \ge 0}$ be a filtration. Let $\left\{X_{i}\right\}_{i=1}^{n}$ be a sequence of random variables such that $\left|X_{i}\right| \leq 1$ almost surely, that $X_{i}$ is $\mathcal{F}_{i}$-measurable. For every $\delta \in(0,1)$, we have
  $$
  \PP\left[\sum_{i=1}^{n} X_{i}^{2} \ge \sum_{i=1}^{n} 8 \mathbb{E}\left[X_{i}^{2} \mid \mathcal{F}_{i-1}\right]+4 \ln \frac{4}{\delta}\right] \leqslant\left(\left\lceil\log _{2} n\right\rceil+1\right) \delta
  $$
\end{lemma}




\section{Proofs for VARLin2}

Throughout the proof, we use $c$ as absolute constant that can be different every single time it is used.



\subsection{Proof of Lemma \ref{lem:optimism}}
\begin{proof}
Assume that $\th^* \in \Theta_k$ for all $k\in[K]$. Since $\th^* \in \Theta_k$,
\begin{align*}
    Q_h^k(s,a)&=\min\{r(s,a)+\max_{\th \in \Theta_k} \sum_{i=1}^d\th_iP_{s,a}^i V_{h+1}^k\}
    \\&\ge \min \{1,r(s,a)+\sum_{i=1}^d\theta_i^*P_{s,a}^iV_{h+1}^k\}
    \\&\ge \min \{1,r(s,a)+\sum_{i=1}^d\theta_i^*P_{s,a}^iV_{h+1}^*\}
    \\&=Q_h^*(s,a),
\end{align*}
so the statement follows.
\end{proof}

\subsection{Proof of Lemma \ref{lem:confset-rl} }

\begin{proof} 
\def\VV{\mathbb{V}}
\def\EE{\mathbb{E}}
\def\cF{\mathcal{F}}
Similar to the linear bandit case, let $\hcB_\ell$ be a $\xi_\ell$-net over $\mathbb{B}_1^d(2)$ with cardinality at most $(\frac{12}{\xi_\ell})^d$ and pick $\mu \in \mathbb{B}_1^d(2)$ and $\mu'\in \hcB_\ell$ such that the distance between them is at most $\xi_\ell$. Let us define the conditional variance $\VV_{v,u}[\eps^m_{v,u}] := \VV[\eps^m_{v,u} \mid \cF_{u}^v]$ where $\cF_{u}^v$ denotes history up to (and including) episode $v$ and time horizon $u$.
%Set $\eta_{k,h}^m = (\th^*)^\T x_{k,h}^{m+1}-((\th^*)^\T x_{k,h}^m)^2$ \kj{this notation conflicts with $\eta^m_{k,h}$ from the main text. Following E.3 of Zhang et al, we can just use $\VV[\eps^m_{v,u} \mid \cF_{u-1}^v]$ instead (todo: define $\cF_{u}^v$ as the $\sig$-algebra generated by the random variables up to (and including) episode $v$ and horizon $u$). Then, we can use $\VV_{v,u}[\eps^m_{v,u}] := \VV[\eps^m_{v,u} \mid \cF_{u}^v] \le ... \le \eta^m_{v,u}$ by Jensen's inequality.} and $\eps_{v,u}^m = (\theta^*)^\T x_{v,u}^m - (V_{u+1}^v (s_{u+1}^v))^{2^m}$.

% \kj{Q: did we define $\VV_{v,u}$?}
Noticing
\begin{align*}
  \VV_{v,u}[\eps^m_{v,u}] 
  &= \EE_{v,u}[(\eps^m_{v,u})^2]
\\&= ((\th^* )^\T x^{m}_{v,u})^2 - 2 ((\th^* )^\T x^{m}_{v,u}) \cd \EE_{v,u}[ (V^v_{u+1}(s^v_{u+1}))^{2^m} ] + \EE_{v,u}[ \del{(V_{u+1}^v(s^v_{u+1}))^{2^m} }^2],
\end{align*}
% Using Jensen's inequality, $((\th^*)^\T x^m_{v,u} )^2 \le (\th^*)^\T x^{m+1}_{v,u}$.
$\EE_{v,u}[ (V^v_{u+1}(s^v_{u+1}))^{2^m} ] = (\th^* )^\T x^{m}_{v,u}$, and $\EE_{v,u}[ \del{(V_{u+1}^v(s^v_{u+1}))^{2^m} }^2] = (\th^*)^\T x^{m+1}_{v,u}$, we have
$$\VV_{v,u}[\eps^m_{v,u}]  = (\th^*)^\T x^{m+1}_{v,u} - ((\th^*)^\T x^{m}_{v,u})^2.$$

%{
%\color{red}
%Zhang's paper
%$$\VV_{v,u-1}[\eps^m_{v,u}]  \le  (\th^*)^\T x^{m+1}_{v,u} - ((\th^*)^\T x^{m}_{v,u})^2 \le \eta_{v,u}^m$$
%}

We apply Lemma \ref{ineq} with $\eps=1$, $b=2^{-\ell}$ to obtain 
\begin{equation*}
    \lt|\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T \mu' }_\ell \eps_{v,u}^{m}\rt| \leq 4\sqrt{\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu' }_\ell^2 \VV[\eps^m_{v,u} \mid \cF_{u}^v] } +  4 \cdot 2^{-\ell} \ln(1/\dt)
\end{equation*}
with probability at least $1-\delta(1+\log_2 (HK))$ and repeat the similar procedure by taking the union bound. 
We drop $\ell$ from the clipping notation for the sake of brevity. 
%  \begin{align*}
%    &|\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}}  \clip{(x_{v,u}^m)^\T \mu } \eps_{v,u}^{m}|
%    \\&=   |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} (\clip{(x_{v,u}^m)^\T \mu} - \clip{(x_{v,u}^m)^\T\mu'}) \eps_{v,u}^m| + |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'} \eps_{v,u}^m| 
%    \\&\le \sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} |\clip{(x_{v,u}^m)^\T\mu} - \clip{(x_{v,u}^m)^\T\mu'}| + |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'} \eps_{v,u}^m| \tag{$|\eps_s|\le 1$}
%   \\&\le HK\xi_\ell  + 4\sqrt{\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'}^2 \eta_{v,u}^m \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
%    \\&\le HK \xi_\ell + 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \{\clip{(x_{v,u}^m)^\T\mu}^2 +\xi_\ell^2\}\eta_{v,u}^m \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
%    \\&\le HK \xi_\ell +4\xi_\ell\sqrt{2HK\ln(1/\dt)}+ 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu}^2 \eta_{v,u}^m \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
%    \\&\le 2^{-\ell} + 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{{x_{v,u}^{m}}^\T\mu}^2\ln(1/\dt)} + (4\sqrt{2}+4) \cd 2^{-\ell}  \ln(1/\dt)  \tag{choose $\xi_\ell = 2^{-\ell}/(HK)$}
%    \\&\le                       4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}}\clip{{x_{v,u}^{m}}^\T\mu}^2 \eta_{v,u}^m \ln(1/\dt)} + 12\cd 2^{-\ell}\ln(1/\dt) 
%    \tag{by $1 \le \ln(1/\dt)$ }
%  \end{align*}

  \begin{align*}
    &|\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}}  \clip{(x_{v,u}^m)^\T \mu } \eps_{v,u}^{m}|
    \\&=   |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} (\clip{(x_{v,u}^m)^\T \mu} - \clip{(x_{v,u}^m)^\T\mu'}) \eps_{v,u}^m| + |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'} \eps_{v,u}^m| 
    \\&\le \sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} |\clip{(x_{v,u}^m)^\T\mu} - \clip{(x_{v,u}^m)^\T\mu'}| + |\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'} \eps_{v,u}^m| \tag{$|\eps_s|\le 1$}
    \\&\le HK\xi_\ell  + 4\sqrt{\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu'}^2 \VV[\eps^m_{v,u} \mid \cF_{u}^v] \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
    \\&\le HK \xi_\ell + 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \{\clip{(x_{v,u}^m)^\T\mu}^2 +\xi_\ell^2\}\VV[\eps^m_{v,u} \mid \cF_{u}^v] \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
    \\&\le HK \xi_\ell +4\xi_\ell\sqrt{2HK\ln(1/\dt)}+ 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{(x_{v,u}^m)^\T\mu}^2 \VV[\eps^m_{v,u} \mid \cF_{u}^v] \ln(1/\dt)} + 4\cd 2^{-\ell}\ln(1/\dt)
    \\&\le (4\sqrt{2}+5) \cd 2^{-\ell}  \ln(1/\dt) + 4\sqrt{2\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{({x_{v,u}^{m}})^\T\mu}^2\VV[\eps^m_{v,u} \mid \cF_{u}^v]\ln(1/\dt)}  \tag{choose $\xi_\ell = 2^{-\ell}/(HK)$}
        \\&\le 4 \cd 2^{-\ell}  \ln(1/\dt') + 4\sqrt{\sum_{(v,u)\in \mathcal{T}_{k,H}^{m,i}} \clip{({x_{v,u}^{m}})^\T\mu}^2\eta_{v,u}^m\ln(1/\dt')}  \tag{setting $\dt = {\dt'}^{1/3}$}
    \end{align*}
We then take union bounds over $m \in \{1,2,...,L\}$, $i,\ell \in [L]$, $k\in[K]$, and $\mu' \in \hcB_\ell$, which invoke applying Lemma \ref{ineq} $(2HK)^{2(d+2)}$ times. It follows from
\begin{equation*}
    \sum_{i,\ell,k} |\hcB_\ell| = L_0 L K \sum_{\ell} (HK2^\ell)^d \le (HK)^2 (HK)^d\frac{2^{Ld}}{2^d} \le (HK2^{L})^{d+2} \le (2HK)^{2(d+2)}.
\end{equation*}
Hence, the display above holds with probability at least $1-{\dt}(1+\log_2(HK))(2HK)^{2(d+2)}\ge 1-\dt (2HK)^{2(d+3)}$. Replacing $\dt$ with $ 1/(2HK)^{2(d+3)}\cd \dt$ and setting $\iota=3\cd\ln((2HK)^{2(d+3)}/\dt)$ the result follows.

\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Proof of Lemma \ref{lem:epc2}}
\begin{proof}
  Lemma 12 of~\citet{ay11improved} shows the following in its proof: Let $A$, $B$, and $C$ be positive semi-definite (PSD) matrices such that $A = B + C$. Then we have that 
  \begin{align*}
    \sup_{x\neq 0 }\fr{\|x\|^2_{A} }{\norm{x}^2_B}  \le \fr{\det(A)}{\det(B)} ~.
  \end{align*}
  Note that $V^{-1}_{\anc(t)} = V^{-1}_{t-1} + C$ for some PSD matrix $C$ (to see this, apply a series of rank-one update formula for the covariance matrix).
  Thus, we have that if $t \in J$, then
  \begin{align*}
    r < \fr{\norm{x_t}^2_{V_{\anc(t)}^{-1}}}{\norm{x_t}^{2}_{V_{t-1}^{-1}} }  
    \le \fr{|V^{-1}_{\anc(t)}|}{|V_{t-1}^{-1}|} 
    =   \fr{|V_{t-1}|}{|V_{\anc(t)}|}  ~.
  \end{align*}
  Let ${J[t]} = J \cap [t]$ with $[0] := \emptyset$.
  Let $\prev(t)$ be the time step in $J$ immediately prior to $t$: $\prev(t) := \max\{s\in \{0\} \cup J: s < t\}$ 
  Define ${W_t} = V_0 + \sum_{s\in J[t]} x_s x_s^\T$.
  \begin{align*}
    \del{\fr{d\lam + X^2|J|}{d} }^d
    &\ge \del{\fr{\tr(W_T)}{d} }^d
    \\&\ge |W_T| \tag{AM-GM ineq.}
    \\&= |V_0| \prod_{t\in J} \fr{|W_t|}{|W_{\mathsf{prev}(t)}|} 
    \\&\ge |V_0| \prod_{t\in J} \fr{|W_t|}{|W_{\anc(t)}|}  \tag{$ \mathsf{prev}(t) \le \anc(t)$ }
    \\&= |V_0| r^{|J|}
    \\&\ge \lam^d r^{|J|}
    \\  \implies 
    |J| &\le \fr{d}{\ln(r)}\ln\del{1+\fr{X^2|J|}{d\lam} } 
  \end{align*}
  Then, 
  \begin{align} \label{eq:20210425-0} 
    |J| &\le \fr{d}{\ln(r)}\ln\del{1+\fr{X^2|J|}{d\lam} } =: {A} \ln (1 + {B} |J|)
  \end{align}
  We want to solve it for $|J|$.
  Do the following:
  \begin{align}
    |J| 
    \le A \ln(1 + B |J|) 
    &= A\del{\ln\del{\fr{|J|}{2A} } + \ln\del{2A(\fr{1}{|J|} + B) } } 
    \\&\le \fr{|J|}{2} + A \ln\del{\fr{2A}{e} \del{\fr{1}{|J|} + B } } 
    \\  \implies |J| &\le 2A \ln\del{\fr{2A}{e} \del{\fr{1}{|J|} + B } }  =  \fr{2}{\ln(r)} d \ln\del{\fr{2d}{e\ln(r)}\del{\fr 1 {|J|}  + \frac {X^2} {d\lam}}  }  \label{eq:20210425-3}
  \end{align}
  
  We fix $c>0$ and consider two cases:
  \begin{itemize}
    \item Case 1: $|J| < cd$ \\
    In this case, from~\eqref{eq:20210425-0}, we have $|J| \le \fr{d}{\ln(r)} \ln\del{1 + \fr{cL^2}{\lam} }  $ 
    \item Case 2: $|J| \ge cd$\\
    In this case, from~\eqref{eq:20210425-3} we have $ |J| \le  \fr{2}{\ln(r)} d \ln\del{\fr{2}{e \ln(r)}\del{\fr 1 {c}  + \frac{X^2}{ \lam}}  }$
  \end{itemize}
  We set $c = \fr{2}{e \ln(r)}$ to obtain
  $   |J| \le \frac{2}{\ln(r)} d \ln \del{1 + \fr{2/e}{\ln(r)}\frac {X^2} {\lam}}  $.
\end{proof}


\subsection{Proof of Lemma \ref{lem:concreg-emp-rl}}
%\gray{ \begin{align*}
%    \|\mu_{k,h}^m \|_{(W_{\anc(a)}^{m,i,\ell} - 2^{-\ell} I )}^2 
%    &= \sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{(x_{v,u}^m)\mu_{k,h}^m} (x_{v,u}^m)\mu_{k,h}^m 
%    \\&= \sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{(x_{v,u}^m)\mu_{k,h}^m} (-\eps_{v,u}^m(\th_{k,h}^m) + \eps_{v,u}^m(\th^*)) 
%    \\&\le  \sqrt{\sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{x_{v,u}\mu_{k,h}^m}^2 \eta_{v,u}^m(\th_{k,h}^m) \iota}  + 4\cd 2^{-\ell} \iota + 4\sqrt{\sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{(x_{v,u}^m)\mu_{k,h}^m}^2 \eta_{v,u}^m(\th^*) \iota} + 4\cd2^{-\ell} \iota 
%    \\&\le 2\sqrt{\sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{(x_{v,u}^m)\mu_{k,h}^m}^2\cd 2^{-i} \iota}+8\cd 2^{-\ell}\iota 
%        \\&\le 2\sqrt{\sum_{(v,u)\in \mathcal{T}_{k-1,H}^{m,i}} \clip{(x_{v,u}^m)\mu_{k,h}^m}x_{v,u}^m)\mu_{k,h}^m \cd 2^{-i} \iota}+8\cd 2^{-\ell}\iota 
%    \\& \le 2\|\mu_{k,h}^m\|_{W_{\anc(a)}^{m,i,\ell}}\sqrt{2^{-i}\iota}+8\cd 2^{-\ell}\iota
%  \end{align*}
%Solving for $\|\mu_{k,h}^m\|_{W_{\anc(a)}^{m,i,\ell}}$, we get the desired bound.
%}
%\kj{how about the following?}

Recall that $\th_t^m=\argmax_{\th \in \Th_{k-1}} |\{\th x_t^{m+1}-(\th x_t^{m})^2\}|$ and $\eta_b^m(\th)=\th x_b^{m+1}-(\th x_b^{m+1})^2$
  We have
  \begin{align*}
  \|\mu_{t}^m \|_{(W_{\anc(t)}^{m,i,\ell} - 2^{-\ell} I )}^2 
  &= \sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m} (x_{b}^m)\mu_{t}^m 
  \\&= \sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m} (-\eps_{b}^m(\th_{t}^m) + \eps_{b}^m(\th^*)) 
  \\&\le  \sqrt{\sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m}^2 \eta_{b}^m(\th_{t}^m) \iota}  + 4\cd 2^{-\ell} \iota + 4\sqrt{\sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m}^2 \eta_{b}^m(\th^*) \iota} + 4\cd2^{-\ell} \iota 
  \\&\le C\sqrt{\sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m}^2\cd 2^{-i} \iota}+8\cd 2^{-\ell}\iota %\tag{\kj{$\eta^m_b \le 2\cd 2^{-i}$, and $\eta^m_b(\th^*) \le \eta^m_b$, right? do we have the right const here?}}
  \\&\le C\sqrt{\sum_{b\in \mathcal{T}_{\anc(t)}^{m,i}} \clip{(x_{b}^m)^\top\mu_{t}^m} (x_{b}^m)^\T\mu_{t}^m \cd 2^{-i} \iota}+8\cd 2^{-\ell}\iota
  \\& \le C\|\mu_{t}^m\|_{W_{\anc(t)}^{m,i,\ell}}\sqrt{2^{-i}\iota}+8\cd 2^{-\ell}\iota
\end{align*}
Solving for $\|\mu_{t}^m\|_{W_{\anc(t)}^{m,i,\ell}}$, we get the desired bound.

\subsection{The Exact Definition of $I_{k,h}$ and Proof of Lemma~\ref{lem-I}}\label{proof_of_lem_I}

%Fix $m$, $i$, $\ell$ and let us denote $x_{k,h}$ and $\mu_{k,h}$ by $x_a$ and $\mu_a$ with $D[a]=(k,h)$. %Hence we can further define $\cT_a^{m,i}:=\cT_{D[a]}^{m,i}$. 
Fix $m$ and $i$.
Let $t \in \cT^{m,i}_T$ and $\ell = \ell^m_t$.
We recall Lemma~\ref{lem:concreg-emp-rl} that yields
\begin{align*}
 \norm{\mu^m_{t}}_{W^{m,i,\ell}_{\anc(t)}} 
  &\le c_M \cd \max\{\sqrt{2^{-i} \iota}, \sqrt{2^{-\ell}\iota} \}
\end{align*}

Let us define $\blue{\mathcal{T}^{m,i,\ell}}=\{t \in \cT_T^{m,i}: (x_{t}^m)^\T \mu_{t}^m \in (2\cd2^{-\ell},2\cd 2^{1-\ell}])\}$
and split the time steps $\cT^{m,i,\ell}$  as follows:
\begin{align*}
  \blue{\cT^{m,i,\ell,\la1\ra}} := \cbr{t \in \cT^{m,i,\ell}: \norm{\mu^m_{t}}_{W^{m,i,\ell}_{\anc(t)}} \le c_M \sqrt{2^{-i} \iota} }  
  \text{~~~ and ~~~} 
  \blue{\cT^{m,i,\ell,\la2\ra}} := \cT^{m,i,\ell}  \sm \cT^{m,i,\ell,\la1\ra} ~.
\end{align*}

Given $t \in [T]$, let $\blue{n_t^{m,i,\ell,\la1\ra}}$ be $n \in \{0,\ldots,\ell\} $ such that
\begin{align*}
  \max_{t':t \le t'\in \cT^{m,i,\ell,\la1\ra}} |(x^m_{t})^\T\mu^m_{t'}| \in \lt\lparen \onec{n \neq 0} \cd 2^{-\ell+n}, 2^{-\ell+n+1}  \rt\rbrack 
\end{align*}
where we set $n=0$ if the maximum above is less or equal to $2^{-\ell}$.

Let $\blue{\cT^{m,i,\ell,\la1\ra,n}} = \cT^{m,i,\ell,\la1\ra} \cap \{t: n_t^{m,i,\ell,\la1\ra} = n\}$ and
set $\blue{V^{m,i,\ell,\la1\ra,n}_{t}} := 2^{-\ell}I + \sum_{b \in \cT^{m,i,\ell,\la1\ra,n}_{t}} x^m_{b}  (x^m_{b})^\T$ with $\blue{\cT_t^{m,i,\ell,\la z \ra,n}} :=\{a'\le a:a'\in \cT^{m,i,\ell,\la z \ra,n}\}$.

Define
\begin{align*}
    \blue{I^{m,i,\ell,\la1\ra,n}_{t}} := \onec{\forall t'\in \cT^{m,i,\ell,\la1\ra,n}_{t} \text{ with } \sfk(t')=\sfk(t),~   \norm{x_{t'}}^2_{(V^{m,i,\ell,\la1\ra,n}_{\anc(t')})^{-1}} \le r \norm{x_{t'}}^2_{(V^{m,i,\ell,\la1\ra,n}_{t'-1})^{-1}}  }
\end{align*}
for some $r>1$ to be specified later.
With this definition, one can see that $\sum_{t\in[T]: \sfh(t) < H}  I^{m,i,\ell,\la1\ra,n}_{t}-I^{m,i,\ell,\la1\ra,n}_{t+1}$ is the number of bad episodes where there exists $h\in[H]$ such that 
\begin{align*}
 \norm{x_{t}}^2_{(V^{m,i,\ell,\la1\ra,n}_{\anc(t)})^{-1}} > r \norm{x_t}^2_{(V^{m,i,\ell,\la1\ra,n}_{t-1})^{-1}}~.
\end{align*}
Define $\blue{I^{m,i,\ell,\la1\ra,n}_{k,h}} := I^{m,i,\ell,\la1\ra,n}_{\sft(k,h)}$.
%\kj{how about $\sfk(t') = k-1$ instead of $D[a][1]=k$?}
Define similar quantities for $\la2\ra$ as well.

Define $\blue{I_{t}} := \prod_{m,i,\ell,n} I^{m,i,\ell,\la1\ra,n}_{t} \prod_{m,i,\ell,n} I^{m,i,\ell,\la2\ra,n}_{t}$.
We now prove Lemma~\ref{lem-I}.

Note that
\begin{align*}
\sum_{k=1}^K \sum_{h=1}^{H-1} I_{k,h} - I_{k,h+1}  \le \sum_{k=1}^K \sum_{h=1}^{H-1} \sum_{m \le L_0}\sum_{i \le L }\sum_{\ell \le L} \sum_{z\in[2]} \sum_{n =0}^{\ell} \del{I^{m,i,\ell,\la z\ra,n}_{k,h} - I^{m,i,\ell,\la z\ra,n}_{k,h+1} },
\end{align*}
We now assume $z=1$ without loss of generality.
The display above can be written as
\begin{align*}
    \sum_{t\in[T]: \sfh(t) < H}  (I_{t} - I_{t+1})
  &\le \sum_{m,i,\ell,n} \sum_{t\in[T]: \sfh(t) < H}  I^{m,i,\ell,\la1\ra,n}_{t} - I^{m,i,\ell,\la1\ra,n}_{t+1}~.
\end{align*}
% Recalling that $\sum_{t\in[T]: \sfh(t) < H}  I^{m,i,\ell,\la1\ra,n}_{t}-I^{m,i,\ell,\la1\ra,n}_{t+1}$ is counting the number of bad episodes $k$ where there exists $h\in[H]$ such that 
% \begin{align*}
%  \norm{x_{t}}^2_{(V^{m,i,\ell,\la1\ra,n}_{\anc(t)})^{-1}} > r \norm{x_t}^2_{(V^{m,i,\ell,\la1\ra,n}_{t-1})^{-1}}
% \end{align*}
Recall that the inner sum above is the count of the `bad' episodes.
We invoke Lemma~\ref{lem:epc2} $2L_0(L)^3$ times with $X=\sqrt{d}$ as $\|x_t\|_1\leq \sqrt{d}$  to finish the proof as 
 \begin{equation*}
    \sum_{k,h}I_{k,h}-I_{k,h+1}\le O\left(\frac{d}{\ln (r)}\log^5\left(dHK(1 + \fr{d^2}{\ln (r) }) \right)\right)
\end{equation*}
%\kj{I changed the above slightly; does it look correct?}
%{\color{red} You are right, I think this can be simplified since
%$$C\log(dHK) \ge \log(dHK(1+\frac{1}{\ln(r)}))$$
%for $C>r$}

\subsection{Proof of Proposition ~\ref{prop:rl-bound}}\label{details}

To proceed we safely choose $r=2$ and inherit all notations from Section~\ref{proof_of_lem_I}. Let us define
\begin{align*}
  \blue{\brcT^{m,i,\ell,\la z\ra}} := \cT^{m,i,\ell,\la z\ra} \cap \cbr{t\in[T]:I_t = 1}  
\end{align*}
where $z \in \{1,2\}$.
We start with $R_m$ as 
\begin{align*}
  R_m &= \sum_{t}  (\brx_{t}^m)^\top \mu_{t}^m
  \\&\le \sum_{t,i,\ell} \sum_{t \in \brcT^{m,i,\ell,\la1\ra}}  (\brx_{t}^m)^\top \mu_{t}^m
  + \sum_{t,i,\ell} \sum_{t \in \brcT^{m,i,\ell,\la2\ra}} (\brx_{t}^m)^\top \mu_{t}^m.
\end{align*}

Let us fix $m$, $i$, and $\ell$ and focus on controlling $\sum_{t \in \brcT^{m,i,\ell,\la z\ra}} (\brx_{t}^m)^\top \mu_{t}^m $ for $z\in[2]$.
Hereafter, we omit the superscripts of $(m,i,\ell)$ to avoid clutter, unless there is a need. 

Note that for $t  \in \brcT^{\la1\ra,n}$ and $b$ such that $t \le b$, 
\begin{align*}
  W_{\anc(t)}(\mu_b)
  &= 2^{-\ell} I +  \sum_{t' \in \cT^{m,i,\ell}_{\anc(t)}} (1\wedge \fr{2^{-\ell} }{|x_{t'} \mu_b | } )   x_{t'} x_{t'}^\T
  \\&\succeq 2^{-\ell} I +  \sum_{t' \in \cT^{m,i,\ell,\la1\ra,n}_{\anc(t)}  } (1\wedge \fr{2^{-\ell} }{|x_{t'} \mu_b | } )   x_{t'} x_{t'}^\T
  \\&\succeq 2^{-\ell} I +  \sum_{t' \in \cT^{m,i,\ell,\la1\ra,n}_{\anc(t)}  } (1\wedge \fr{2^{-\ell} }{2^{-\ell+n+1} } )   x_{t'} x_{t'}^\T
  \\&\succeq 2^{-\ell} I +  2^{-n-1} \sum_{t' \in \cT^{m,i,\ell,\la1\ra,n}_{\anc(t)} } x_{t'} x_{t'}^\T
  \\&\succeq c2^{-n} V^{\la1\ra,n}_{\anc(t)}~.
\end{align*}

For $t  \in \brcT^{\la1\ra,n}$, let $b = \arg \max_{t \le b'\in \brcT^{\la1\ra} } |x_{t}^\top \mu_{b'}|$.
%\kj{inner product notation}
Then,
\begin{align*}
  2^{-\ell + n} 
  &\le |x_{t}^\top \mu_{b}| \tag{def'n of $b$}
  \\&\le \norm{x_{t}}_{W_{\anc(t)}^{-1}(\mu_{b})}  \norm{\mu_b}_{W_{\anc(t)}(\mu_b)}  
  \\&\le \sqrt{2^n} \norm{x_{t}}_{(V^{\la1\ra,n}_{\anc(t)})^{-1}}  \norm{\mu_{b}}_{W_{\anc(b)}(\mu_b)}   
  \\&\le c\sqrt{r} \sqrt{2^n} \norm{x_{t}}_{(V^{\la1\ra,n}_{t-1})^{-1}}  \sqrt{2^{-i}\iota} ~.  \tag{by $b \in \brcT^{\la1\ra}$  }
\end{align*}
This implies that
\begin{align*}
  \norm{x_{t}}_{(V^{\la1\ra,n}_{t-1})^{-1}}^2  \ge c_{\la1\ra} \fr{2^{-2\ell+n}}{r 2^{-i}\iota}. 
\end{align*}
for some absolute constant $c_{\la1\ra} > 0$.

Thus,
\begin{align*}
  \sum_{t\in \brcT^{\la1\ra}} x_{t}\mu_{t}
  &\le   c2^{-\ell} \sum_{t\in \brcT^{\la1\ra}} 1
  \\&\le c2^{-\ell} \sqrt{|\brcT^{\la1\ra}| \sum_{t\in \brcT^{\la1\ra}} 1}
  \\&\le c2^{-\ell} \sqrt{|\brcT^{\la1\ra}| \sum_{n=0}^{\ell} \sum_{t\in \brcT^{\la1\ra,n}} 1}
  \\&\le c2^{-\ell} \sqrt{|\brcT^{\la1\ra}| \sum_{n=0}^{\ell} \sum_{t\in \brcT^{\la1\ra,n}} \onec{\norm{x_t }_{(V^{\la1\ra,n}_{t-1})^{-1}}^2 \ge c_{\la1\ra}\fr{2^{-2\ell+n}}{r 2^{-i}\iota }} } 
  \\&\le c2^{-\ell} \sqrt{|\brcT^{\la1\ra}| \sum_{n=0}^{\ell} \sum_{t\in \cT^{\la1\ra,n}} \onec{\norm{x_t }_{(V^{\la1\ra,n}_{t-1})^{-1}}^2 \ge c_{\la1\ra}\fr{2^{-2\ell+n}}{r 2^{-i}\iota }} } \tag{$\brcT^{\la1\ra,n} \subseteq \cT^{\la1\ra,n}$}
  \\&\le c2^{-\ell} \sqrt{|\brcT^{\la1\ra}| \sum_{n=0}^{\ell} \fr{r 2^{-i} \iota}{2^{-2\ell + n} } d \ln\del{ 1 + c\fr{r 2^{-i}\iota}{2^{-2\ell+n} 2^{-\ell} }  }  }  \tag{Lemma~\ref{lem:epc}}
  \\&\le c\sqrt{dr |\brcT^{\la1\ra}| 2^{-i} \iota \ln\del{ 1 + c r \iota 8^{\ell}  }  } 
  \\&\le c \sqrt{dr (1 + \sum_{t\in \brcT^{\la1\ra}} \eta_t ) \iota \ln\del{ 1 + c r \iota 8^{\ell}  }  } 
\end{align*}
% where $\blue{\breve\eta^m_t} := \eta^m_t I^{m}_t$ with $I^m_t := \prod_i \prod_\ell \prod_n \prod_{z\in\{1,2\}} I^{m,i,\ell,\la z\ra,n}_t$.
%$\bar\eta = \sum_{t \in \brcT^{\la1\ra}} \breve\eta^m_{t} $. 


For the other case involving $\brcT^{\la2\ra}$, we use the same logic as above.
Let $t \in \brcT^{\la1\ra,n}$.
Then, for any $b$ such that $a \le b$, one can show that
\begin{align*}
  W_{\anc(t)}(\mu_b)
  &\succeq c2^{-n} V^{\la2\ra,n}_{\anc(t)}~.
\end{align*}
Then, once again letting $b = \arg \max_{t<b\in \brcT^{\la2\ra} } |x_{t}^\top \mu_{b}|$ for $t\in\brcT^{\la2\ra,n}$ one can show that
\begin{align*}
  2^{-\ell + n} 
  &\le c\sqrt{r} \sqrt{2^n} \norm{x_{t}}_{(V^{\la2\ra,n}_{t-1})^{-1}}  \sqrt{2^{-\ell}\iota} ~.
\end{align*}
This implies that
\begin{align*}
  \norm{x_t}_{(V^{\la2\ra,n}_{t-1})^{-1}}^2  \ge c \fr{2^{-\ell+n}}{r \iota} 
\end{align*}
for some absolute constant $c>0$.
Then,
\begin{align*}
  \sum_{t\in \brcT_{\la2\ra}} x_t^\top\mu_t
  &\le   c2^{-\ell} \sum_{n=0}^{\ell} \sum_{(k,h)\in \brcT^{\la2\ra,n}} 1 
  \\&\le   c2^{-\ell} \sum_{n=0}^{\ell} \sum_{t\in \brcT^{\la2\ra,n}} \onec{\norm{x}^{2}_{(V^{\la2\ra,n}_{a-1})^{-1}} \ge c\fr{2^{n-\ell}}{r\iota} }
  \\&\le   c2^{-\ell} \sum_{n=0}^{\ell} c \fr{r\iota}{2^{n-\ell} }   d\ln\del{1+c\fr{r\iota}{2^{n-\ell}\cd 2^{-\ell} } }
  \\&\le   c d r \iota \ln\del{1 + c r \iota 4^\ell}
\end{align*}

Invoking the elliptical potential count lemma together with $r=2$,
\begin{align*}
  R_m \le c\sum_{i}^{L} \sum_{\ell}^{L}   \del{d^{0.5}\sqrt{(1+ \sum_{t\in\brcT^{m,i,\ell}}\eta^m_{t})\iota \ln\del{1+c\iota 8^\ell} } + d \iota\ln\del{1+c\iota 8^\ell} },
\end{align*}
which implies that
\begin{align*}
  R_m &\le  O\left(d^{0.5}\log^{2.5}(HK)\sqrt{\sum_{t} \breve\eta^m_t \iota \log(\iota )}+d \log^3(HK)\iota \log(\iota)\right).
  %\\&\le \hat O(d^{2.5}\log^{3}(dHK)\sqrt{\bar \eta \iota  )}+d^6 \log^{3.5}(dHK)\iota)
\end{align*}
where $\blue{\breve\eta^m_t} := \eta^m_t I_t$.


\subsection{Proof of Theorem \ref{main-rl}}\label{proof_of_rl}

\begin{proof}
We continue from the proof in the main paper where it remains to bound $R_0 + M_0$.
Using the relation  (equation (56) and (57) in \citep{zhang21variance}),
\begin{equation*}
    \sum_{t}\breve \eta_{t}^m \le |M_{m+1}|+O(d\log^5(dHK)+2^{m+1}(K+R_0))+R_{m+1}+2R_m,
\end{equation*}
one has, using Proposition~\ref{prop:rl-bound}, 
\begin{equation*} 
    R_m\le O\big(d^{0.5}   \log^{2.5}(dHK)\sqrt{\iota\log(\iota)}\sqrt{|M_{m+1}|+2^{m+1}(K+R_0)+R_{m+1}+2R_m}+d \log^{5}(dHK) \iota\log(\iota)) 
\end{equation*}
The strategy is to solve the recursive inequalities with respect to $R_m$ and $M_m$ to obtain a bound on $R_0$ and $M_0$.
By Lemma~\ref{lem-M}, we have
\begin{equation}\label{boot2}
|M_m| \le O(\sqrt{|M_{m+1}| + 2^{m+1}(K+R_0)\log(1/\delta)}+d^{0.5}\log^{2.5}(dHK) + \log(1/\delta))~.
\end{equation}
With $\blue{b_m} :=R_m+|M_m|$, we have
\begin{equation*}
    b_m 
    \le 
    \hat O\big(d \log^{3}(dHK) \sqrt{\log(1/\dt)}\sqrt{b_m+b_{m+1}+2^{m+1}(K+R_0)} + d^{2} \log^{7}(dHK)\log (1/\dt) \big).
\end{equation*}
where $\hat O$ ignores doubly logarithmic factors. 

We now use Lemma~\ref{rec-lem} with $\lambda_1=HK$, $\lambda_2= \hat\Theta(d\log^{3}(dHK)\sqrt{\log (1/\dt)})$, $\lambda_3=(K+R_0)$ and $\lambda_4=\hat\Theta(d^{2} \log^{7}(dHK)\ln(1/\dt))$ where $\hat\Theta$ ignores doubly logarithmic factors, we obtain
\begin{equation*}
    R_0\le b_0 \le \tilde O\big(d^{2}\log^{7}(dHK)\log (1/\dt)+\sqrt{(K+R_0)d^2\log^6(dHK)\log(1/\dt)}\big).
\end{equation*}
We can solve it for $R_0$ to obtain $R_0\le \tilde O(\sqrt{K d^2\log^7(dHK)\log(1/\dt)} + d^{2}\log^{7}(dHK)\log (1/\dt))$. 

Next, we apply Lemma~\ref{bootstrap} to \eqref{boot2} with $\lambda_2=\Theta(1)$, $\lambda_3 = (K+R_0)\ln(1/\dt)$, and $\lambda_4 = \Theta(d^{0.5} \log^{2.5}(dHK) + \ln(1/\dt))$ to obtain
\begin{align*}
    |M_0| 
    &\le O(\sqrt{(K+R_0)\ln(1/\dt)} + d^{0.5} \log^{2.5}(dHK) + \ln(1/\dt))
  \\&\le \tilde O(\sqrt{K\log(1/\dt)} + \sqrt{d^{2}\log^{7}(dHK)\log^2(1/\dt)} + d^{0.5} \log^{2.5}(dHK) + \ln(1/\dt))
\end{align*}
where the last inequality uses $\sqrt{AB} \le \frac{A+B}{2}$ to obtain the following:
\begin{align*}
    K + R_0 
      &\le \tilde O( K + d^{2}\log^{7}(dHK)\log (1/\dt)+\sqrt{K d^2\log^7(dHK)\log(1/\dt)} )
    \\&\le \tilde O\del{ K + d^{2}\log^{7}(dHK)\log (1/\dt) + \fr12\cd K + \fr12\cd d^{2}\log^{7}(dHK)\log (1/\dt) }~.
\end{align*}
Altogether, we obtain
\begin{align*}
    b_0 = \tilde O( \sqrt{K d^2\log^7(dHK)\log^2(1/\dt)} + d^{2}\log^{7}(dHK)\log (1/\dt) )
\end{align*}
This concludes the proof.

\end{proof}


\subsection{Miscellaneous lemmas}

\begin{lemma}\label{ineq}(\citet[Lemma 11]{zhang2021model})
  Let $(M_n)_{n\geq0}$ be a martingale such that $M_0=0$ and $|M_n-M_{n-1}| \leq b$ almost surely for $n\geq1$. For each $n\geq 0$, let $\mathcal{F}_n=\sigma(M_1,...,M_n)$. Then for any $n \geq 1$ and $\eps,\delta>0$, we have
  \begin{equation*}
      \mathbb{P}\del{|M_n|\geq 2 \sqrt{ \sum_{i=1}^n \mathbb{E}[(M_{i}-M_{i-1})^2|\mathcal{F}_{i-1}] \ln(1/\delta)}+2\sqrt{\eps \ln(1/\delta)}+2 b \ln(1/\delta)} \leq 2(\log_2(b^2 n/\eps) +1)\delta
  \end{equation*}
\end{lemma}

\begin{lemma}\label{lem-M}(\citet[Lemma 25]{zhang21variance})
\begin{align*}
  |M_m| \le O\del{\sqrt{M_{m+1}+O(d\log^5(dHK))+2^{m+1}(K+R_0)\log(1/\delta)}+\log(1/\delta)}
\end{align*}
\end{lemma}

%\begin{proof}
%It is a straightforward result by modifying $d\log^5(dHK)$ in Lemma 12 \citep{zhang21variance} to $d\log^4(dHK)$ using Lemma~\ref{lem-I}
%\end{proof}
\begin{lemma}\label{lem-R3}(\citet[Lemma 6]{zhang21variance})
$\Reg_3\le O(\sqrt{K\log(1/\dt)})$.
\end{lemma}

\begin{lemma}\label{rec-lem}(\citet[Lemma 12]{zhang21variance})
For $\lambda_i>0$, $i\in\{1,2,4\}$ and $\lambda_3 \ge 1$, let $\kappa=\max\{\log_2(\lambda_1),1\}$. Assume that $0\le a_i\le \lambda_1$ and $a_i \le \lambda_2 \sqrt{a_i+a_{i+1}+2^{i+1}\lambda_3}+\lambda_4$ for $i \in \{1,2,...,\kappa\}$. 
Then, we have
\begin{equation*}
    a_1 \le 22 \lambda_2^2 +6\lambda_4+4\lambda_2 \sqrt{2\lambda_3}
\end{equation*}
\end{lemma}

\begin{lemma}\label{bootstrap}(\citet[Lemma 2]{zhang2021reinforcement})
Let $\lambda_1,\lambda_2,\lambda_4 \ge0$ and $\lambda_3 \ge 1$ with $i'=\log_2(\lambda_1)$. We have a sequence $\{a_i\}_i$ for $i \in \{1,2,...,i'\}$ satisfying $a_i\le\lambda_1$ and $a_i \le \lambda_2 \sqrt{a_{i+1}+2^{i+1}\lambda_3}+\lambda_4$. Then,
\begin{equation*}
    a_1 \le \max\cbr{(\lambda_2 +\sqrt{\lambda_2^2+\lambda_4})^2,\lambda_2\sqrt{8\lambda_3}+\lambda_4}
\end{equation*}
\end{lemma}

\section{Comparison with~\citet{he2021logarithmic}}\label{app:diff}

At a high-level, \citet{he2021logarithmic} apply a similar strategy to ours. One immediate difference is that we do not incur an extra dependence on $d$ inside the logarithm, but it could be due to the fact that their lemma is applying the count on a different quantity from ours. Note that our EPC is still novel and tighter than the bound appeared in a concurrent work of \citet[Lemma 6.2]{wagenmaker2022first} for a large enough $K$ (i.e., time horizon). 

Note that the core of our novelty is the point of view introduced by the the matrix norm with respect to $W_{\ell,k-1}(\mu)$. 
This enables the connection to the elliptical potential lemma and the peeling technique. 
Such a viewpoint is exactly what the paper of VOFUL~\cite{zhang21variance} did not seem to have realized.
Indeed, the proof of VOFUL \cite{zhang21variance} does not use peeling on $x_k^\top \mu_k$ as we do.

% Indeed, the proof of VOFUL \cite{zhang21variance} does not use peeling on $x_k^\top \mu_k$ as we do!


% , which has made the analysis rather complicated. 
% This
% Indeed, the proof of VOFUL \cite{zhang21variance} does not use peeling on $x_k^\top \mu_k$. 

We also like to highlight that Lemma~\ref{lem:epc2} is still novel and is one of the main contributors to the improved regret bound for the linear mixture MDP.