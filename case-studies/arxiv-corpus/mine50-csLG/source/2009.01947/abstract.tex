\begin{abstract}
  We present combinatorial and parallelizable algorithms
  for maximization of a submodular function, not necessarily
  monotone, with respect to a size constraint.
  We improve the best approximation factor achieved
  by an algorithm that has optimal adaptivity and
  nearly optimal query
  complexity to $0.193 - \epsi$. The conference version
  of this work mistakenly employed a subroutine that does
  not work for non-monotone, submodular functions.
  In this version, we propose a fixed and improved subroutine
  to add a set with high average marginal gain,
  \threseq, 
  which returns a solution in $\oh{\log(n)}$
  adaptive rounds with high probability.
    Moreover, we provide two approximation algorithms.
    The first has approximation
    ratio $1/6 - \epsi$, adaptivity
    $O( \log (n) )$, and query complexity $O( n \log (k) )$,
    while the second has approximation ratio $0.193 - \epsi$,
    adaptivity $O( \log^2 (n) )$, and query complexity $O(n \log (k))$.
    Our algorithms are empirically 
    validated to use a low number of adaptive rounds and total queries
    while obtaining solutions with high objective value in comparison with
    state-of-the-art approximation algorithms, including continuous algorithms
    that use the multilinear extension. 
    %We also demonstrate empirically
    %that 
    %algorithms which make use of the multilinear extension of a submodular
    %function are extremely inefficient in comparison with combinatorial algorithms.
    \end{abstract}

% \begin{keywords}
% non-monotone submodular maximization, parallelizable algorithms, threshold procedure
% \end{keywords}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
