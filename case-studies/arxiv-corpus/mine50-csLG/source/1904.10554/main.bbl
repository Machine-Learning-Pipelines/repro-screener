\begin{thebibliography}{10}

\bibitem{berger2005fictitious}
{\sc U.~Berger}, {\em Fictitious play in 2$\times$ n games}, Journal of
  Economic Theory, 120 (2005), pp.~139--154.

\bibitem{brown1951iterative}
{\sc G.~W. Brown}, {\em Iterative solution of games by fictitious play},
  Activity analysis of production and allocation, 13 (1951), pp.~374--376.

\bibitem{bu2008comprehensive}
{\sc L.~Bu, R.~Babu, B.~De~Schutter, et~al.}, {\em A comprehensive survey of
  multiagent reinforcement learning}, IEEE Transactions on Systems, Man, and
  Cybernetics, Part C (Applications and Reviews), 38 (2008), pp.~156--172.

\bibitem{carmona2017probabilistic}
{\sc R.~Carmona and F.~Delarue}, {\em Probabilistic theory of mean field games:
  vol. i, mean field fbsdes, control, and games}, Stochastic Analysis and
  Applications. Springer Verlag,  (2017).

\bibitem{casgrain2018algorithmic}
{\sc P.~Casgrain and S.~Jaimungal}, {\em Mean field games with partial
  information for algorithmic trading}, arXiv preprint arXiv:1803.04094,
  (2018).

\bibitem{casgrain2020mean}
{\sc P.~Casgrain and S.~Jaimungal}, {\em Mean-field games with differing
  beliefs for algorithmic trading}, Mathematical Finance, 30 (2020),
  pp.~995--1034.

\bibitem{elfwing2018sigmoid}
{\sc S.~Elfwing, E.~Uchibe, and K.~Doya}, {\em Sigmoid-weighted linear units
  for neural network function approximation in reinforcement learning}, Neural
  Networks, 107 (2018), pp.~3--11.

\bibitem{gu2016continuous}
{\sc S.~Gu, T.~Lillicrap, I.~Sutskever, and S.~Levine}, {\em Continuous deep
  q-learning with model-based acceleration}, in International Conference on
  Machine Learning, 2016, pp.~2829--2838.

\bibitem{guo2019learning}
{\sc X.~Guo, A.~Hu, R.~Xu, and J.~Zhang}, {\em Learning mean-field games},
  arXiv preprint arXiv:1901.09585,  (2019).

\bibitem{heinrich2015fictitious}
{\sc J.~Heinrich, M.~Lanctot, and D.~Silver}, {\em Fictitious self-play in
  extensive-form games}, in International conference on machine learning, PMLR,
  2015, pp.~805--813.

\bibitem{hessel2018rainbow}
{\sc M.~Hessel, J.~Modayil, H.~Van~Hasselt, T.~Schaul, G.~Ostrovski, W.~Dabney,
  D.~Horgan, B.~Piot, M.~Azar, and D.~Silver}, {\em Rainbow: Combining
  improvements in deep reinforcement learning}, in Thirty-Second AAAI
  Conference on Artificial Intelligence, 2018.

\bibitem{hu2003nash}
{\sc J.~Hu and M.~P. Wellman}, {\em {N}ash q-learning for general-sum
  stochastic games}, Journal of machine learning research, 4 (2003),
  pp.~1039--1069.

\bibitem{hu2019deep}
{\sc R.~Hu}, {\em Deep fictitious play for stochastic differential games},
  arXiv preprint arXiv:1903.09376,  (2019).

\bibitem{huang2010large}
{\sc M.~Huang}, {\em Large-population {LQG} games involving a major player: the
  {N}ash certainty equivalence principle}, SIAM Journal on Control and
  Optimization, 48 (2010), pp.~3318--3353.

\bibitem{huang2006large}
{\sc M.~Huang, R.~P. Malham{\'e}, P.~E. Caines, et~al.}, {\em Large population
  stochastic dynamic games: closed-loop mckean-vlasov systems and the {N}ash
  certainty equivalence principle}, Communications in Information \& Systems, 6
  (2006), pp.~221--252.

\bibitem{huang2015mean}
{\sc X.~Huang, S.~Jaimungal, and M.~Nourian}, {\em Mean-field game strategies
  for optimal execution}, Applied Mathematical Finance, Forthcoming,  (2015).

\bibitem{konda2000actor}
{\sc V.~R. Konda and J.~N. Tsitsiklis}, {\em Actor-critic algorithms}, in
  Advances in neural information processing systems, 2000, pp.~1008--1014.

\bibitem{lanctot2017unified}
{\sc M.~Lanctot, V.~Zambaldi, A.~Gruslys, A.~Lazaridou, K.~Tuyls,
  J.~P{\'e}rolat, D.~Silver, and T.~Graepel}, {\em A unified game-theoretic
  approach to multiagent reinforcement learning}, in Advances in Neural
  Information Processing Systems, 2017, pp.~4190--4203.

\bibitem{lasry2007mean}
{\sc J.-M. Lasry and P.-L. Lions}, {\em Mean field games}, Japanese journal of
  mathematics, 2 (2007), pp.~229--260.

\bibitem{lillicrap2015continuous}
{\sc T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and D.~Wierstra}, {\em Continuous control with deep reinforcement
  learning}, arXiv preprint arXiv:1509.02971,  (2015).

\bibitem{loshchilov2018decoupled}
{\sc I.~Loshchilov and F.~Hutter}, {\em Decoupled weight decay regularization},
  in International Conference on Learning Representations, 2018.

\bibitem{mnih2013playing}
{\sc V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra,
  and M.~Riedmiller}, {\em Playing atari with deep reinforcement learning},
  arXiv preprint arXiv:1312.5602,  (2013).

\bibitem{monderer1996potential}
{\sc D.~Monderer and L.~S. Shapley}, {\em Potential games}, Games and economic
  behavior, 14 (1996), pp.~124--143.

\bibitem{neuman2021trading}
{\sc E.~Neuman and M.~Vo{\ss}}, {\em Trading with the crowd}, Available at SSRN
  3868708,  (2021).

\bibitem{nourian2013ep}
{\sc M.~Nourian and P.~E. Caines}, {\em {$\epsilon$}-{N}ash mean field game
  theory for nonlinear stochastic dynamical systems with major and minor
  agents}, SIAM Journal on Control and Optimization, 51 (2013), pp.~3302--3331.

\bibitem{sutton2000policy}
{\sc R.~S. Sutton, D.~A. McAllester, S.~P. Singh, and Y.~Mansour}, {\em Policy
  gradient methods for reinforcement learning with function approximation}, in
  Advances in neural information processing systems, 2000, pp.~1057--1063.

\bibitem{todorov2005generalized}
{\sc E.~Todorov and W.~Li}, {\em A generalized iterative lqg method for
  locally-optimal feedback control of constrained nonlinear stochastic
  systems}, in Proceedings of the 2005, American Control Conference, 2005.,
  IEEE, 2005, pp.~300--306.

\bibitem{zaheer2017deep}
{\sc M.~Zaheer, S.~Kottur, S.~Ravanbakhsh, B.~Poczos, R.~R. Salakhutdinov, and
  A.~J. Smola}, {\em Deep sets}, in Advances in neural information processing
  systems, 2017, pp.~3391--3401.

\end{thebibliography}
