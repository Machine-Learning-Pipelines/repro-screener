% \begin{wraptable}{r}{4.5cm}
\begin{center}
\begin{tabular}{|c|c|}
\hline

\textbf{Method} & \textbf{MPJPE} \\

\hline
Conv. layer & 31.9 \\
\hline
TE - 1$l$, 64$h$ & 30.9 \\
\hline
TE - 2$l$, 64$h$ & 37.8 \\
\hline
MHA - 128$h$ & 30.5 \\
\hline
MHA - 64$h$ & \textbf{30.2} \\
\hline
MHA - 32$h$ & 30.6 \\
\hline
MHA - 16$h$ & 30.9 \\
\hline

\end{tabular}
\end{center}
% \caption{The impact of multi-view fusion architecture. Legend: TE - Transformer Encoder. MHA - Multi-head Attention. $l$ refer to no. of stacked layers. $h$ refer to no. of heads in attention layer.}
% \label{tab:fusion_arch}
% \end{wraptable}
