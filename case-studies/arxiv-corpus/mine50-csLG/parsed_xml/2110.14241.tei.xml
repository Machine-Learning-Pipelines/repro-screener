<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic population-based meta-learning for multi-agent communication with natural language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-10-27">27 Oct 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
							<email>abhinavg@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">35th Conference on Neural Information Processing Systems</orgName>
								<address>
									<postCode>2021)</postCode>
									<settlement>Sydney</settlement>
									<region>NeurIPS</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
							<email>lanctot@deepmind.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">35th Conference on Neural Information Processing Systems</orgName>
								<address>
									<postCode>2021)</postCode>
									<settlement>Sydney</settlement>
									<region>NeurIPS</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
							<email>angeliki@deepmind.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">35th Conference on Neural Information Processing Systems</orgName>
								<address>
									<postCode>2021)</postCode>
									<settlement>Sydney</settlement>
									<region>NeurIPS</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic population-based meta-learning for multi-agent communication with natural language</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-10-27">27 Oct 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">F25DCA59B1378E2987DA1E661FEECC52</idno>
					<idno type="arXiv">arXiv:2110.14241v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-31T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, our goal is to train agents that can coordinate with seen, unseen as well as human partners in a multi-agent communication environment involving natural language. Previous work using a single set of agents has shown great progress in generalizing to known partners, however it struggles when coordinating with unfamiliar agents. To mitigate that, recent work explored the use of population-based approaches, where multiple agents interact with each other with the goal of learning more generic protocols. These methods, while able to result in good coordination between unseen partners, still only achieve so in cases of simple languages, thus failing to adapt to human partners using natural language. We attribute this to the use of static populations and instead propose a dynamic population-based metalearning approach that builds such a population in an iterative manner. We perform a holistic evaluation of our method on two different referential games, and show that our agents outperform all prior work when communicating with seen partners and humans. Furthermore, we analyze the natural language generation skills of our agents, where we find that our agents also outperform strong baselines. Finally, we test the robustness of our agents when communicating with out-of-population agents and carefully test the importance of each component of our method through ablation studies. * Work partially done during an internship at DeepMind.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humans excel at large-group coordination, with natural language playing a key role in their problem solving ability <ref type="bibr" target="#b49">[49,</ref><ref type="bibr" target="#b7">8]</ref>. Inspired by these findings, in this work our goal is to endow artificial agents with communication skills in natural language, which can in turn allow them to coordinate effectively in three key situations when playing referential games (i) with agents they have been paired with during their training (ii) with new agents they have not been paired with before and (iii) with humans.</p><p>Our starting point is recent work in the emergent communication literature, which proposes to learn protocols "from scratch", allowing like these agents that have been trained together (and for a large number of iterations) to form conventions <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19]</ref>. While such communication approaches result in agents achieving higher rewards at test time when paired with their training partners <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23]</ref>, there is growing evidence that these agents do not acquire communication skills with general properties <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18]</ref> but rather learn to form communication protocols that are based solely on idiosyncratic conventions.</p><p>Interestingly, these type of communication pathologies are also observed in natural languages, where they are linked to the size of a linguistic community <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b34">35]</ref>, i.e. the smaller the community the more complex the languages get. This has recently inspired the use of populationbased approaches to multi-agent communication in which agents within a population interact with one another <ref type="bibr" target="#b48">[48,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref>. One such approach is L2C <ref type="bibr" target="#b31">[32]</ref> which uses meta-learning approaches like MAML <ref type="bibr" target="#b9">[10]</ref> combined with a static population of agents. Indeed, L2C results in communication protocols with some primitive forms of compositionality, allowing agents to successfully communicate with unseen partners. Nevertheless, even in this case, the induced protocols fail to adapt to natural language, leaving open questions with regard to coordination with humans. We hypothesize that a potential bottleneck of this and related approaches lies in the use of static populations. Intuitively, the initial diversity induced by different random initializations of the population gradually vanishes when given enough capacity and training iterations, thus allowing all agents in the population to co-adapt to each other and converge to the same ad-hoc conventions. Simply put, it is challenging to maintain diversity in static populations, which is what drives the learning of generalizable protocols.</p><p>With this in mind, we propose to address this issue by dynamically building the population ( ยง3), to gradually induce constructive diversity within the population, so as to enable population-based algorithms (like meta-learning) to train agents that can then generalize to seen and unseen partners as well as humans.Since communication with humans is one of our goals, grounding to natural language is of paramount importance. Consequently, we want the agents to coordinate with humans using limited amount of human data while not drifting away from human behavior. In order to maximize efficiency and minimize the use task-specific language data, we combine two learning signals <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33]</ref>, each bootstrapping the other ( ยง2). First, maximizing task rewards allows the agents to learn to communicate with one another in a purely self-play manner, but using emergent protocols not grounding in natural language. Hence, combining this signal with supervision from a limited dataset of task-specific language data, allows grounding of the emergent protocols in natural language. All in all, our proposed approaches consists of three different phases (i.e., interactive reward-based learning, supervised learning, and meta-learning), each imposing an inductive bias.</p><p>We present extensive experiments in two referential game environments (an image-based and a textbased defined in ยง4) using natural language communication and compare our model against previous approaches, strong baselines and ablations of our method. Moreover, we follow a holistic approach to evaluating multi-agent communication, reporting results on: (a) task performance measured by referential accuracy in ( ยง4.1) (b) the agents' natural language generation skills by computing BLEU score with language data ( ยง4.2) (c) human evaluation of both agents in ( ยง4.3) (d) cross-play evaluation with unseen partners in ( ยง4.5), and (e) robustness against implict bias in the dataset ( ยง4.6).</p><p>2 Learning in multi-agent games with natural language: The case of referential games  Referential Games Referential games are a type of Lewis Signaling games <ref type="bibr" target="#b27">[28]</ref> that have been used in human as well as artificial language experiments <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b12">13]</ref>. This fully cooperative game consists of two players, a speaker S and a listener L who interact with each other to solve a common task. In our setup, both agents are parameterized using deep neural networks, where the speaker's and listener's parameters are denoted by ฮธ and ฯ respectively. The speaker gets as input a target object t, encodes it in its own embedding space and sends a discrete message m = S(t) to the listener. The listener receives two inputs, the message m and a set of distractor objects D (|D| = K) and the target object t. The listener embeds both of these into a shared vector representation to compute a similarity score between the message and the objects and outputs a prediction t about the target object. Both agents are given a reward if the listener is able to correctly predict the target object. We denote the maximum length of the message m with l and the vocabulary set with V . In our work, we use two different types of objects: images and sentences as described in ยง4.</p><formula xml:id="formula_0">A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactive Learning</head><p>The most common approach to train agents to solve the main communicative task in the multi-agent communication framework is by using interactive (reward-driven) learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29]</ref>. The reward function r for both agents is the same and given by: r = 1 if t =   t and โ 0.1 otherwise. We optimize the agents' parameters using reinforcement learning, and specifically, using policy gradients (REINFORCE <ref type="bibr" target="#b53">[53]</ref>), similar to <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>. The listener is additionally optimized using a supervised learning (cross-entropy) loss since we know the ground truth label (which is the target object). The corresponding interactive loss functions for the speaker (J int S ) and the listener (J int L ) are given by:</p><formula xml:id="formula_1">J int S (t; ฮธ) = โ r l l j=1 log p(m j |m &lt;j , t; ฮธ) + ฮป hs H S (ฮธ)<label>(1)</label></formula><p>J int L (m, t, D; ฯ) = โr log p(t |m, t, D; ฯ) + ฮป s log p(t = t|m, t, D; ฯ)</p><formula xml:id="formula_2">+ ฮป hl H L (ฯ) (2)</formula><p>where H S and H L denote entropy regularization for the speaker and listener policies respectively. ฮป hs and ฮป hl are non-negative regularization coefficients and ฮป s โฅ 0 is a scalar quantity.  Behavior Grounding If we wish to enable agents to communicate with humans, it is essential to ground their behavior into the corresponding human distribution. Recent work <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> achieves this by performing supervised learning with the use of a natural language dataset. Consequently, the speaker needs to send messages that are human-interpretable while the listener should be able to understand natural language. To achieve this, we let humans provide descriptions of the objects and collect such (object, description) pairs to train our agents using supervised learning. Let us denote this dataset by D with m * being the description for the target object t present in D. Then the corresponding cross-entropy losses for the speaker (J sup S ) and the listener (J sup L ) are:</p><formula xml:id="formula_3">J sup S (m * , t; ฮธ) = โ 1 l l j=1 |V | c=1 m * j,c log p(m j,c |m &lt;j , t; ฮธ)<label>(3)</label></formula><formula xml:id="formula_4">J sup L (m * , t, D; ฯ) = โ K+1 j=1 1 (tj =t) p(t j |m * , t, D; ฯ)<label>(4)</label></formula><p>The previous two approaches help in learning protocols that are either closer to human prior or are ad-hoc conventions that get emerged during training. A common pitfall of training a single set of speaker/listener is that both agents tend to overfit to their partners resulting in loss of generalization across multiple partners including humans <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b28">29]</ref>. Since our objective is for the agents to learn robust protocols that match the human distribution and are high rewarding, we adopt a populationbased approach to train agents that generalize across diverse agents in a population.</p><p>Previous approaches have used population as means to regularize the behavior of the agents using a community of fixed number of agents <ref type="bibr" target="#b48">[48]</ref> or by meta-learning an agent on this fixed population of agents. In a given population, each agent learns a best-response to the other agent with the underlying hypothesis being the meta-agent learning the overall best-response to all agents in the population. </p><formula xml:id="formula_5">Eq (4) i โ 1 repeat B i S โ B iโ1 S ฮธi B i L โ B iโ1 L ฯi ฯ 0 โ ฯiโ1; ฯ 0 โ ฯiโ1 for j โ {1, 2, . . . , nmeta} do ฯ j โ MetaLearning(O; ฯ jโ1 , {โฯ โ B i L }) Eq (5) ฯ j โ MetaLearning(O; ฯ jโ1 , {โฮธ โ B i S }) Eq (6) end ฮธ 0 โ ฮธi; ฯ 0 โ ฯ i ; ฯi โ ฯ j ; ฯi โ ฯ j for l โ {1, 2, . . . , nint} do ฮธ l โ InteractiveLearning({t, D} โผ O; ฮธ lโ1 , ฯi) Eq (1) ฯ l โ InteractiveLearning({t, D} โผ O; ฯ lโ1 , ฯi) Eq (2) end ฮธ 0 โ ฮธ l ; ฯ 0 โ ฯ l for m โ {1, 2, . . . , nsup} do ฮธ m โ SupervisedLearning({m, t} โผ D; ฮธ mโ1 ) Eq (3) ฯ m โ SupervisedLearning({m, t, D} โผ D; ฯ mโ1 ) Eq (4) end ฮธi+1 โ ฮธ m ; ฯi+1 โ ฯ m i โ i + 1 until performance of ฯ and ฯ converge</formula><p>The main aim of meta-learning techniques <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b9">10]</ref> is to learn a meta-agent that is able to achieve good generalization across multiple tasks. In the reinforcement learning setting, these tasks can be different sets of goals in the same or different environments. In a multiagent interactive setting, we can reformulate these goals as generalizing to different agents in a population where the agent's partner is its environment. Consequently, meta-learning can only aim to learn generic protocols if there is a rich signal emerging from a diverse set of populations. A previous approach <ref type="bibr" target="#b31">[32]</ref> (L2C) investigating learning diverse agents using different seeds for random initialization of the agent parameters. However, this simplistic way of inducing diversity is limited and only works with more toy (artificial) languages, thus leaving a big performance gap when agents communicate in natural language <ref type="bibr" target="#b32">[33]</ref>. We hypothesize that the desired useful diversity (for meta-learning) is absent in these static populations, hence resulting in lower performance of the meta-agent.</p><p>We aim to tackle this issue by building a dynamic population in an iterative manner, similar to Policy-Space Response Oracles (PSRO) <ref type="bibr" target="#b21">[22]</ref>, which uses empirical game-theoretic analysis in a non-cooperative game to learn a meta-strategy for policy selection. An agent learns a bestresponse to an Oracle which is then added to a buffer that stores this growing population of agents. This buffer is used to obtain an improved Oracle which is used in subsequent iteration. We split the training into two phases as depicted in Fig 2b <ref type="figure">.</ref> We will describe the method for training a meta-listener (an equivalent method is used for the meta-speaker):</p><p>Learning a meta-listener We train a metalistener that plays with all speakers present in the current population buffer. At each training iteration, the meta-listener aims to distill the behavior of all past listeners that interacted with the current speaker population.</p><p>Building the speaker population After obtaining the newly trained meta-listener, we expand the speaker population by playing the meta-listener with the speaker that was added to the buffer in the previous iteration. This encourages new behavior to emerge as a result of interacting with the distilled meta-listener. Our hypothesis is that by adopting this iterative mechanism of distillation and expansion, we are able to obtain a diverse population where the behavior of each consecutive agent in the buffer changes gradually.</p><p>In this work, we use techniques that use gradient descent for optimizing the meta-agent. In particular, we use the popular Model Agnostic Meta Learning (MAML) <ref type="bibr" target="#b9">[10]</ref> to train the meta-agents. MAML based approaches provide a good initialization over the parameters to be able to quickly adapt to new tasks. An important point to note here is that in our setup, the task distribution is changing over time and is determined as a result of multi-agent learning. We also show some results using other algorithms that are derived from MAML in the Appendix. We denote the parameters of meta-speaker S m by ฯ and meta-listener L m by ฯ. We assume a buffer of speakers denoted by B S and listeners by B L . We split the collection of objects O into two sets O i and O o in order to compute the inner and outer loop losses in MAML respectively. Now, we can define the objective functions for the meta-speaker (J meta S m ) and the meta-listener (J meta L m ) as follows:</p><formula xml:id="formula_6">J meta S m (O; ฯ) = LโB L J int S m t o ; ฯ โ ฮฑโ ฯ J int S m t i ; ฯ<label>(5)</label></formula><formula xml:id="formula_7">J meta L m (O; ฯ) = SโB S J int L m m o , t o , D o ; ฯ โ ฮฑโ ฯ J int L m m i , t i , D i ; ฯ<label>(6)</label></formula><p>where Finally, the trained meta-agents are fine-tuned using the dataset D before the testing phase. The fine-tuning losses are the same as the supervised losses Eq (3) (4) described in the previous section.</p><formula xml:id="formula_8">t i โ O i , t o โ O o , m o = S(t o ), m i = S(t i ),</formula><p>Since the number of training iterations is unknown and could be potentially much larger than the size of the buffer the memory can hold, we use reservoir sampling to keep a uniform sample of past agents in the buffer. The detailed algorithm can be found in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Prior approaches</head><p>Recent work has investigated combining the two objective functions of self-play and imitation learning, with the goal of training agents that use natural language and perform well on a given emergent communication task. This transforms the problem into training a task conditional language model in a multi-agent setup. S2P <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b12">13]</ref> proposes methods that devise a curriculum between the two training phases updating the speaker and the listener in an iterative manner. SIL <ref type="bibr" target="#b33">[34]</ref> follows a student-teacher paradigm that is trained sequentially, where the teacher agents, initialized from the student agents, are trained using interactive learning. Then the student agents are trained to imitate the teacher agents by sampling data at every training iteration. Another work by <ref type="bibr" target="#b24">[25]</ref> investigates different types of language (semantic and structural) and pragmatic drifts. They propose a reranking module that first samples multiple messages from the speaker and then ranks them according to the task performance. 2 Crucially, the reranking module presents an orthogonal axis of progress and thus can be combined with other approaches presented here.</p><p>With respect to training agents using population-based methods, <ref type="bibr" target="#b48">[48]</ref> propose a learning method that uses a community of fixed number of agents where speakers and listeners are randomly paired with each other at every training iteration. L2C <ref type="bibr" target="#b31">[32]</ref> proposes a meta-training method on a fixed population of agents. They first train different populations of agents via self-play with each population initialized with a different random seed. Then a meta-learner interacts with these agents and learns to adapt to each population simultaneously. Another similar method in <ref type="bibr" target="#b4">[5]</ref> aims at learning a community of agents, where groups of speakers and listeners are used to sample a pair uniformly at random who then play the game and jointly optimize for better task performance. During learning, few agents are reinitialized periodically/at random from a group of agents. The idea is to promote cultural transmission to induce compositionality over multiple generations of language transfer. For our experiments, we reinitialize agents to the pretrained agents that are trained using the human dataset. We denote this method as GEN.TRANS. in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>In this work, we conduct experiments on two referential games in two different modalities, i.e., having agents communicating in English about images, a process akin to image captioning, and having agents communicating in German about English sentences, a process akin to machine translation.</p><p>Images We use the image-based referential game <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b24">25]</ref> which is a common environment used to analyze emergent protocols involving multimodal inputs. We use the MSCOCO dataset <ref type="bibr" target="#b29">[30]</ref> to obtain real images and the corresponding ground truth English captions annotated by humans.</p><p>Since this dataset has multiple gold captions for each image, we randomly select one from the available set and keep |O| = 7000. Following <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>, both speaker and listener are parameterized with recurrent neural networks (GRU <ref type="bibr" target="#b3">[4]</ref>) of size 512 with an embedding layer of size 256. We embed images using a Resnet-50 model <ref type="bibr" target="#b15">[16]</ref> (pretrained on ImageNet <ref type="bibr" target="#b6">[7]</ref>). We set the vocabulary size to 100 and the maximum length of the sentences at 15. We use the same speaker and listener buffer size of 200 for reservoir sampling. Other implementation details are given in the Appendix.</p><p>Text To further test the robustness of our approach to different types of structural priors found on the input data <ref type="bibr" target="#b46">[46]</ref>, we also play a referential game using text as the input modality <ref type="bibr" target="#b25">[26]</ref>. We use the publicly available IWSLT'14 English-German dataset with English as the source and German as the target language. Instead of randomly selecting the distractors from the set of English sentences, we create harder distractors by picking English sentences that are more similar to the source English sentence. For this, we use a Sentence-BERT model <ref type="bibr" target="#b42">[43]</ref> (pretrained on SNLI <ref type="bibr" target="#b1">[2]</ref> and MultiNLI <ref type="bibr" target="#b52">[52]</ref>) to embed all English sentences in the dataset and filter them using a threshold criteria of cosine similarity to systematically choose the distractors. The game complexity increases with an increase in cosine similarity, and we fix this to 0.85. We use a vocabulary size of 100 and maximum sentence length of 20. All other details are the same as the game with images.</p><p>Throughout this section, we report results using 3 random seeds and K = 9, |D| = 5000 in the image game and K = 14, |D| = 5000 in the text game. In the Appendix, we show that our findings are robust and include results with |D| = 2000 and K = 9 on the image and text game respectively. We report referential accuracy as the final task performance of the meta-agents, i.e., how accurately the (meta-) listener is able to predict the target using the (meta-) speaker's messages. Fig <ref type="figure" target="#fig_8">4</ref> plots the referential accuracy on the test set of 1000 images/sentences for the image/text game. In both plots, the pretrained baseline is obtained by separately pretraining the speaker and the listener on the language data without any interactive or meta-learning signal, i.e., only using Eq 3 and Eq 4, and then pairing them together. The emergent communication (EMECOM) baseline is computed by training agents purely via interactive learning and without any supervision from the dataset, i.e., only using Eq 1 and Eq 2. In both image (left plot, 10% random baseline) and text (right plot, 6.7% random baseline), our method outperforms alternative approaches. Specifically, GEN.TRANS. and our method outperform S2P and SIL, both of which can be thought of as single-agent population, indicating the importance of diversity among the agent population. Moreover, our method surpassing GEN.TRANS. and L2C indicates the importance of using the proposed meta-learning approach in conjunction with an adaptive population instead of using a static set of agents. In Sec 4.4 we conduct more ablations to better assess the importance of the different components for our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Referential Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluating Natural Language Skills of (Meta-) speakers</head><p>Previous work on multi-agent communication with language has showed that even when agents receive supervision using natural language data, language drift phenomena result in agents noticeably diverging from natural language while still achieving high referential accuracy <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>. As such, we proceed with directly evaluating the natural language capabilities of the meta-speakers. We start with the image game, in which we view the utterances generated by the meta-speaker as captions and hence evaluate their alignment of the generated captions with human generated ones. We evaluate all methods using 1000 generated captions from the test set. We report BLEU score <ref type="bibr" target="#b38">[39]</ref> between the generated captions and the ground-truth English caption.</p><p>We also report an alternative caption score proposed by <ref type="bibr" target="#b5">[6]</ref>, which uses a pre-trained model on MSCOCO to compute a similarity score between the generated caption and the context (image and ground-truth caption). The results are shown in Table <ref type="table" target="#tab_1">1</ref>, where we see that our method outperforms alternatives indicating that the use of meta-agents is effective in getting higher referential accuracy but not on the expense of worse language skills.  In Table <ref type="table" target="#tab_3">2</ref>, we perform a similar analysis for the (meta-) speaker on the text game. Here, the utterances of the meta-speaker could be thought of as translating the English input sentences to German. Hence, we evaluate the (meta-) speaker as an English-German machine translation system computing BLEU score with the German reference sentences. Apart from comparing our model against different alternatives, we also create stronger baselines by using the English-German pretrained model in the text game with different decoding strategies (all others methods including ours will use greedy decoding). We find that our method, despite using greedy decoding, is able to outperform all variables of the PRETRAINED model, indicating that our technique has a somewhat different effect than the one introduced by simply changing the decoding strategy.</p><p>All in all, we find that even though our objective task was never to just simply maximize captioning (or machine translation) performance, our dynamic population-based meta-learning resulted in metaspeakers with better language skills than the pretrained models, which use the very same number of (limited) language data. While our results are far from being state-of-the-art on captioning or translation, we nevertheless see that our technique can be thought of as a form of semi-supervised learning through self-play, and can perhaps be used in combination with specialized models of the respective tasks. We also include some qualitative samples generated by different speaker models alongside the ground truth captions in Fig 8 <ref type="figure">.</ref> In the Appendix, we show some additional corpus-level statistics that further corroborates this claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Agents interacting with Humans</head><p>Although BLEU score is able to capture some form of syntactical and semantic drift, it still fails to counter the phenomenon of pragmatic drift, as introduced in <ref type="bibr" target="#b24">[25]</ref>. For this reason, we evaluate the performances of our agents, and all other alternative methods, by having agents interact with humans and report referential accuracy. As such, we play games where the (meta-) speaker interacts with a human listener and the (meta-) listener with a human speaker. Thus, in the first case we evaluate the natural language generation abilities of the (meta-) speaker, whereas in the second case we evaluate the natural language understanding skills of the (meta-) listener. The (meta-) speaker is evaluated using 1000 games with humans and the (meta-) listener using 400 games.  Moreover, we compute an upper-bound by computing the referential accuracy when pairing two humans to play the game. In Fig <ref type="figure" target="#fig_9">5a,</ref> we show the results for meta-speaker in the image game where our method outperforms other approaches by a significant margin. In Fig <ref type="figure" target="#fig_9">5b</ref> we compare the performance of the metalistener in the image game with other baselines and found similar observations to the meta-speaker. We find that our method is able to better understand human descriptions by learning diverse caption representations. The results for the game with text follow similar pattern and can be found in Appendix along with other details of the experimental setup. Overall we infer that our method suffers the least amount of pragmatic drift as compared to other baselines, as measured by the performance gap with the human-human gameplay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation studies</head><p>We further analyze the importance of each component of our proposed algorithm by introducing the following ablations.</p><p>no meta-agents In this ablation, we test the importance of building populations of agents by learning speakers (or listeners) through interaction with the meta-agent listener (or speaker respectively), as opposed to just interacting with a randomly chosen listener (or speaker) from the buffer. Our hypothesis is that this promotes diversity within the population, resulting in learning more general communication protocols. Before commenting on the performance of this ablation, we note that this type of training is in fact more unstable, which we attribute to making the training of the two meta-agents interdependent of each other. We leave further analysis of this for future work.  no adaptive-meta In this ablation, we test the importance of training the meta-agent in an iterated manner, as opposed to training it from scratch by resetting the weights of the meta-agent before interacting with the population. We build the population of agents that interact with the meta-agent (whose weights have been reset) in two different ways: (i) by following the approach illustrated in Alg 1 and (ii) by following the approach introduced in No meta-agents above.</p><p>no separate grounding In this ablation, we test the importance of avoiding catastrophic forgetting of language skills by conducting interactive and supervised learning (i.e., Equations 1 till 4 in Algorithm 1) in separate phases, in line with previous work <ref type="bibr" target="#b32">[33]</ref>. Recently, other works <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b33">34]</ref> have proposed using KL divergence between the agents' policies with a pre-trained policy on language data, and as such penanalize policies that diverge from language. Concretely, the corresponding speaker objective is</p><formula xml:id="formula_9">ฮป int J int S + KL(ฮธ Pretrained ||ฮธ).</formula><p>In <ref type="bibr">Fig 6,</ref><ref type="bibr"></ref> we compare the performance of our full approach against all ablations by reporting the referential accuracy on the test set in the image game. The comparatively lower performance of no meta-agents against our method indicates that the agents that interact with the corresponding meta-agent learn more robust and diverse strategies as compared to the ones that interact with any agent in the buffer. Both variants of the no adaptive-meta agents underperform against our approach as well as against no-meta agents. This suggests that the adaptive way of training the meta-agent is crucial in getting higher performance as compared to training it from scratch. We hypothesize that our iterated meta-agent has a slight advantage of being able to learn from agents that get created during the training in turn providing a better initialization to adapt to the new population. The meta-agent captures useful information from past iterations of other agents and provides a richer learning signal to train the next agent to be added. No separate grounding agents perform close to the alternating updates used in our method indicating that one can use multiple ways to integrate the two loss functions in combination with our meta-learning approach. 4   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Induced diversity and out-of-population evaluation</head><p>In Fig 7a, we show the average performance of the meta-listener, obtained after training, playing with different speakers at different stages of their training in the image game. We show that as the training of the speakers progresses, the standard deviation (denoted by blue bars) of the referential accuracy across all the speakers present in the buffer up to that training iteration increases, together with the difference between the best and worst performing agents (denoted by gray bars). This indicates that as the population grows the diversity among the agents also improves, thus resulting in richer training signal for the meta-agents. In the Appendix, we include a similar plot for the meta-speaker reporting average BLEU score.</p><p>We also perform cross-play evaluation to test the generalization during out-of-population communication. For doing so, we obtain 5 meta-agents (5 meta-speakers and 5 meta-listeners) by using Algo 1 with 5 different seeds and report referential accuracy on the test set when pairing all possible combinations of meta-speakers and meta-listeners. On the left plot of Fig 7b we observe that, as expected, the in-population communication found on the diagonal is the best, and performance barely degrades when pairing agents that were not initialized with the same seed, indicating that our agents have learn more generalizable conventions. On the other hand, when conducting a similar evaluation with L2C (right plot), we observe that the protocols learnt in this case overfit to their own partners (diagonal) resulting in high variance across other players, and thus indicating the adoption of more ad-hoc protocols. Consequently, we posit that our method be used for few-shot generalization to unseen partners in a multi-agent interactive environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Robustness against implicit bias in the dataset</head><p>As agents trained using a single dataset may overfit to the objects present in that particular dataset, in this section we design an experiment to test the agents' robustness against implicit dataset biases. We conduct a cross-task evaluation experiment on the referential game with K = 9 distractors where we compute the referential accuracy using images from the Flickr8k dataset <ref type="bibr" target="#b16">[17]</ref> while the agents were trained using the images present in the MSCOCO dataset. Similarly, we also perform a within-task evaluation where we train and then evaluate our agents using the same Flickr8k dataset. We use 5000 images as training set and 1000 images as validation/test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PRETRAINED OURS</head><p>Cross-task 59.7 ยฑ 0.9 70.2 ยฑ 1.8 Within-task 65.3 ยฑ 0.3 78.9 ยฑ 1.4</p><p>Table <ref type="table">3</ref>: Referential accuracy on the test set showing robustness against implicit bias in the dataset.</p><p>Results are presented in Table <ref type="table">3</ref>. While we do observe a drop in the performance when compared to the within-task performance (70.2 v/s 78.9), our across-task model still outperforms the within-task PRETRAINED baseline (70.2 v/s 65.3). This observation correlates with our results using human players and out-of-population evaluation shown in Sec 4.3 and Sec 4.5 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a dynamic population-based method to train agents in a cooperative multi-agent reinforcement learning setup. We showed that our method induces useful diversity into a population of agents which helps in learning a robust meta-agent. Empirically, we show that our agents outperform prior work on the task performance, auxiliary tasks and even human-based evaluation. In the future, we plan to extend this approach in cases where agents are performing temporally extended physical actions in an environment with perceptual observations. One limitation of our approach pertains to maintaining a buffer of past agents that are used to train the meta-agent. Moreover, we would also like to analyze the effect of using task-independent language data (as opposed to task-dependent that we use now) within a multi-agent reinforcement learning task.   We use the Adam optimizer <ref type="bibr" target="#b19">[20]</ref> in PyTorch <ref type="bibr" target="#b39">[40]</ref> for training the agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Hyperparameters and other training details</head><p>For the baselines (S2P, SIL, L2C, GEN.TRANS.), we used the publicly available repositories attached with the respective publications. We adapt their codebase to train agents on the two referential games used in this work while tuning the hyperparameters separately for each method and each game keeping the same architecture across all baselines. We even used a larger batch size for some methods that performed better than the ones reported in the original papers. We chose the hyperparameters by performing a grid search over the values mentioned in Table <ref type="table" target="#tab_6">4</ref> and others in ยง4. We used the pretrained Resnet-50 embeddings of dimension 2048 for the image game and Sentence-BERT embeddings of size 768 for the text game. We used our internal cluster consisting of Nvidia V100 GPUs to train the models. The annotations in the MSCOCO dataset belong to the COCO Consortium and are licensed under a Creative Commons Attribution 4.0 License.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Further Results</head><p>In this section, we show results on the text game, ablation using meta-learning methods, and additional metrics to evaluate the natural language skills of the (meta-) speakers.  EMECOM results in the highest performance here. We argue that even though its performance on referential accuracy is higher than our method, the corresponding BLEU score (or its compatibility with a human partner) is โผ 0.</p><p>This means that it does not generalize to out-of-population agents or human partners and rather learns ad-hoc conventions that only generalize to its own partner, in line with previous work in emergent communication <ref type="bibr" target="#b24">[25]</ref>. Moreover, this behavior being only observed in |D| = 2000 case but not in the |D| = 5000 case indicates the existence of a threshold (in the # human samples) above which the EMECOM baseline would underperform against other methods, given the same task/network configuration. The blue bars show the standard deviation across all agents present in the buffer. Similar to the observations in ยง4.5, we find that the natural language skills of the meta-speaker improve as the training progress while the population still being diverse enough to provide rich learning signal for meta-training. </p><note type="other">Figure 12</note><p>Other meta-learning methods We also performed an ablation study using different meta-learning algorithms <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b37">38]</ref>. FOMAML is the first-order approximation of MAML and Reptile is another first-order meta-learning algorithm that performs stochastic gradient descent for a few steps across all tasks and then updates the parameter towards the average of updated taskspecific weights. We show the results in the image game using referential accuracy in Fig 12b <ref type="figure">.</ref> The performances of the all algorithms are competitive with each other indicating robustness across the three methods. Furthermore, we think that recent advancements in meta-learning algorithms <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b35">36]</ref> could be combined with our algorithm to further analyze this effect and investigate biases resulting from a specific meta-algorithm.</p><p>Natural language skills of meta-speakers We also show some corpus-level statistics for studying the linguistic diversity of the produced messages over and above the BLEU statistics shown in Sec 4.2.</p><p>โข Average ratio of the length of generated utterance per human utterance We analyze the average sentence length for all the generated utterances in the test set and compare that with the ground-truth utterances present in the dataset for the image game. We would like to point out that the utterances in the dataset were collected for a different task (image captioning and machine translation). Hence the generated captions are less diverse and shorter as compared to the human captions because the underlying interactive learning task only requires captioning in context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Human Experiment Setup</head><p>Our human experiments were done in a controlled environment with a group of 45 undergraduate and graduate students. The experiments were overseen and approved by our internal lab review board. The participants were not compensated for taking part in the experiments as our lab has been conducting such experiments in the past on a quid pro quo basis. Moreover, the participants were given the following instructions to play the game and were ensured that their individual identities would not be revealed or used in a way that could contaminate our results. Consequently, there were no participant risks involved in our experiments. In addition, to filter noise in the experiments, for each utterance we evaluated the performance of each participant against other participants. Concretely, we played each utterance of the (speaker) participant with 5 other (listener) participants and compared the performance across all 5 games. All utterances that do not obtain the same game score for at least 4/5 games were excluded. Further filtering was done based on a threshold given by the BLEU score (threshold=30) between the participant utterance and the ground-truth utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall instructions:</head><p>We are interested in conducting human experiments for the popular referential games proposed in Lewis et al, '69. It is a cooperative game that involves two players: a speaker and a listener. A speaker observes a target image and emits a message that is sent to the listener. The listener looks at the message and tries to identify the target image among a set of distractor images. Both agents are given a positive reward if the listener's prediction is accurate and zero otherwise. Our experiments require each participant to play as a speaker and a listener with different partners. Your partner could be a human or one of our trained agents. You will not be given the identities of your partners and your individual identities will not be used for analyzing the final results.</p><p>Message to the human speaker: You are assigned the role of a speaker. Look at the image carefully and write a caption that best describes the image.</p><p>Message to the human listener: You are assigned the role of a listener. Read the message carefully and use that to choose the target image for which the message was intended, among the set of other distractor images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Failure examples</head><p>We show some qualitative failure examples from the image game where our agents exhibit different kinds of errors. We group all of them into three categories:</p><p>โข Incorrect message due to imperfect vision Dataset utterance: a big black bear that is walking into the road Speaker message: A black dog crossing the road with cars.</p><p>In this test example, the speaker incorrectly uses dog for a bear.</p><p>โข Incorrect language usage by the speaker Dataset utterance: a young man with a lacrosse stick and nike bag dressed in a shirt and tie. Speaker message: A group of people standing with bags, tie, and bottle.</p><p>Here, the speaker tried to add all observed objects in the message without being semantically correct.</p><p>โข Incorrect language understanding by the listener Speaker message: A child with a teddy bear.</p><p>Listener chooses an incorrect target image that only contains teddy bears confusing the teddy bear with a child.</p><p>We believe that the speaker gets confused when it encounters an out-of-vocabulary object in the target image. Likewise, the listener chooses a wrong target image when the complexity of the distractors is increased (by using distractors with similar objects as in the target image). Nonetheless, we think these issues are not specific to our agent and would arise in any interactive learning model as we scale up to include more and more objects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Referential Game with images.</figDesc><graphic coords="2,353.79,555.17,115.28,81.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Meta-learning a listener using two types of population. In Fig 2a, a fixed set of speakers and listeners are trained using self-play. Then a meta-listener is trained by interacting with the fixed population of speakers. In Fig 2b, the meta-listener is trained using the current population of speakers at time t in top-phase. Speakers are added to this population iteratively by training the latest speaker (obtained at t โ 1) with the updated meta-listener (denoted by dashed arrow) in the bottom-phase. In Fig 2c, the final trained meta-listener plays with human speakers during test time.</figDesc><graphic coords="3,376.83,215.46,55.27,74.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Limited human dataset D.</figDesc><graphic coords="3,336.63,564.03,109.87,78.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>and D i and D o are sets of distractor objects sampled from O i and O o respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Referential accuracy of the (meta-) agents on the test set (Left): Image game and (Right) Text game (p &lt; 0.05, t-test).</figDesc><graphic coords="6,306.00,474.77,198.00,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Human evaluation on the image game. The black line in both plots represent the performance of the (Human-speaker, Humanlistener) pair.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Referential accuracy for different ablations in the image game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7a :Figure 7b :</head><label>7a7b</label><figDesc>Figure 7a: Average referential accuracy on the test set when a trained meta-listener individually plays with each speaker present in the buffer at the corresponding training iteration. The blue bars show the standard deviation across all speakers in the buffer. The gray bars show the interval between the minimum and maximum performing speaker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Qualitative samples generated by the (meta-) speaker in the game with images.</figDesc><graphic coords="10,108.00,72.00,396.00,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Detailed algorithm outline. We show the different phases involved in training a meta-listener L m and building the corresponding speaker population (buffer) B S . Similar outline can be drawn for training the meta-speaker S m .</figDesc><graphic coords="15,156.28,277.44,88.66,57.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 11 Referential</head><label>11</label><figDesc>Figure 11    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Fig 11b shows results on the text game with |D| = 5000 and K = 9. Similar to the trend observed in Fig 4, our method outperforms all other baselines. Induced Diversity In Fig 12a, we plot the average BLEU score of a trained meta-speaker, obtained after training, playing with different listeners at different stages of the training in the image game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Evaluating the (meta-) speaker in the image game using the metric proposed in<ref type="bibr" target="#b5">[6]</ref> (p &lt; 0.05, t-test).</figDesc><table><row><cell></cell><cell>Caption Score</cell><cell>BLEU</cell></row><row><cell>PRETRAINED</cell><cell>5.2 ยฑ 0.02</cell><cell>24.2 ยฑ 0.1</cell></row><row><cell>S2P</cell><cell>5.5 ยฑ 0.04</cell><cell>26.1 ยฑ 0.3</cell></row><row><cell>SIL</cell><cell>5.5 ยฑ 0.04</cell><cell>25.6 ยฑ 0.24</cell></row><row><cell>L2C</cell><cell>5.4 ยฑ 0.07</cell><cell>25.4 ยฑ 0.45</cell></row><row><cell>GEN.TRANS.</cell><cell>6.1 ยฑ 0.05</cell><cell>28.4 ยฑ 0.32</cell></row><row><cell>OURS</cell><cell>6.6 ยฑ 0.04</cell><cell>29.3 ยฑ 0.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>BLEU score on German sentences for (meta-) speaker in the text game across various baselines and decoding strategies. n denotes number of beams in beam-search (p &lt; 0.05, t-test).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Hyperparameters. Bold indicates the chosen values used for the final analysis.</figDesc><table><row><cell>We</cell><cell>show</cell><cell>here</cell><cell>the</cell><cell>range</cell><cell>of</cell><cell cols="2">parameter</cell><cell cols="2">configurations</cell><cell>we</cell><cell>tried</cell><cell>dur-</cell></row><row><cell>ing</cell><cell>training</cell><cell cols="2">(bold</cell><cell>indicates</cell><cell></cell><cell>the</cell><cell>ones</cell><cell>used</cell><cell>in</cell><cell>the</cell><cell>experiments):</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Name</cell><cell></cell><cell></cell><cell cols="2">Values used</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Batch Size</cell><cell></cell><cell cols="2">512, 1024</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Buffer Size</cell><cell></cell><cell cols="2">50, 100, 200</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n meta</cell><cell></cell><cell cols="3">20, 40, 60, 65, 70</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n sup</cell><cell></cell><cell></cell><cell cols="2">10, 20, 25, 30</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n int</cell><cell></cell><cell cols="3">40, 60, 70, 80, 100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ฮป hs</cell><cell></cell><cell></cell><cell cols="2">0.1, 0.01, 0.001</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ฮป hl</cell><cell></cell><cell cols="3">0.1, 0.03, 0.007, 0.001</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ฮป s</cell><cell></cell><cell></cell><cell cols="2">0.1, 0.5, 0.8, 1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Learning rate (outer loop) 1e-4, 1e-5, 6e-5, 6e-4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Learning rate (inner loop)</cell><cell></cell><cell cols="2">1e-4, 3e-4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ฮป int</cell><cell></cell><cell></cell><cell cols="2">1, 0.1, 5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>InFig 10,   we present the results of the human evaluation on the text game. Similar to the trend found in Sec 4.3, we show that agents trained using our method beat all prior baselines when paired with both human listeners and human speakers. Both Fig 10a and 10b are drawn using 100 agent (and human) utterances that translate an English sentence to German.</figDesc><table><row><cell>Human</cell><cell>Evaluation We</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">used 9 distractor objects</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">and the models trained with |D| = 5000 for both games. For the image game, in Fig 5a each agent speaker outputs 1000 utterances corresponding to all the images in the test set, which are then given to</cell><cell>Acc %</cell><cell>60 70 80</cell><cell>54.8</cell><cell cols="2">62.1 Pretrained S2P</cell><cell cols="4">60.9 Human Speaker SIL Gen.Trans.</cell><cell cols="2">67.2 Ours</cell><cell>71.5</cell><cell cols="2">Acc %</cell><cell>70 80</cell><cell>67.7</cell><cell cols="2">72.0 Pretrained S2P</cell><cell>Human Listener SIL Gen.Trans. 71.1</cell><cell>Ours 73.1</cell><cell>75.4</cell></row><row><cell cols="2">the human listeners to play the game. Similarly, for evaluating the agent listener</cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>60</cell><cell></cell><cell></cell></row><row><cell cols="2">with a human speaker, each</cell><cell cols="12">(a) Agent speaker vs Human listener</cell><cell cols="6">(b) Agent listener vs Human speaker</cell></row><row><cell cols="2">agent evaluates 400 human utterances in Fig 5b. The black line corresponds to 400 human-speaker vs human-</cell><cell cols="18">Figure 10: Human evaluation on the text game. The black bar in both plots represent the performance of the (Human-speaker, Human-listener) pair.</cell></row><row><cell cols="4">55 listener matches. 45 Acc % 65</cell><cell>45.3</cell><cell>62.1 Pretrained EmeCom</cell><cell cols="2">52.2</cell><cell>S2P SIL</cell><cell>47.6</cell><cell cols="2">51.1 L2C Gen.Trans.</cell><cell>53.5</cell><cell>57.7 Ours</cell><cell>Acc %</cell><cell cols="2">65 75 85</cell><cell>68.3</cell><cell>72.6 Pretrained EmeCom</cell><cell>73.7</cell><cell>S2P SIL</cell><cell>70.6</cell><cell>71.9 L2C Gen.Trans.</cell><cell>74.8</cell><cell>78.7 Ours</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">(a) Image game</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Text game</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Their approach uses a different setup that involves giving speaker access to the distractor objects.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We note that the participants were neither aware of the identity of the agent they were playing against nor they played consecutive games with the same agent. This allows for a more fair comparison of the language skills of agents since participants did not have the chance to adapt to ad-hoc conceptions potentially used by agents (e.g., consistently referring to cats as onions).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Note that our choice of using alternating updates for interactive learning and supervised learning is arbitrary and based on<ref type="bibr" target="#b32">[33]</ref>. We believe that any multi-objective learning method could work here.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding Transparency Statement</head><p>AG is supported by IBM scholarship. We thank Compute Canada for providing the compute resources to run the experiments.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11871</idno>
		<idno>arXiv: 1905.11871</idno>
		<title level="m">Miss Tools and Mr Fruit: Emergent communication in agents learning about object affordances</title>
				<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09">September 2015</date>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Compositionality and generalization in emergent languages</title>
		<author>
			<persName><forename type="first">Rahma</forename><surname>Chaabouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Kharitonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<editor>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joel</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">July 5-10, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4427" to="4442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoderdecoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriรซnboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10">October 2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09067</idno>
		<idno>arXiv: 1904.09067</idno>
		<title level="m">Emergence of Compositional Language with Deep Generational Transmission</title>
				<imprint>
			<date type="published" when="2019-04">April 2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to evaluate image captioning</title>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guandao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Language as a coordination tool evolves slowly</title>
		<author>
			<persName><forename type="first">Tamรกs</forename><surname>Dรกvid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Dunbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Society Open Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160259</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Emergent communication in a multi-modal, multi-step referential game</title>
		<author>
			<persName><forename type="first">Katrina</forename><surname>Evtimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Drozdov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03400</idno>
		<idno>arXiv: 1703.03400</idno>
		<imprint>
			<date type="published" when="2017-03">March 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">To populate is to regulate</title>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Fitzgerald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to Communicate with Deep Multi-Agent Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nando</forename><surname>Ioannis Alexandros Assael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><surname>Whiteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2137" to="2145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Seeded self-play for language learning</title>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Beyond Vision and LANguage: inTEgrating Realworld kNowledge (LANTERN)</title>
				<meeting>the Beyond Vision and LANguage: inTEgrating Realworld kNowledge (LANTERN)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="62" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Emergent linguistic phenomena in multi-agent communication games</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Harding Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="3691" to="3701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols</title>
		<author>
			<persName><forename type="first">Serhii</forename><surname>Havrylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2149" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Framing image description as a ranking task: Data, models and evaluation metrics (extended abstract)</title>
		<author>
			<persName><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="853" to="899" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">other-play&quot; for zero-shot coordination. CoRR, abs</title>
		<author>
			<persName><forename type="first">Hengyuan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Peysakhovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><forename type="middle">N</forename><surname>Foerster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003.02979, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Kharitonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahma</forename><surname>Chaabouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13687</idno>
		<idno>arXiv: 1905.13687</idno>
		<title level="m">Information Minimization In Emergent Languages</title>
				<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
				<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural language does not emerge &apos;naturally&apos; in multi-agent dialog</title>
		<author>
			<persName><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josรฉ</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="2962" to="2967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A unified game-theoretic approach to multiagent reinforcement learning</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Audrunas</forename><surname>Gruslys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Perolat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4190" to="4203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Emergence of linguistic communication from referential games with symbolic and pixel input</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-Agent Cooperation and the Emergence of (Natural) Language</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Peysakhovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-agent communication meets natural language: Synergies between functional and structural language learning</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Potapenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Tieleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="7663" to="7674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Countering language drift via visual grounding</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="4376" to="4386" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Emergent translation in multiagent communication</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Convention: A philosophical study</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ease-of-teaching and language structure from emergent communication</title>
		<author>
			<persName><forename type="first">Fushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bowling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alchรฉ-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15825" to="15835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollรกr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the pitfalls of measuring emergent communication</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS &apos;19</title>
				<meeting>the 18th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS &apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="693" to="701" />
		</imprint>
	</monogr>
	<note>International Foundation for Autonomous Agents and Multiagent Systems</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to learn to communicate</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adaptive and Multitask Learning Workshop at ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the interaction between supervision and self-play in emergent communication</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Countering language drift with seeded iterated learning. CoRR, abs</title>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumye</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003.12694, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Language structure is partly determined by social structure</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rick</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">e8559</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning unsupervised learning rules</title>
		<author>
			<persName><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Emergence of grounded compositional language in multiagent populations</title>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<idno>arXiv: 1803.02999</idno>
	</analytic>
	<monogr>
		<title level="j">On First-Order Meta-Learning Algorithms</title>
		<imprint>
			<date type="published" when="2018-03">March 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
				<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24">2017. April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Simpler grammar, larger vocabulary: how population size affects language</title>
		<author>
			<persName><forename type="first">Florencia</forename><surname>Reali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morten</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. B</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="page">20172586</biblScope>
			<date type="published" when="1871">1871. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERT-networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ProMP: Proximal meta-policy search</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Rothfuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignasi</forename><surname>Clavera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamim</forename><surname>Asfour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<editor>Maria Florina Balcan and Kilian Q</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<author>
			<persName><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
				<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016-06">Jun 2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Exploring structural inductive biases in emergent communication</title>
		<author>
			<persName><forename type="first">Agnieszka</forename><surname>Slowik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateja</forename><surname>Jamnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">B</forename><surname>Holden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1335">2002.01335, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning multiagent communication with backpropagation</title>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2244" to="2252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Shaping representations through communication: community size effect in artificial learning systems</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibl</forename><surname>Mourad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS Workshop on Visually Grounded Interaction and Language</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Origins of human communication</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tomasello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Sociolinguistic typology: Social determinants of linguistic complexity</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Trudgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The consequences of talking to strangers: Evolutionary corollaries of socio-cultural influences on linguistic form</title>
		<author>
			<persName><forename type="first">Alison</forename><surname>Wray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George W</forename><surname>Grace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="543" to="578" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
