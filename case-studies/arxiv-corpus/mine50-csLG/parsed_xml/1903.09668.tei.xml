<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Augmentation for Bayesian Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-10-24">24 Oct 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuexi</forename><surname>Wang</surname></persName>
							<email>yuexi.wang@chicagobooth.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Booth School of Business</orgName>
								<orgName type="institution">University of Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nicholas</forename><surname>Polson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Booth School of Business</orgName>
								<orgName type="institution">University of Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vadim</forename><forename type="middle">O</forename><surname>Sokolov</surname></persName>
							<email>vsokolov@gmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Volgenau School of Engineering</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Augmentation for Bayesian Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-10-24">24 Oct 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">A72804F2747CACD6212C4F11D143F446</idno>
					<idno type="arXiv">arXiv:1903.09668v4[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-31T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>deep learning</term>
					<term>data augmentation</term>
					<term>MCMC</term>
					<term>back-propagation</term>
					<term>SGD</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep Learning (DL) methods have emerged as one of the most powerful tools for functional approximation and prediction. While the representation properties of DL have been well studied, uncertainty quantification remains challenging and largely unexplored. Data augmentation techniques are a natural approach to provide uncertainty quantification and to incorporate stochastic Monte Carlo search into stochastic gradient descent (SGD) methods. The purpose of our paper is to show that training DL architectures with data augmentation leads to efficiency gains. We use the theory of scale mixtures of normals to derive data augmentation strategies for deep learning. This allows variants of the expectation-maximization and MCMC algorithms to be brought to bear on these high dimensional nonlinear deep learning models. To demonstrate our methodology, we develop data augmentation algorithms for a variety of commonly used activation functions: logit, ReLU, leaky ReLU and SVM. Our methodology is compared to traditional stochastic gradient descent with back-propagation. Our optimization procedure leads to a version of iteratively re-weighted least squares and can be implemented at scale with accelerated linear algebra methods providing substantial improvement in speed. We illustrate our methodology on a number of standard datasets. Finally, we conclude with directions for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks (DNNs) have become a central tool for Artificial Intelligence (AI) applications such as, image processing (ImageNet, <ref type="bibr" target="#b24">Krizhevsky et al. (2012)</ref>), object recognition (ResNet, <ref type="bibr" target="#b16">He et al. (2016)</ref>) and game intelligence (AlphaGoZero, <ref type="bibr" target="#b53">Silver et al. (2016)</ref>). The approximability <ref type="bibr" target="#b43">(Poggio et al., 2017;</ref><ref type="bibr" target="#b2">Bauer and Kohler, 2019)</ref> and rate of convergence of deep learning, either in the frequentist fashion <ref type="bibr" target="#b52">(Schmidt-Hieber, 2020)</ref> or from a Bayesian predictive point of view <ref type="bibr" target="#b45">(Polson and Rockova, 2018;</ref><ref type="bibr" target="#b59">Wang and Rockova, 2020)</ref>, have been well-explored and understood. <ref type="bibr" target="#b8">Fan et al. (2021)</ref> provides a selective overview of deep learning. However, training deep learners is challenging due to the high dimensional search space and the non-convex objective function. Deep neural networks have also suffered from issues such as local traps, miscalibration and overfitting. Various efforts have been made to improve the generalization performance and many of their roots lie in Bayesian modeling. For example, Dropout <ref type="bibr" target="#b58">(Wager et al., 2013)</ref> is commonly used and can be viewed as a deterministic ridge ℓ 2 regularization. Sparsity structure via spike-and-slab priors <ref type="bibr" target="#b45">(Polson and Rockova, 2018)</ref> on weights helps DNNs adapt to smoothness and avoid overfitting. <ref type="bibr" target="#b50">Rezende et al. (2014)</ref> propose stochastic back-propagation through the use of latent Gaussian variables.</p><p>In this paper, following the spirit of hierarchical Bayesian modeling, we develop data augmentation strategies for deep learning with a complete data likelihood function equivalent to weighted least squares regression. By using the theory of mean-variance mixtures of Gaussians, our latent variable representation brings all of the conditionally linear model theory to deep learning. For example, it allows for the straightforward specification of uncertainty at each layer of deep learning and for a wide range of regularization penalties. Our method applies to commonly used activation functions such as ReLU, leaky ReLU, logit (see also <ref type="bibr" target="#b10">Gan et al. (2015)</ref>), and provides a general framework for training and inference in DNNs. It inherits the advantages and disadvantages of data augmentation schemes. For approximation methods like Expectation-Maximization (EM) and Minorize-Maximization (MM), they are stable as they increase the objective but can be slow in the neighborhood of the maximum point even with acceleration methods such as Nesterov acceleration available and the performance is highly dependent on the properties of the objective function. Stochastic exploratory methods like MCMC have the main advantage of addressing uncertainty quantification (UQ) and are stable in the sense they require no tuning. Hyper-parameter estimation is immediately available using traditional Bayesian methods. DA augments the objective function with extra hidden units which allow for efficient step size selection for the gradient descent search. In some of the applications, data augmentation methods can be formulated in terms of complete data sufficient statistics, a considerable advantage when dealing with large datasets where most of the computational expense comes from repeatedly iterating over the data. By combing the MCMC methods with the J-copies trick <ref type="bibr" target="#b21">(Jacquier et al., 2007)</ref>, we can move faster towards posterior mode and avoid local maxima. Traditional methods for training deep learning models such as stochastic gradient descent (SGD) have none of the above advantages. We also note that we exploit the advantages of SGD and accelerated linear algebra methods when we implement our weighted least squares regression step.</p><p>Data augmentation strategies are commonplace in statistical algorithms and accelerated convergence <ref type="bibr" target="#b38">(Nesterov, 1983;</ref><ref type="bibr" target="#b14">Green, 1984)</ref> is available. Our goal is to show similar efficiency improvements for deep learning. Our work builds on <ref type="bibr" target="#b6">Deng et al. (2019)</ref> who provide adaptive empirical Bayes methods. In particular, we show how to implement standard activation functions, including ReLU <ref type="bibr" target="#b45">(Polson and Rockova, 2018)</ref>, logistic <ref type="bibr" target="#b62">(Zhou et al., 2012;</ref><ref type="bibr" target="#b17">Hernández-Lobato and Adams, 2015)</ref> and SVM <ref type="bibr" target="#b29">(Mallick et al., 2005)</ref> activation functions and provide specific data augmentation strategies and algorithms. The core subroutine of the resulting algorithms solves a least squares problem. Scalable linear algebra libraries such as Compute Unified Device Architecture (CUDA) and accelerated linear algebra (XLA) are available for implementation. To illustrate our approach, empirically we experiment with two benchmark datasets using Pólya-Gamma data augmentation for logit activation functions. For the deep architecture embedded in our approach, we adopt deep ReLU networks. Deep networks are able to achieve the same level of approximation accuracy with exponentially fewer parameters for compositional functions <ref type="bibr" target="#b32">(Mhaskar et al., 2017)</ref>. <ref type="bibr" target="#b43">Poggio et al. (2017)</ref> further show how deep networks can avoid the curse of dimensionality. The ReLU function is favored due to its ability to avoid vanishing gradients and its expressibility and inherent sparsity. Approximation properties of deep ReLU networks have been developed in <ref type="bibr" target="#b33">Montufar et al. (2014)</ref>, <ref type="bibr" target="#b54">Telgarsky (2017)</ref>, and <ref type="bibr" target="#b27">Liang and Srikant (2017)</ref>. <ref type="bibr" target="#b61">Yarotsky (2017)</ref> and <ref type="bibr" target="#b52">Schmidt-Hieber (2020)</ref> show that deep ReLU networks can yield a rateoptimal approximation of smooth functions of an arbitrary order. <ref type="bibr" target="#b45">Polson and Rockova (2018)</ref> provide posterior rates of convergence for sparse deep learning.</p><p>There is another active area of research that revives traditional statistical models with the computational power of DL <ref type="bibr" target="#b3">(Bhadra et al., 2021)</ref>. Examples include Gaussian Process models <ref type="bibr" target="#b18">(Higdon et al., 2008;</ref><ref type="bibr" target="#b13">Gramacy and Lee, 2008)</ref>, Generalized Linear Models (GLM) and Generalized Linear Mixed Models (GLMM) <ref type="bibr" target="#b56">(Tran et al., 2020)</ref> and Partial Least Squares (PLS) <ref type="bibr" target="#b44">(Polson et al., 2021)</ref>. Our method benefits from the computation efficiency and flexibility of expression of the deep neural network. In addition, our work builds on the sampling optimization literature <ref type="bibr" target="#b41">(Pincus, 1968</ref><ref type="bibr">(Pincus, , 1970) )</ref> which now uses MCMC methods. Other examples include <ref type="bibr" target="#b28">Ma et al. (2019)</ref> who study that sampling can be faster than optimization and <ref type="bibr" target="#b37">Neelakantan et al. (2017)</ref> showing that gradient noise can improve learning for very deep networks. <ref type="bibr" target="#b10">Gan et al. (2015)</ref> implements data augmentation inside learning deep sigmoid belief networks. <ref type="bibr">Neal (2011)</ref> and <ref type="bibr" target="#b5">Chen et al. (2014)</ref> provide Hamitonian Monte Carlo (HMC) algorithms for MCMC. <ref type="bibr" target="#b7">Duan et al. (2018)</ref> proposes a family of calibrated data-augmentation algorithms to increase the effective sample size.</p><p>The rest of our paper is outlined as follows. Section 2 provides the general setting of deep neural networks and shows how DA can be integrated into deep learning using the duality between Bayesian simulation and optimization. Section 3 describes our data augmentation (DA) schemes and two approaches to implement them. Section 4 provides applications to Gaussian regression, support vector machines and logistic regression using Pólya-Gamma augmentation <ref type="bibr">(Polson et al., 2013)</ref>. Section 5 provides the experiments of DA on both regression and classification problems. Section 6 concludes with directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bayesian Deep Learning</head><p>In deep learning we wish to recover a multivariate predictive map f θ (•) denoted by</p><formula xml:id="formula_0">y = f θ (x), where y = (y 1 , . . . , y n ) ′ , y i ∈ R denotes a univariate output and x = (x 1 , . . . , x n ) ′ , x i ∈ R p a high-dimensional set of inputs. Using training data of input-output pairs {y i , x i } n</formula><p>i=1 that generalizes well out-of-sample, the goal is to provide a predictive rule for a new input variable</p><formula xml:id="formula_1">x ⋆ y ⋆ = f θ(x ⋆ ),</formula><p>where θ is estimated from training data typically using SGD. The interest in deep learners lies in their ability to perform better than the additive rule for those interpolation or prediction problems. Other statistical alternatives include Gaussian processes but they often have difficulty in handling higher dimensions.</p><p>Deep learners use compositions <ref type="bibr" target="#b23">(Kolmogorov, 1957;</ref><ref type="bibr" target="#b57">Vitushkin, 1964)</ref> of ridge functions rather than additive functions that are commonplace in statistical applications. With L ∈ N we denote the number of hidden layers and with p l ∈ N the number of neurons at the l th layer. Setting p L+1 = p, p 0 = p 1 = 1, we denote with p = (p 0 , p 1 , . . . , p L+1 ) ∈ N L+2 the vector of neuron counts for the entire network. Imagine composing L layers, a deep predictor then takes the form</p><formula xml:id="formula_2">y = f θ (x) = (f W0,b0 • f W1,b1 • • • • • f WL,bL )(x), (2.1)</formula><p>where b l ∈ R p l is a shift vector, W l ∈ R p l−1 ×p l is a weight matrix that links neurons between (l −1) th and l th layers and</p><formula xml:id="formula_3">f W l ,b l (x) = f l (W l x+b l ) is a semi-affine function. We denote with θ = {(W 0 , b 0 ), (W 1 , b 1 ), . . . , (W L , b L )}</formula><p>as the stacked parameters. We can rewrite the compositions in (2.1) with a set of latent variables Z = (Z 1 , Z 2 , . . . , Z L ) ′ as</p><formula xml:id="formula_4">y = f 0 (Z 1 W 0 + b 0 ), Z l = f l (Z l+1 W l + b l ), l = 1, . . . , L, Z L+1 = x, (2.2)</formula><p>where Z l ∈ R n×p l is the matrix of hidden nodes in l-th layer. We only consider the case p = 1 and Z 1 ∈ R n in our work. We provide discussion on extensions to cases p &gt; 1 for some of our applications in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bayesian Simulation and Regularization Duality</head><p>The problem of deep learning regularization <ref type="bibr" target="#b49">(Polson and Sokolov, 2017)</ref> is to find a set of parameters θ which minimizes a combination of a negative log-likelihood ℓ(y, f θ (x)) and a penalty function φ(θ) defined by θ := arg min</p><formula xml:id="formula_5">θ n i=1 ℓ(y i , f θ (x i )) + λ #θ j=1 φ(θ j ),<label>(2.3)</label></formula><p>where λ controls regularization and #θ denotes the number of parameters in θ.</p><p>When the function f θ (x) is a deep learner defined as (2.1), we can specify different amount of penalty λ l and form of regularization function φ l (•) for each layer. Then the objective function can be written as</p><formula xml:id="formula_6">θ = arg min θ 1 n n i=1 ℓ(y i , f θ (x i )) + L l=0 λ l φ l (W l , b l ).</formula><p>(2.4)</p><p>Commonly used regularization techniques for deep learners include L 2 (weight decay), spike-and-slab regularization <ref type="bibr" target="#b45">(Polson and Rockova, 2018)</ref> and dropout <ref type="bibr" target="#b58">(Wager et al., 2013)</ref>, which can also be viewed as a variant of L 2 -regularization.</p><p>As such the optimization problem in (2.4) of training a deep learner f θ (•) involves a highly nonlinear objective function. Stochastic gradient descent (SGD) is a popular tool based on back-propagation (a.k.a. the chain rule), but it often suffers from local traps and overfitting due to the non-convex nature of the problem. We propose data augmentation techniques which can be seamlessly applied in this context and provide efficiency gains. This is achieved via the hierarchical duality between optimization with regularization and finding the maximum a posteriori (MAP) estimate <ref type="bibr" target="#b48">(Polson and Scott, 2011)</ref>, as described in the following lemma.</p><p>Lemma 2.1. The regularization problem</p><formula xml:id="formula_7">θ = arg min θ 1 n n i=1 ℓ(y i , f θ (x i )) + L l=0 λ l φ l (W l , b l )</formula><p>is equivalent to finding the the Bayesian MAP estimator defined by</p><formula xml:id="formula_8">arg max θ p(θ|y) = arg max θ exp − 1 n n i=1 ℓ(y i , f θ (x i )) − L l=0 λ l φ l (W l , b l ) ,</formula><p>which corresponds to the mode of a posterior distribution characterized as</p><formula xml:id="formula_9">p(θ | y) = p(y | θ)p(θ)/p(y), p(y|θ) ∝ exp{− n i=1 ℓ y i , f θ (x i ) }, p(θ) ∝ exp{− L l=0 λ l φ l (W l , b l )}.</formula><p>Here p(θ) can be interpreted as a prior probability distribution and the log-prior as the regularization penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A Stochastic Top Layer</head><p>By exploiting the duality from Lemma 2.1, we wish to use a Bayesian framework to add stochastic layers -so as to fully account for the uncertainty in estimating the predictive rule f θ (•). Thus, we convert the sequence of composite functions in the deep learner specified in (2.2) to a stochastic version given by</p><formula xml:id="formula_10">y | Z 1 ∼ p(y | Z 1 ), Z l ∼ N (f l (W l Z l+1 + b l ), τ 2 l ), l = 1, 2, . . . , L, Z L+1 = x.</formula><p>(2.5) Now the hidden variables Z = (Z 1 , . . . , Z L ) ′ can be viewed as data augmentation variables and hence will also allow the contribution of fast scalable algorithms for inference and prediction.</p><p>For the ease of computation, we only replace the top layer of the DNN with a stochastic layer. We denote network structure below the top layer with B = {(W 1 , b 1 ), . . . , (W L , b L )}, and the network structure can be rewritten as</p><formula xml:id="formula_11">y = f 0 (Z 1 W 0 + b 0 ), Z 1 = f B (x),</formula><p>where the function f 0 (Z 1 W 0 + b 0 ) is the top layer structure and function f B (x) is the network architecture below the top layer. Considering the objective function in (2.4), we implement the solutions with a two-step iterative search. At iteration t, we have 1. DA-update for the top layer W 0 , b 0 as the MAP estimator of the distribution</p><formula xml:id="formula_12">p(W 0 , b 0 | Z (t) 1 , y) ∝ p(y, Z (t) 1 | W 0 , b 0 )p(W 0 , b 0 ) (2.6) ∝ exp − 1 n n i=1 ℓ(y i , f θ (x i ) | B (t) ) + λ 0 φ 0 (W 0 , b 0 ) 2. SGD-update for the deep architecture B B (t+1) = arg min B 1 n n i=1 ℓ y i , f θ (x i ) | (W 0 , b 0 ) (t+1) + L l=1 λ l φ l (W l , b l ) = arg min B 1 n n i=1 ℓ Z (t) 1 , f B (x i ) + L l=1 λ l φ l (W l , b l ). 3. Sample Z (t+1) 1 from a normal distribution N (µ (t) z , σ<label>(t)</label></formula><p>z ) where µ</p><formula xml:id="formula_13">(t)</formula><p>z and σ (t) z are determined jointly by {θ (t) , x, y}.</p><p>The main contribution of our work comes from two aspects: (1) we update top layer weights {W 0 , b 0 } conditional on B as in (2.6), which is also equivalent to conditioning on Z 1 , with data augmentation techniques as later shown in Section 3; (2) the latent variables Z 1 is sampled from a normal distribution rather than optimized by gradient descent methods. Z 1 serves as a bridge that connects a weighted L 2 -norm model f 0 and a deep learner f B . Commonly used activation functions {f l } L l=1 are linear affine functions, rectified linear units (ReLU), sigmoid, hyperbolic tangent (tanh), and etc. We illustrate our methods with a deep ReLU network, i.e., {f l } L l=1 are ReLU functions, due to its expressibility and inherent sparsity. In the next section, we introduce our data augmentation strategies and show how the stochastic layers can be achieved via data augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Augmentation for Deep Learning</head><p>Data augmentation introduces a vector of auxiliary variables, denoted by ω = (ω 1 , . . . , ω n ) ′ with ω i ∈ R, such that the posterior can be written as</p><formula xml:id="formula_14">p(θ | y) = E ω p(θ, ω | y) ,</formula><p>where the augmented auxiliary distribution, p(θ, ω | y) factorizes nicely into complete conditionals p(θ | ω, y) and p(ω | θ, y). A crucial ingredient is that p(θ | ω, y) is easily managed typically via conditional Gaussians.</p><p>Data augmentation tricks allow us to express the likelihood as an expectation of a weighted L 2 -norm. Specifically, we write</p><formula xml:id="formula_15">exp − ℓ y, f θ (x) = E ω exp − Q y | f θ (x), ω = ∞ 0 exp − Q y | f θ (x), ω p(ω)d ω</formula><p>where p(ω) is the prior on the auxiliary variables ω = (ω 1 , . . . , ω n ) ′ and the function Q y | f θ (x), ω is designed to be a quadratic form, given the data augmentation variables ω. The function</p><formula xml:id="formula_16">f θ (x) = (f 0 • • • • • f L )(x) is a deep learner.</formula><p>Table <ref type="table">1</ref> shows that standard activation functions such as ReLU, logit, lasso and check can be expressed in the form of (3.1). Commonly used activation functions for deep learning, with an appropriate stochastic assumptions for w (for notation of simplicity, we derive the standard form for the single observation case) can be expressed as</p><formula xml:id="formula_17">exp(− max(1 − x, 0)) = E ω 1 √ 2πω exp − 1 2ω (x − 1 − ω) 2 , where ω ∼ GIG(1, 0, 0), exp(− log(1 + e x )) = E ω exp(− 1 2 ωx 2 ) , where ω ∼ PG(1, 0), exp(−|x|) = E ω 1 √ 2πω exp − 1 2ω x 2 , where ω ∼ E 1 2 .</formula><p>Here GIG denotes the Generalized Inverse Gaussian distribution, PG represents the Pólya Gamma distribution <ref type="bibr">(Polson et al., 2013)</ref>, and E represents the exponential distribution.</p><formula xml:id="formula_18">l(W, b) Q(W, b, ω) p(ω) ReLU: max(1 − z i , 0) ∞ 0 1 √ 2πcλ exp − (x + aλ) 2 2cλ d λ = 1 a exp − 2 max(ax, 0) c GIG(1, 0, 0) Logit: log(1 + e zi ) 1 2 b e (a−b/2)ψ ∞ 0 e −ωψ 2 /2 p(ω)d ω = (e ψ ) a (1 + e ψ ) b PG(b, 0) Lasso: | zi σ | ∞ 0 1 √ 2πcλ exp − x 2 2cλ e − 1 2 λ d λ = 1 c exp − |x| c E( 1 2 ) Check: |z i | + (2τ − 1)z i ∞ 0 1 √ 2πcλ exp − (x + (2τ − 1)λ) 2 2c 2 λ e −2τ (1−τ )λ d λ = 1 c exp − 2 c ρ τ (x) GIG(1, 0, 2 √ τ − τ 2 ) x Table 1: Data Augmentation Strategies. Here ρ τ (x) = 1 2 |x| + τ − 1 2 x is the check function.</formula><p>Using the data augmentation strategies, the objectives are represented as mixtures of Gaussians. DA can perform such an optimization with only the use of a sequence of iteratively re-weighted L 2 -norms. This allows us to use XLA techniques to accelerate the training.</p><p>Remark 3.1. The log-posterior is optimized given the training data, {y i , x i } n i=1 . Deep learning possesses the key property that ∇ θ log p(y|θ, x) is computationally inexpensive to evaluate using tensor methods for very complicated architectures and fast implementation on large datasets. One caveat is that the posterior is highly multi-modal and providing good hyperparameter tuning can be expensive. This is clearly a fruitful area of research for state-of-the-art stochastic MCMC algorithms to provide more efficient algorithms. For shallow architectures, the alternating direction method of multipliers (ADMM) is an efficient solution to the optimization problem.</p><p>Similarly we can represent the regularization penalty exp(−λφ(θ)) in data augmentation form. Hence, we can then replace the optimization problem in (2.4) with</p><formula xml:id="formula_19">θ := arg max θ E ω exp − 1 n n i=1 Q y i | f θ (x i ), ω − L l=0 λ l φ l (W l , b l ) , (3.1)</formula><p>using the duality in Lemma 2.1.</p><p>There are two approaches to Monte Carlo optimization which could handle our data augmentation <ref type="bibr" target="#b12">(Geyer, 1996)</ref>, missing data methods like Expectation-Maximization (EM) algorithms or stochastic search methods like Markov Chain Monte Carlo (MCMC). The first approach is based on a probabilistic approximation of the objective function (3.1) and is less concerned with exploring Θ. The second type is more exploratory which aims to optimize the objective function by visiting the entire range of Θ and is less tied to the properties of the function.</p><p>For EM algorithms, we consider constructing a surrogate optimization problem which has the same solution to (3.1) <ref type="bibr" target="#b26">(Lange et al., 2000)</ref>. Specifically, we define a new objective function as</p><formula xml:id="formula_20">H(θ) = E ω|θ exp − 1 n n i=1 Q y i | f θ (x i ), ω − L l=0 λ l φ l (W l , b l ) ,</formula><p>which is a concave function to be maximized. A natural choice of the surrogate function can be constructed using Jensen's inequality as</p><formula xml:id="formula_21">G θ | θ (t) = − E ω|θ (t) 1 n n i=1 Q y i | f θ (x i ), ω + L l=0 λ l φ l (W l , b l ) ,</formula><p>where each ω i is drawn from conditional distribution p(ω i | θ) ∝ p(ω i , θ) and the minorization is satisfied as log</p><formula xml:id="formula_22">H(θ) ≥ G θ | θ (t) .</formula><p>Maximizing G θ | θ (t) with respect to θ drives H(θ) uphill. The ascent property of the EM algorithm relies on the nonnegativity of the Kullback-Leibler divergence of two conditional probability densities <ref type="bibr" target="#b20">(Hunter and Lange, 2004;</ref><ref type="bibr" target="#b25">Lange, 2013a)</ref>. The EM algorithm enjoys the numerical stability as it steadily increases the likelihood without wildly overshooting or undershooting. It simplifies the optimization problem by (1) avoiding large matrix inversion; (2) linearizing the objective function;</p><p>(3) separating the variables of the optimization problem <ref type="bibr" target="#b25">(Lange, 2013b)</ref>. In Section 4.3 we show how Pólya-Gamma augmentation leads to an EM algorithm for logistic regression.</p><p>The exploratory alternative to solve (3.1) is stochastic search methods such as MCMC. The data augmentation strategies enable us to sample from the joint posterior</p><formula xml:id="formula_23">p(θ | y) ∝ exp − 1 n n i=1 ℓ y i , f θ (x i ) − L l=0 λ l φ l (W l , b l ) = E ω exp − 1 n n i=1 Q y i | f θ (x i ), ω − L l=0 λ l φ l (W l , b l ) = ∞ 0 exp − 1 n n i=1 Q(y i | f θ (x i ), ω p(ω)p(θ)d ω</formula><p>where the prior is related to the regularization penalty, via p(θ) ∝ exp − L l=0 λ l φ l (W l , b l ) . Hence, we can provide an MCMC algorithm in the augmented space (θ, ω) and simulate from the joint posterior distribution, denoted by p(θ, ω | y), namely</p><formula xml:id="formula_24">p(θ, ω | y) ∝ exp − Q(y | f θ (x), ω) p(θ)p(ω).</formula><p>A sequence can be simulated using MCMC Gibbs conditionals,</p><formula xml:id="formula_25">p θ (t) | ω (t) , y ∝ exp − Q(y | f θ (x), ω (t) ) p(θ), p ω (t+1) | θ (t) , y ∝ exp − Q(y | f θ (t) (x), ω) p(ω).</formula><p>Then we recover stochastic draws θ (t) ∼ p(θ | y) from the marginal posterior. These draws can be used in prediction to account for predictive uncertainty, namely</p><formula xml:id="formula_26">p y ⋆ | f (x ⋆ ) = p y ⋆ | θ, f θ (x ⋆ ) p(θ | y)d θ ≈ 1 T T t=1 p y ⋆ | θ (t) , f θ (t) (x ⋆ ) . (3.2) As Q(y | f θ (x)</formula><p>, ω) is conditionally quadratic, the update step for θ | ω, y can be achieved using SGD or a weighted L 2 -norm -the weights ω are adaptive and provide an automatic choice of the learning rate, thus avoiding backtracking which can be computationally expensive. And the performance of MCMC search is less tied to the statistical properties (i.e. convexity or concavity) of the objective function. We provide examples of how Gaussian regression and SVMs can be implements in Section 4.1 and Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MCMC with J-copies</head><p>The MCMC methods offer a full description of the objective function (3.1) over the entire space Θ. Inspired by the simulated annealing algorithm <ref type="bibr" target="#b31">(Metropolis et al., 1953)</ref>, we introduce a scaling factor J to allow for faster moves on the surface of (3.1) to maximize. It also helps avoiding the trapping attraction of local maxima. In addition, the corresponding posterior is connected to the Boltzmann distribution, whose density is prescribed by the energy potential f (θ) and temperature J as</p><formula xml:id="formula_27">π J (θ) = exp {−Jf (θ)} /Z J for θ ∈ Θ (3.3)</formula><p>where</p><formula xml:id="formula_28">Z J = Θ exp {−Jf (θ)} dθ is an appropriate normalizing constant.</formula><p>To simulate the posterior mode without evaluating the likelihood directly <ref type="bibr" target="#b21">(Jacquier et al., 2007)</ref>, we sample J independent copies of hidden variable Z 1 . Denoted the copies with Z 1 1 , . . . , Z J 1 , we sample them simultaneously and independently from the posterior distribution</p><formula xml:id="formula_29">Z j 1 |θ, x, y iid ∼ N (µ z , σ 2 z ), j = 1, . . . , J,</formula><p>where µ z , σ z are determined by {x, y, θ}. And we stack the J copies as</p><formula xml:id="formula_30">y (S) =        y y y . . . y        , Z (S) 1 =        Z 1 1 Z 2 1 Z 3 1 . . . Z J 1        , f B (x (S) ) =        f B (x) f B (x) f B (x) . . . f B (x)        (3.4)</formula><p>where y (S) , Z (S) 1</p><p>and f B (x (S) ) are (n × J)-dimensional vectors. We use Z (S) 1</p><p>to amplify the information in y, which is especially useful in the finite sample problems. Figure <ref type="figure" target="#fig_0">1</ref> illustrates our network architecture. given data y, x can be written as</p><formula xml:id="formula_31">π J (θ, Z (S) 1 | x, y) ∝ J j=1 p(y | θ, Z j 1 )p(Z j 1 | θ, x, y)p(θ).</formula><p>Hence, the marginal joint posterior</p><formula xml:id="formula_32">p(θ | x, y) = π J (θ, Z (S) 1 | x, y)d Z (S) 1</formula><p>concentrates on the density proportional to p(x, y | θ) J p(θ) and provides us with a simulation solution to finding the MAP estimator <ref type="bibr" target="#b41">(Pincus, 1968</ref><ref type="bibr">(Pincus, , 1970))</ref>.</p><p>Another alternative to simulate from the posterior mode is Hamiltonian Monte Carlo <ref type="bibr">(Neal, 2011)</ref>, which is a modification of Metropolis-Hastings (MH) sampler. Adding an additional momentum variable ν to the Boltzmann distribution in (3.3), and generating draws from joint distribution</p><formula xml:id="formula_33">π J (θ, ω) ∝ exp −Jf (θ) − (1/2)ν T M −1 ν ,</formula><p>where M is a mass matrix. <ref type="bibr" target="#b5">Chen et al. (2014)</ref> adopt this approach in a deep learning setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Connection to Diffusion Theory</head><p>An alternative to the MCMC algorithm can be derived from diffusion theory <ref type="bibr" target="#b40">(Phillips and Smith, 1996)</ref>. For example, we can approximate the random walk Metropolis-Hastings algorithm with the Langevin diffusion L t defined by the stochastic differential equation</p><formula xml:id="formula_34">dL t = dB t + 1 2 ∇ log f (L t )dt</formula><p>, where B t is the standard Brownian motion. More specifically, let d := |θ|, we write the random walk like transition as</p><formula xml:id="formula_35">θ (t+1) = θ (t) + σ 2 2 ∇ log f (θ (t) ) + σǫ t ,</formula><p>where ǫ t ∼ N d (0, I d ) and σ 2 corresponds to the discretization size.</p><p>This can also be derived by taking a second-order approximation of log(f ), namely</p><formula xml:id="formula_36">log f (θ (t+1) ) = log f (θ (t) ) + θ (t+1) − θ (t) ′ ∇ log f (θ (t) ) − 1 2 θ (t+1) − θ (t) ′ H(θ (t) ) θ (t+1) − θ (t) ,</formula><p>where</p><formula xml:id="formula_37">H(θ (t) ) = −∇ 2 log f (θ (t)</formula><p>) is the Hessian matrix. By taking exponential transformation on both sides, the random walk type approximation to f (θ (t+1) ) is</p><formula xml:id="formula_38">f (θ (t+1) ) ∝ exp θ (t+1) − θ (t) ′ ∇ log f (θ (t) ) − 1 2 θ (t+1) − θ (t) ′ H(θ (t) ) θ (t+1) − θ (t) ∝ exp − 1 2 θ (t+1) − θ (t) ′ H(θ (t) ) θ (t+1) − θ (t)</formula><p>.</p><p>where θ</p><formula xml:id="formula_39">(t) = θ (t) +H −1 (θ (t) )∇ log f (θ (t)</formula><p>). If we simplify this approximation by replacing H(θ (t) ) with σ −2 I p , the Taylor approximation leads to updating step as</p><formula xml:id="formula_40">θ (t+1) = θ (t) + σ 2 ∇ log f (θ (t) ) + σǫ t .</formula><p>Roberts and Rosenthal (1998) give further discussion on the choice of σ that would yield an acceptance rate of 0.574 to achieve optimal convergence rate. <ref type="bibr" target="#b30">Mandt et al. (2017)</ref> show that SGD can be interpreted as a multivariate Ornstein-Uhlenbeck process</p><formula xml:id="formula_41">dθ (t) = −ηAθ (t) dt + η C S dW (t) ,</formula><p>here η is the constant learning rate, A is the symmetric Hessian matrix at the optimum and C S is the covariance of the mini-batch (of size S) gradient noise, which is assumed to be approximately constant near the local optimum of the loss. They also provide results on discrete-time dynamics on other Stochastic Gradient MCMC algorithms, such as Stochastic Gradient Langevin dynamics (SGLD) by <ref type="bibr" target="#b60">Welling and Teh (2011)</ref> and Stochastic Gradient Fisher Scoring by <ref type="bibr" target="#b0">Ahn et al. (2012)</ref>.</p><p>Combing their results and the Langevin dynamics of MCMC algorithms, we can write the approximation of our DA-DL updating scheme as</p><formula xml:id="formula_42">W 0 b 0 (t+1) = W 0 b 0 (t) + σ 2 ∇ log f 0 (Z (t) 1 W (t) 0 + b (t) 0 ) + σǫ 0t , B (t+1) = B (t) − η∇ 2 f B * (x)B (t) + C √ S ηǫ Bt .</formula><p>Similar adaptive dynamics are also observed in other methods. <ref type="bibr" target="#b11">Geman and Hwang (1986)</ref> show the convergence of the annealing process using Langevin equations. Slice sampling <ref type="bibr" target="#b35">(Neal, 2003)</ref> adaptively chooses the step size based on the local properties of the density function. By constructing local quadratic approximations, it could adapt to the dependencies between variables. <ref type="bibr" target="#b34">Murray et al. (2010)</ref> further propose elliptical slice sampling that operates on the ellipse of states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications</head><p>To illustrate our methodology, we provide three examples: (1) a standard Gaussian regression model with squared loss; (2) a binary classification model under the support vector machine framework; (3) a logistic regression model paired with a Pólya mixing distribution. For the Gaussian regression and SVM models, we implement with J-copies stacking strategy to provide full posterior modes.</p><p>Before diving into the examples, we introduce the notations we use throughout this section. We continue to denote the output with y = (y 1 , . . . , y n ) ′ , y i ∈ R, the input with x = (x 1 , . . . , x n ) ′ , x i ∈ R p , the latent variable of the top layer with Z 1 = (z 1,1 , . . . , z 1,n ) ′ , z 1,i ∈ R and the stacked version as in (3.4). We introduce stochastic noises ǫ 0 = (ǫ 0,1 , . . . , ǫ 0,n ) ′ in the top layer and ǫ z = (ǫ z,1 , . . . , ǫ z,n ) ′ in the second layer, where ǫ 0,i iid ∼ N (0, τ 2 0 ) and ǫ z,i iid ∼ N (0, τ 2 z ). The scale parameters τ 0 and τ z are pre-specified and determine the level of randomness or uncertainty for the DA-update and SGD-update respectively. We use η to denote the learning rate used in the SGD updates and T is number of training epochs. We use • to denote ℓ 2 -norm such that y = n i=1 y 2 i and the matrix-type norm as y Σ = y T Σy. Our models differ from standard deep learning models and some newly proposed Bayesian approaches in the adoption of stochastic noises ǫ 0 and ǫ z . It distinguishes our model from other deterministic neural networks. By letting ǫ z follow a spiky distribution that puts most of its mass around zero, we can control the estimation approximating to posterior mode instead of posterior mean. The randomness allows us to adopt a stacked system and make the best use of data especially when the dataset is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Gaussian Regression</head><p>We consider the regression model as</p><formula xml:id="formula_43">y i = z 1,i W 0 + b 0 + ǫ 0,i ,</formula><p>where</p><formula xml:id="formula_44">y i ∈ (−∞, ∞), ǫ 0,i i.i.d ∼ N (0, τ 2 0 ), z 1,i = f B (x i ) + ǫ z,i ,</formula><p>where ǫ z,i i.i.d</p><p>∼ N (0, τ 2 z ). The posterior updates are given by</p><formula xml:id="formula_45">Ŵ0 = Cov(Z 1 , y)/Var(Z 1 ), (4.1) b0 = ȳ − W 0 Z1 , (4.2) p(Z 1 | y, x, θ) = C z exp − 1 2τ 2 0 y − Z 1 W 0 − b 0 2 − 1 2τ 2 z Z 1 − f B (x) 2 ,</formula><p>where ȳ = 1 n n i=1 y i and C z is a normalizing constant. The latent variable Z 1 is drawn from following normal distribution Z 1 ∼ N (µ Z , σ 2 Z ) with the mean and variance specified as</p><formula xml:id="formula_46">µ Z = τ 2 z W 0 (y − b 0 ) + τ 2 0 f B (x) W 2 0 τ 2 z + τ 2 0 , σ 2 Z = τ 2 0 τ 2 z W 2 0 τ 2 z + τ 2 0 . (4.</formula><p>3)</p><p>The J copies of Z 1 are simulated and stacked as</p><formula xml:id="formula_47">Z j 1 iid ∼ N (µ Z , σ 2 Z ), Z<label>(S) 1</label></formula><p>= (Z 1 1 , . . . , Z J 1 ) ′ . The updating scheme for this Gaussian regression is summarized in Algorithm 1.</p><p>The model can also be generalized to multivariate y. Let y i be a q-dimension vector, we denote each dimension as y ik , k = 1, . . . , q, and the model is written as</p><formula xml:id="formula_48">y ik = z 1,i W 0k + b 0k + ǫ 0,ik ,</formula><p>where</p><formula xml:id="formula_49">y ik ∈ (−∞, ∞), ǫ 0,ik iid ∼ N (0, τ 2 0 ), z 1,i = f B (x i ) + ǫ z,i ,</formula><p>where ǫ z,i iid ∼ N (0, τ 2 z ), where W 0 = (W 01 , . . . , W 0q ) ′ is now a q-dimensional vector with W 0k computed similarly to (4.1), b 0 = (b 01 , . . . , b 0q ) ′ is also q-dimensional with b 0k calculated as (4.2). The posterior update for Z 1 becomes</p><formula xml:id="formula_50">p(Z 1 | y, x, θ) = C z exp − 1 2τ 2 0 q k=1 y k − Z 1 W 0k − b 0k 2 − 1 2τ 2 z Z 1 − f B (x) 2 ,</formula><p>Algorithm 1 Data Augmentation with J-copies for Gaussian Regression (DA-GR) Update the weights in the top layer with {y (S) , Z</p><formula xml:id="formula_51">1: Initialize B (0) , W<label>(</label></formula><formula xml:id="formula_52">(t,S) 1 } W (t) 0 = Cov(Z (t,S) 1 , y (S) )/Var(Z (t,S) 1 ) b (t) 0 = ȳ(S) − W (t) 0 Z1 (t,S)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Update the deep learner f B with {Z</p><formula xml:id="formula_53">(t,S) 1 , x (S) } B (t) = B (t−1) − η∇f B (t−1) x (S) | Z (t,S) 1 ⊲ SGD 5: Update Z (S) 1</formula><p>jointly from deep learner f B and sampling layer f 0</p><formula xml:id="formula_54">Z 1 j,(t+1) | W (t) 0 , b (t) 0 , y, f B (t) (x) iid ∼ N µ (t) z , σ (t) z 2 , j = 1, . . . , J 6: return ŷ = W (T ) 0 f B (T ) (x) + b (T ) 0</formula><p>which is a multivariate normal distribution with the mean and variance as</p><formula xml:id="formula_55">µ Z = τ 2 z q k=1 W 0k (y k − b 0k ) + τ 2 0 f B (x) τ 2 z q k=1 W 2 0k + τ 2 0 , σ 2 Z = τ 2 0 τ 2 z τ 2 z q j=k W 2 0k + τ 2 0 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Support Vector Machines (SVMs)</head><p>Support vector machines require data augmentation for rectified linear unit (ReLU) activation functions. <ref type="bibr" target="#b48">Polson and Scott (2011)</ref> and <ref type="bibr" target="#b29">Mallick et al. (2005)</ref> write the support vector machine model as</p><formula xml:id="formula_56">y = Z 1 W 0 + λ + √ λǫ 0 , where λ ∼ p(λ),</formula><p>where p(λ) follows a flat uniform prior. The augmentation variable λ = (λ 1 , . . . , λ n ) ′ can be regarded as slacks admitting fuzzy boundaries between classes.</p><p>By incorporating the augmentation variable λ, the ReLU deep learning model can be written as</p><formula xml:id="formula_57">y i = z 1,i W 0 + λ i + λ i ǫ 0,i , where y i ∈ {−1, 1}, ǫ 0,i i.i.d ∼ N (0, τ 2 0 ), z 1,i = f B (x i ) + ǫ z,i , where ǫ z,i i.i.d ∼ N (0, τ 2 z )</formula><p>. From a probabilistic perspective, the likelihood function for the output y is given by</p><formula xml:id="formula_58">p(y i | W 0 , z 1,i ) ∝ exp − 2 τ 2 0 max(1 − y i z 1,i W 0 , 0) ∝ ∞ 0 1 τ 0 √ 2πλ i exp − 1 2τ 2 0 (1 + λ i − y i z 1,i W 0 ) 2 λ i d λ i .</formula><p>Derived from this augmented likelihood function, the conditional updates are</p><formula xml:id="formula_59">W 0 | y, Z 1 , λ ∝ n i=1 1 τ 0 √ λ i exp − 1 2τ 2 0 n i=1 (1 + λ i − y i z 1,i W 0 ) 2 λ i Z 1 | y, x, W 0 , B ∝ exp − 1 2τ 2 0 y − Z 1 W 0 2 Λ −1 − 1 2τ 2 z Z 1 − f B (x) 2</formula><p>where Λ = diag(λ 1 , . . . , λ n ) is the diagonal matrix of the augmentation variables.</p><p>In order to generate the latent variables, we use conditional Gibbs sampling as</p><formula xml:id="formula_60">λ −1 i | W 0 , y i , z 1,i ∼ IG(|1 − y i z 1,i W 0 | −1 , τ −2 0 ) (4.4) W 0 | y, Z 1 , λ ∼ N (µ w , σ 2 w ) (4.5) Z 1 | y, x, W 0 , B ∼ N (µ z , σ 2 z ) (4.6)</formula><p>with the means and variances given by</p><formula xml:id="formula_61">µ w = n i=1 y i z 1,i 1+λi λi τ 2 0 n i=1 y 2 i z 2 1,i λi , σ 2 w = 1 τ 2 0 n i=1 y 2 i z 2 1,i λi , µ z = W 0 τ 2 z y + τ 2 0 f B (x)Λ1 W 0 τ 2 z + τ 2 0 Λ1 , σ 2 z = τ 2 0 τ 2 z Λ1 W 2 0 τ 2 z + τ 2 0 Λ1</formula><p>, where IG denotes the Inverse Gaussian distribution and 1 = (1, . . . , 1) ′ is a n-dimensional unit vector.</p><p>The J-copies strategy can also be adopted here. Z j 1 and λ j needs to be sampled independently for j = 1, . . . , J. Algorithm 2 summarizes the updating scheme with J-copies for SVMs.</p><p>Algorithm 2 Data Augmentation with J-copies for SVM (DA-SVM)</p><formula xml:id="formula_62">1: Initialize B (0) , W (0) 0 , λ (0) 2: for epoch t = 1, . . . , T do 3:</formula><p>Update the weights and slack variables in the top layer with {y (S) , Z</p><formula xml:id="formula_63">(t,S) 1 } {λ (t,S) } −1 | W (t−1) 0 , y (S) , Z (t,S) 1 ∼ IG(|1 − y (S) Z (t,S) 1 W (t−1) 0 | −1 , 1 τ 2 0 ) W (t) 0 | y (S) , Z (t,S) 1 , λ (t,S) ∼ N (µ (t) ω , σ (t) ω 2 ) 4: Update the deep learner f B with {Z (t,S) 1 , x (S) } B (t) = B (t−1) − η∇f B (t−1) x (S) | Z (t,S) 1 ⊲ SGD 5: Update Z (S) 1</formula><p>jointly from the deep learner f B and the sampling layer</p><formula xml:id="formula_64">W 0 Z j,(t+1) 1 | W (t) 0 , λ j,(t) , y, f B (t) (x) iid ∼ N (µ (t) z , σ (t) z 2 ), j = 1, . . . , J 6: return ŷ = 1, if W (T ) 0 f B (T ) (x) &gt; 0 −1, otherwise.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Logistic Regression</head><p>The aim of this example is to show how EM algorithm can be implemented via a weighted L 2 -norm in deep learning. Adopting the logistic regression model from <ref type="bibr">Polson and Scott (2013)</ref>, we focus on the penalization of W 0 , with parameter optimization given by Ŵ0 = arg min</p><formula xml:id="formula_65">W0 1 n n i=1 log 1 + exp − y i f DL B (x i )W 0 + φ(W 0 | τ ) ,</formula><p>The outcomes y i are coded as ±1, and τ is assumed fixed.</p><p>For likelihood function ℓ and regularization penalty φ, we assume</p><formula xml:id="formula_66">p(y i | σ) ∝ ∞ 0 √ ω i √ 2πσ exp − ω i 2σ 2 y i f B (x i )W 0 − 1 2ω i 2 p(ω i )d ω j , (4.7) p(W 0 | τ ) = ∞ 0 √ λ √ 2πτ exp − λ 2τ 2 (W 0 − µ W − κ W λ −1 ) 2 p(λ)d λ, (4.8)</formula><p>where µ W , κ W are pre-specified terms controlling the prior of the penalty term and λ is endowed with a Pólya distribution prior P (λ). Let ω −1 i have a Pólya distribution with α = 1, κ = 1/2, the following three updates will generate a sequence of estimates that converges to a stationary point of posterior</p><formula xml:id="formula_67">W (t+1) 0 = (τ −2 Λ (t) + x T * Ω (t) x * ) −1 ( 1 2 x T * 1), ω (t+1) i = 1 z (t+1) i e z (t+1) i 1 + e z (t+1) i − 1 2 , λ (t+1) = κ W + τ 2 φ ′ (W (t) 0 | τ ) W (t) 0 − µ W , where z (t) i = y i z T 1,i W (t) 0 = y i logit(ŷ t i ),</formula><p>x * is a matrix with rows x * i = y i z 1,i , Ω = diag(ω 1 , . . . , ω n ) and Λ = diag(λ 1 , . . . , λ p ) are diagonal matrices. x * can be written as x * = diag(y)Z 1 , φ ′ (•) denotes the derivative of standard normal density function.</p><p>In the non-penalized case, with λ i = 0 for every i, the updates can be simplified as weighted least squares</p><formula xml:id="formula_68">W (t+1) 0 = (Z (t) 1 T diag(y)Ω (t) diag(y)Z (t) 1 ) −1 ( 1 2 y T Z (t) 1 ), ω (t+1) i = 1 z (t+1) i e z (t+1) i 1 + e z (t+1) i − 1 2 .</formula><p>We focus on the non-penalized binary classification case and Algorithm 3 summarizes our approach. Further generalizations are available. For example, a ridge-regression penalty, along with the generalized double-pareto prior <ref type="bibr" target="#b1">(Armagan et al., 2013)</ref> can be implemented by adding a sample-wise L 2 -regularizer. A multinomial generalization of this model can be found in <ref type="bibr">Polson and Scott (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We illustrate the performance of our methods on both synthetic and real datasets, compared to the deep ReLU networks without the data augmentation layer. We refer to the latter as DL in our results. We denote the data augmented gaussian regression in Algorithm 1 as DA-GR, the SVM implementation in Algorithm 2 as DA-SVM and the logistic regression in Algorithm 3 as DA-logit. For appropriate comparison, we adopt the same network structures, such as the number of layers, the number of hidden nodes, and regularizations like dropout rates, for DL and our methods. The differences between our Algorithm 3 Data Augmentation for Logistic Regression (DA-logit)</p><formula xml:id="formula_69">1: Initialize W (0) 0 , b<label>(0)</label></formula><p>0 B (0) 2: for epoch t = 1, . . . , T do 3:</p><p>Retrieve the input and output of the top layer</p><formula xml:id="formula_70">Z (t) 1 = f B (t−1) (x) ⊲ input y (t) = sigmoid(W (t−1) 0 Z (t) 1 + b (t−1) 0 ) ⊲ output 4:</formula><p>Calculate the sample-wise weights</p><formula xml:id="formula_71">z (t) = y • logit(y (t) ) ⊲ transformed responses ω (t) = 1 z (t) (sigmoid(z (t) ) − 1 2 ) ⊲ weights 5:</formula><p>Update the entire deep learner f θ with {y, x} θ</p><formula xml:id="formula_72">(t) = θ (t−1) − η∇f θ (t−1) (x | y, sample weights = ω (t) ) ⊲ SGD 6: return ŷ = 1, if f θ (T ) (x) &gt; 1 2 −1, otherwise.</formula><p>methods and DL are that (1) the top layer weights W 0 , b 0 of DL are updated via SGD optimization, while the weights W 0 , b 0 of our methods are updated via MCMC or EM;</p><p>(2) for binary classification, DA-logit and DL adopt a sigmoid activation function in the top layer to produce a binary output, while DA-SVM uses a linear function in the top layer and the augmented sampling layer transforms the continuous value into a binary output. For all experiments, the datasets are partitioned into 70% training and 30% testing randomly. For the optimization we use a modification of the SGD algorithm, the Adaptive moment estimation (Adam, <ref type="bibr" target="#b22">Kingma and Ba (2015)</ref>) algorithm. The Adam algorithm combines the estimate of the stochastic gradient with the earlier estimate of the gradient, and scales this using an estimate of the second moment of the unit-level gradient. We have also explored RMSprop <ref type="bibr" target="#b55">(Tieleman and Hinton, 2012</ref>) optimizer and we observe similar decreases in regression or classification errors.</p><p>To illustrate how the choice of J could affect the speed of convergence, we include different implementations of DA-GR and DA-SVM with J = 2, 5, 10. We have explored different sampling noise variance τ 0 , τ Z , but the choices, in general, do not affect the results significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Friedman Data</head><p>The benchmark <ref type="bibr" target="#b9">(Friedman, 1991)</ref> setup uses a regression of the form</p><formula xml:id="formula_73">y i = 10 sin(πx i1 x i2 ) + 20(x i3 − 0.5) 2 + 10x i4 + 5x i5 + ǫ i , with ǫ i ∼ N (0, σ 2 ),</formula><p>where x i = (x i1 , x i1 , . . . , x ip ) and only the first 5 covariates are predictive of y i . We run the experiments with n = 100, 1 000 and p = 10, 50, 100, 1 000 to explore the performance in both low dimensional and high dimensional scenarios. We implement both one-layer (L = 1) and two-layer (L = 2) ReLU networks with 64 hidden units in each layer. For DA-GR model, we let τ 0 = 0.1, τ z = 1. The experiments are repeated 50 times with different random seeds.</p><p>Figure <ref type="figure">2</ref> reports the three quartiles of the out-of-sample squared errors (MSEs). The top row is the performance of the one-layer networks and the bottom row is the performance of the two-layer networks. The two-layer networks perform better and converge faster. For DA-GR, when J = 5 or J = 10, it converges significantly faster and the prediction errors are also smaller. When J = 2, the performance of DA-GR is relatively similar to the deep learning model with only SGD updates. This is due to the fact that DA-GR with J-copies learns the posterior mode which is equivalent to the minimization point of the objective function, and it concentrates on the mode faster when J becomes larger.</p><p>The computation costs of DA are higher as shown in Figure <ref type="figure">3</ref>. This is not entirely unexpected since we introduce sampling steps. When J increases, the computation costs also increase slightly. Given the improvement in convergence speed and prediction errors, our data augmentation strategies are still worthwhile even with some extra computation costs. In addition, for each epoch, we can draw the sample-wise posteriors in parallel and the gap between the computation time can be further mitigated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Boston Housing Data</head><p>Another classical regression benchmark dataset is the Boston Housing dataset 1 , see, for example, <ref type="bibr" target="#b17">Hernández-Lobato and Adams (2015)</ref>. The data contains n = 506 observations with 13 features. To show the robustness of DA, we repeat the experiment 20 times with different training subsets. We adopt the ReLU networks with one hidden layer of 64 units and set the dropout rate to be 0.5. For the DA-GR model, we let τ 0 = 0.1, τ Z = 1.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the prediction errors of all methods. DA-GR with J = 10 performs significantly better than the others, in terms of both prediction errors and convergence rates. Meanwhile, DA-GR with J = 2 behaves similarly to SGD at the beginning, but it converges significantly faster than SGD after a few epochs. This again, shows that with the J-copies strategy, our method helps the optimization converge at a faster speed, and injecting the noise helps the model generalize well out-of-sample. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Wine Quality Data Set</head><p>The Wine Quality Data Set 2 contains 4 898 observations with 11 features. The output wine rating is an integer variable ranging from 0 to 10 (the observed range in the data is from 3 to 9). The frequency of each rating is reported in The most frequent ratings are 5 and 6. Since we focus on binary classification problems, we provide two types of classifications, both of which have relatively balanced categories: (1) wine with a rating of 5 or 6 (Test 1); (2) wine with a rating of ≤ 5 or &gt; 5 (Test 2). We use the same network architectures adopted in Friedman's example with τ 0 = τ z = 0.1.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> provides results for the two types of binary classifications. In both cases, DA-SVM performs better than DA-logit and DL. The advantage of large J is still significant and helps converge especially in the early phase. DA-logit outperforms DL in Test 1 when the network is shallow (L=1), while in other cases performs similarly to DL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Airbnb Data Set</head><p>The Airbnb Kaggle competition 3 provides a more challenging application with 21 3451 observations in total, and classified by destination into 12 classes: 10 most popular countries, other and no destination found (NDF), where other corresponds to any other country which is not among the top 10 and NDF corresponds to situations that no booking was made. The countries are denoted with their standard codes, as 'AU' for Australia, 'CA' for Canada, 'DE' for Germany, 'ES' for Spain, 'FR' for France, 'UK' for United Kingdom, 'IT' for Italy, 'NL' for Netherlands, 'PT' for Portugal, 'US' for United States. Table <ref type="table" target="#tab_3">3</ref> reports the percentage of each class. We follow the preprocessing steps in <ref type="bibr" target="#b49">Polson and Sokolov (2017)</ref>. The list of variables contains information from the sessions records (number of sessions, summary statistics of action types, device types and session duration), and user tables such as gender, language, affiliate provider etc. All categorical variables are converted to binary dummies, which leads to 661 features in total. For the neural network architecture, we use a two-layer ReLU network with 64 hidden units on each layer and set the dropout rate to be 0.3. For the SVM model, we let τ 0 = τ z = 0.1.   Figure <ref type="figure" target="#fig_5">6</ref> demonstrates the binary classifications for Spain versus UK and UK versus Italy. For both cases, the out-of-sample misclassification rates are not small and the fluctuations over epochs are big, suggesting that a better model structure may be needed. However, we still observe that DA-SVM with J = 5 or J = 10 has smaller classification errors over epochs and the out-of-sample errors decrease faster during earlier phase of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Summary of Experiment Results</head><p>From the above examples, we observe that DA-logit which is implemented under the EM principle does not show an obvious advantage over the vanilla neural network. It shows some improvements on the convergence speed when the network is shallow in the Wine Quality dataset case as in Figure <ref type="figure" target="#fig_4">5</ref>. This could be partially due to the fact that we did not apply regularization on the DA layer for our logit implementation. More importantly, the performance of the EM algorithm is contingent on the statistical properties of the objective function. Although the surrogate function is constructed via only the top layer whose quadratic form ensures concavity, the property of the objective function as a whole becomes complicated when the deep network architecture is more complex. Since our method also inherits the negative side of EM and MM algorithms, convergence to the global maximum is not guaranteed in the absence of concavity. However, this observation could open the possibility of future research where we can combine the EM algorithms with shape-constrained neural networks <ref type="bibr" target="#b15">(Gupta et al., 2020)</ref>.</p><p>On the contrary, the MCMC methods with the J-copies strategy significantly improve the prediction errors and convergence speed of the neural networks for both regression and classification problems. And the advantages become more outstanding when J is larger. The phenomenon suggests that the stochastic exploratory methods are preferable when the statistical property of the objective function is unknown or too complex. And the J-copies scheme largely relieves the problem of being trapped into local modes.</p><p>One concern of using MCMC methods is the extra computation costs induced by the sampling steps. In our current version where p 1 = 1, the sample-wise sampling steps can be computed in parallel. If one wishes to introduce a higher dimension latent variable Z 1 such that p 1 &gt; 1, the computation costs will increase as it may involve sampling from multivariate distributions. In that case, fast sampling implementation such as <ref type="bibr" target="#b4">Bhattacharya et al. (2016)</ref> is recommended to speed up the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Various regularization methods have been deployed in neural networks to prevent overfitting, such as early stopping, weight decay, dropout <ref type="bibr" target="#b19">(Hinton et al., 2012)</ref>, gradient noise <ref type="bibr" target="#b37">(Neelakantan et al., 2017)</ref>. Bayesian strategies tackle the regularization problem by proposing probability structures on the weights. We show that data augmentation strategies are available for many standard activation functions (ReLU, SVM, logit) used in deep learning.</p><p>Using MCMC provides a natural stochastic search mechanism that avoids procedures such as back-tracking and provides full descriptions of the objective function over the entire range Θ. Training deep neural networks thus benefits from additional hidden stochastic augmentation units (a.k.a. data augmentation). Uncertainty can be injected into the network through the probabilistic distributions on only one or two layers, permitting more variability of the network. When more data are observed, the level of uncertainty decreases as more information is learned and the network becomes more deterministic. We also exploit the duality between maximum a posteriori estimation and optimization. We provide a J-copies stacking scheme to speed up the convergence to posterior mode and avoid trapping attraction of the local modes. Concerning efficiency, DA provides a natural framework to convert the objective function into weighted least squares and is straightforward to implement with the current deep learning training process.</p><p>Our three motivational examples illustrated the advantages of data augmentation. Our work has the potential to be generalized to many other data augmentation schemes and different regularization priors. Probabilistic structures on more units and layers are also possible to allow for more uncertainty.</p><p>Our DA-DL methods enjoy the benefits of both worlds. On one hand, with the data augmentation on top, it is robust to random weight initialization. Although we still need to specify the learning rates for the deep architecture, the top layer can learn adaptively and the entire network becomes less sensitive to the choice of learning rate. On the other hand, the fast SGD updates from the deep architecture largely alleviate the computation concerns compared to a fully Bayesian hierarchical model.</p><p>There are many directions to future research, including adding more sampling layers so the model could accommodate more randomness and flexibility, and using weighted Bayesian bootstrap <ref type="bibr" target="#b39">(Newton et al., 2021)</ref> to approximate the unweighted posteriors by assigning random weight to each observation and penalty. Uncertainty quantification for prediction is also possible. Although we focus on the training aspect of deep learning, one can collect posterior draws θ (t) from the MCMC procedure when the training process converges. Using (3.2), we can construct predictive intervals and conduct inference.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: J-copies Network Architecture With the stacked system, the joint distribution of the parameters θ and the augmented hidden variables Z (S) 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>for epoch t = 1, . . . , T do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Quartiles of out-of-sample MSEs under the Friedman Setup. We explore cases where n = 1 000 and p = 10, 50, 100, 1 000. The tests are repeated 50 times. The medians of out-of-sample MSEs after training for 1 to 10 epochs are plotted with lines and the vertical bars mark the 25 % and 75% quantiles of the MSEs. DA-GR refers to DA Gaussian regression shown in Algorithm 1 and DL stands for the ReLU networks without the data-augmentation layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Out-of-sample MSEs for the Boston Housing dataset. The experiment is repeated 20 times with different training subsampling. The medians of MSEs after training for 1 to 50 epochs are provided, with the vertical bars marking the 25% and 75% quantiles of the errors. DA-GR refers to the data augmentation strategy in Algorithm 1 and DL stands for the ReLU networks without the data-augmentation layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Binary Classifications on the Wine Quality dataset. Two types of binary classifications are considered here. The experiment is repeated 20 times with different training subsampling. We compare the misclassification rates of DA-SVM in Algorithm 2 with J = 2, 5, 10, DA-logit in Algorithm 3 and the ReLU networks without the data augmentation layer (DL), after training for 1 to 10 epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Binary Classifications on the Airbnb Booking Dataset. Two types of binary classifications are considered here. The experiment is repeated 20 times with different training subsampling. We compare the misclassification rates of DA-SVM in Algorithm 2 with J = 2, 5, 10, DA-logit in Algorithm 3 and the ReLU networks without the data augmentation layer, after training for 1 to 20 epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Frequencies of Different Wine Ratings</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Percentage of Each Class (#obs = 21 3451)Our goal is to test the binary classification models on this dataset. We consider two types of binary responses, both of which have relatively balanced amounts of observations in each category.</figDesc><table><row><cell>1. Spain (1.05%) vs United Kingdom(1.09%)</cell></row><row><cell>2. United Kingdom (1.09%) vs Italy (1.33%)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis, 'Wine Quality Data Set', UCI Machine Learning Repository.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bayesian posterior sampling via stochastic gradient fisher scoring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>1591-1598. 12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning</title>
				<meeting>the 29th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generalized double Pareto shrinkage</title>
		<author>
			<persName><forename type="first">A</forename><surname>Armagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno>119. 16</idno>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On deep learning as a remedy for the curse of dimensionality in nonparametric regression</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2261" to="2285" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Merging two cultures: deep and statistical learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhadra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.11561.3</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast sampling with Gaussian scale mixture priors in high-dimensional regression</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Mallick</surname></persName>
		</author>
		<idno>asw042. 23</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stochastic gradient Hamiltonian Monte Carlo</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An adaptive empirical Bayesian method for sparse deep learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5563" to="5573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scaling up data augmentation MCMC via calibration</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Johndrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2575" to="2608" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A selective overview of deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="290" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multivariate adaptive regression splines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning deep sigmoid belief networks with data augmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Diffusions for global optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-R</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1031" to="1043" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimation and optimization of functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Markov chain Monte Carlo in practice</title>
				<imprint>
			<publisher>Chapman and Hall</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="241" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian treed Gaussian process models with an application to computer modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Gramacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K H</forename><surname>Lee</surname></persName>
		</author>
		<idno>1119-1130. 3</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">483</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="170" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multidimensional shape constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Louidor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mangylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<idno>PMLR. 23</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3918" to="3928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic backpropagation for scalable learning of Bayesian neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Computer model calibration using high-dimensional output</title>
		<author>
			<persName><forename type="first">D</forename><surname>Higdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gattiker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rightley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">482</biblScope>
			<biblScope unit="page" from="570" to="583" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580.23</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A tutorial on MM algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">MCMC maximum likelihood for latent state models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jacquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the representation of continuous functions of many variables by superposition of continuous functions of one variable and addition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Doklady Akademii Nauk</title>
				<imprint>
			<date type="published" when="1957">1957</date>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="953" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The MM algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization</title>
				<imprint>
			<publisher>Springer Science &amp; Business Media</publisher>
			<date type="published" when="2013">2013a. 2013b</date>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="185" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optimization transfer using surrogate objective functions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Why deep neural networks for function approximation?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sampling can be faster than optimization</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Flammarion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">42</biblScope>
			<biblScope unit="page" from="20881" to="20885" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Sciences</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bayesian classification of tumours by using gene expression data</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent as approximate Bayesian inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4873" to="4907" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Equation of state calculations by fast computing machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">When and why are deep networks better than shallow ones</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Poggio</surname></persName>
		</author>
		<idno>2343-2349. 2</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th Conference on Artificial Intelligence</title>
				<meeting>the 31th Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the number of linear regions of deep neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Montufar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>2924-2932. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Elliptical slice sampling</title>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackay</surname></persName>
		</author>
		<idno>541-548. 12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics</title>
				<meeting>the thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Slice sampling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="705" to="741" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Handbook of Markov Chain Monte Carlo</title>
		<idno>2. 3</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>MCMC using Hamiltonian dynamics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adding gradient noise improves learning for very deep networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A method for unconstrained convex minimization problem with the rate of convergence O (1/k 2 )</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Doklady AN USSR</title>
				<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="page" from="543" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weighted Bayesian bootstrap for scalable posterior distributions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="421" to="437" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayesian model comparison via jump diffusions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Markov Chain Monte Carlo in Practice</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">239</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A closed form solution of certain programming problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pincus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Monte Carlo Method for the approximate solution of certain types of constrained optimization problems</title>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="503" to="519" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Deep learning partial least squares</title>
		<author>
			<persName><forename type="first">N</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.14085.3</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Posterior concentration for sparse deep learning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rockova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Data augmentation for Non-Gaussian regression models using variance-mean mixtures</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Bayesian inference for logistic models using Pólya-Gamma latent variables</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Windle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">504</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Data augmentation for Support Vector Machines</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep learning: a Bayesian perspective</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sokolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Optimal scaling of discrete approximations to Langevin diffusions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="268" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Nonparametric regression using deep neural networks with ReLU activation function</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidt-Hieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neural networks and rational functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
		<ptr target="JMLR.org.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3387" to="3393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Rmsprop: Divide the gradient by a running average of its recent magnitude. coursera: Neural networks for machine learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COURSERA Neural Networks Mach. Learn</title>
		<imprint>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bayesian deep net GLM and GLMM</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><surname>M-N Sand Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="113" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Proof of the existence of analytic functions of several complex variables which are not representable by linear superpositions of continuously differentiable functions of fewer variables</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vitushkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="793" to="796" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dropout training as adaptive regularization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Uncertainty quantification for sparse deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rockova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Bayesian learning via stochastic gradient Langevin dynamics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
				<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="681" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Error bounds for approximations with deep ReLU networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yarotsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="103" to="114" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Beta-negative binomial process and Poisson factor analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hannah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno>1462- 1471. 2</idno>
	</analytic>
	<monogr>
		<title level="j">In Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
