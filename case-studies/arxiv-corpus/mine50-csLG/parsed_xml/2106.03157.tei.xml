<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervision is All You Need for Solving Rubik&apos;s Cube</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Kyo</forename><surname>Takano</surname></persName>
							<email>&lt;kyo.takano@mentalese.co&gt;.</email>
							<affiliation key="aff0">
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Supervision is All You Need for Solving Rubik&apos;s Cube</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2217FCD458233B5197E72F51F77E09AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-31T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing combinatorial search methods are often complex and require some expertise. In this work, we propose a simple and performant deep learning method, especially for goal-predefined combinatorial problems represented by Rubik's Cube. We show that, for solving such problems with high optimality, it can be sufficient to train a deep neural network on random scrambles branching from the goal state. When tested on Rubik's Cube, our method outperformed the previous state-ofthe-art method DeepCubeA in solution optimality, being 10 times more efficient in training and 2.0 times in inference. One key assumption is that, when viewed from scrambled states, random moves from the goal are biased to be optimal. We also demonstrate the proposed method on 15 Puzzle and Lights Out. F' U R2 D' B F L Figure 1. All you need for training a Deep Neural Network (DNN)</p><p>to solve Rubik's Cube. We apply a sequence of random moves to the goal state, and at each step, the DNN learns to predict the last move of the scramble based on the resulting state. We assume that, although random, the scramble moves are biased to be optimal. When solving, we can explore a solution simply by inverting moves inferred by the DNN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Combinatorial search is important both in theory and practice. One representative example is Traveling Salesman Problem, in which a salesman tries to travel through multiple cities in the shortest path possible <ref type="bibr" target="#b1">(Applegate et al., 2011;</ref><ref type="bibr">Russell &amp; Norvig, 2021)</ref>. Despite how easy it sounds, due to its combinatorial complexity, the problem is labeled NP-hard <ref type="bibr" target="#b19">(Papadimitriou &amp; Steiglitz, 1998)</ref>; as the number of cities grows, the number of possible combinations to search for explodes, easily exceeding the limits of a classical computer. In the real world, algorithms for such problems have many applications including planning, scheduling, resource allocation, route planning, and so on.</p><p>Since the naive brute-force search is impractical, past researchers have developed several search methods to address the complexity of such problems. These include exact algorithms to systematically find an optimal solution within an acceptable amount of time, and heuristic algorithms to find a good enough solution faster. Most recently, deep learning has emerged as a method for automatically training a heuristic function that is optimized for a given objective. Deep reinforcement learning, in particular, has enabled automatic training of a Deep Neural Network (DNN) as such to solve a combinatorial problem near-optimally, even without labeled data or a huge memory <ref type="bibr" target="#b16">(Mazyavkina et al., 2021;</ref><ref type="bibr" target="#b24">Vesselinova et al., 2020)</ref>. By rewarding efficient moves/actions, a DNN can learn to find increasingly better solutions.</p><p>Nevertheless, combinatorial search is still no easy task. Implementing an explicit search algorithm often requires not only expertise in the area but also commensurate computational resources and human efforts. Meanwhile, reinforcement learning may be useful for automating part of that process, but it still requires familiarity with the method itself and a lot of trial and error.</p><p>In the present study, taking Rubik's Cube as a particular example, we focus on a specific class of combinatorial problems-namely, those with a predefined goal-and propose a novel method for solving such problems. The idea is straightforward: train a DNN on mere random scrambles diverging from the goal, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>. We evaluate our method against the previous state-of-the-art deep learning method named DeepCubeA <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>, by experimenting with Rubik's Cube. arXiv:2106.03157v4 <ref type="bibr">[cs.</ref>LG] 24 Oct 2022 2 Related Work Rubik's Cube and 15 Puzzle are typical examples of goalpredefined combinatorial problems. To generalize, the task in such problems is to find a sequence of moves that reaches the predefined goal from a given state. For individual descriptions, see Experiment for Rubik's Cube and Appendix B for 15 Puzzle. Henceforth, we consider any of such problems as a pathfinding task on an implicit graph. Each node in the graph represents a unique state, and edges indicate moves to its adjacent nodes with equal probability.</p><p>Among various methods for solving those problems, we pay particular attention to two leading methods with highly optimality. First, Iterative Deepening A* (IDA*), a complete search algorithm that is guaranteed to find an optimal solution in a reasonable time <ref type="bibr" target="#b12">(Korf, 1985;</ref><ref type="bibr" target="#b13">1997)</ref>. Second, DeepCubeA, a near-optimal method that leverages deep reinforcement learning <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>. Both are forward search methods to find the goal by expanding nodes from a given state, in order of their estimated distances. <ref type="bibr" target="#b12">Korf (1985)</ref> developed IDA* as the first admissible search algorithm to solve 15 Puzzle optimally. IDA* is a combination of two algorithms: Iterative Deepening Depth-First Search (IDDFS) and A* search <ref type="bibr" target="#b7">(Hart et al., 1968)</ref>. IDDFS is a depth-first search that iteratively deepens until a solution is found, and like a breadth-first search, it is guaranteed to find optimal solutions. However, if a state space is too large, the search algorithm becomes infeasible to run within a realistic time frame. To enable IDDFS in such a vast state space, <ref type="bibr" target="#b12">Korf (1985)</ref> incorporated the idea of A* search, which expands nodes in order of their estimated total distance formulated as</p><formula xml:id="formula_0">f (x) = g(x) + h(x)<label>(1)</label></formula><p>where x is an expanded node, g(x) is the depth from the starting node, and h(x) is the lower bound of the remaining distance to the goal informed by theory heuristic. Using the same formula, IDA* iteratively increases the threshold for f (x) instead of depth, greatly reducing the number of expanded nodes without compromising the optimality. Later, Korf extended IDA* as the first optimal solver against Rubik's Cube, incorporating a pattern database that precomputes lower bounds of distances corresponding to particular patterns (1997). Since then, more efficient implementations have followed this approach <ref type="bibr" target="#b14">(Korf, 2008;</ref><ref type="bibr" target="#b2">Arfaee et al., 2011;</ref><ref type="bibr" target="#b22">Rokicki et al., 2014)</ref>. Even so, they remain problem-specific and require domain knowledge of group theory and search.</p><p>DeepCube was the first to formulate Rubik's Cube as a reinforcement learning task and to solve it successfully <ref type="bibr" target="#b17">(McAleer et al., 2018)</ref>, which soon evolved as DeepCubeA with significant performance improvement <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>. DeepCubeA trains a DNN in place of h(x) in Eq. 1 to estimate the distance from a given state to the predefined goal. By relatively discounting g(x) like weighted A* <ref type="bibr" target="#b20">(Pohl, 1970;</ref><ref type="bibr" target="#b5">Ebendt &amp; Drechsler, 2009)</ref> and expanding a certain number of nodes per iteration, DeepCubeA then searches for a solution so that the approximate lower bound of total distance f (x) is as small as possible. DeepCubeA is also shown applicable to similar problems like 15 Puzzle and its variants, as well as Lights Out and Sokoban <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>.</p><p>Unlike IDA*, which relies on group theory, DeepCubeA automatically trains a DNN as a function approximator to estimate distances. The use of DNN is well suited for this task for a few reasons. First, it can learn complex patterns in data using a fixed number of parameters. Next, it also generalizes well to cases not seen during training. These features are especially convenient when a state space is too large to exhaustively traverse and store in memory. Still, however, deep reinforcement learning is inherently complex and unstable, requiring careful design and hyperparameter tuning. In DeepCubeA, <ref type="bibr" target="#b0">Agostinelli et al. (2019)</ref> had to check regularly that the training loss falls below a certain threshold before saving the DNN, to avoid local optima and performance degradation.</p><p>While both methods are powerful, they still require complex implementation with specialized knowledge. Instead of estimating the distance to guide a search, we propose a more direct method to infer the path itself. Our method trains a DNN on backward scrambles from the goal, treating them as inverse solutions from the resulting states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>A goal-predefined combinatorial problem can also be regarded as the task of tracing a scramble back to the goal.</p><p>Although the actual scramble is unobservable, it may still be possible to infer a plausible scramble as leading up to a given state. Desirably, such a scramble should be as short as possible. To this end, we propose a simple deep learning method to infer a scramble as a backward solution, one move at a time from a given state.</p><p>When training a DNN, our method sequentially scrambles the target problem from its goal state with random moves. At each step of the scramble, the DNN learns to predict the last move of the scramble up to that point, based on the resulting state. Algorithm 1 provides the pseudocode of the training process, and Figure <ref type="figure" target="#fig_0">1</ref> captures an example data point on Rubik's Cube. At inference, we search for a solution as a path back to the goal by repeatedly inverting moves that seemingly caused current states. The core assumption is that the distribution of random scramble moves to be learned by a DNN is biased toward optimality, which we discuss in more detail below. The miniature example in Figure <ref type="figure">2</ref> illustrates how our method would work during both training and inference. </p><formula xml:id="formula_1">f θ : Trained DNN while not converged do T ← ∅ for b = 1 to B do S ← G for n = 1 to N do m ← random(M) S ← S • m T ← T ∪ {(S, m)} Update f θ : S → m using T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Assumptions</head><p>Our method has two assumptions, which are not strictly necessary but are preferably satisfied by the target problem. Assumption 1 concerns the performance limit of the resulting DNN, while Assumption 2 affects its learning efficiency.</p><p>Assumption 1. When random paths connect two nodes, more optimal moves are more often the first move.</p><p>Here, we base the optimality of a move on that of paths starting with it. With respect to the optimality of paths, obviously, the shorter a path between two nodes, the more likely it is to occur as a sequence of random moves. At some nodes, however, many suboptimal paths may stack up on a particular edge, causing the corresponding move to be sampled more often than the optimal alternative(s). Because we want to predict one move at a time, we need to discuss the optimality of moves at the node level.</p><p>Accordingly, we formulate the statistical condition under which Assumption 1 is true for a given problem. Suppose that we have an unknown path connecting two nodes, where each possible move in M has an equal probability at all nodes. Let p N,a be the probability of a particular move a ∈ M being the first move of potential paths consisting of N moves or more,</p><formula xml:id="formula_2">p N,a = kmax k=N C k|a |M| k (2)</formula><p>where k is the move count to the target node, k max is the maximum move count from the goal, |M| is the number of possible moves at each node, and C k|a is the number of k-move paths starting with the move a. Likewise, let b ∈ M be an alternative to a that results in</p><formula xml:id="formula_3">c b a S G c' b' a' S G Figure 2.</formula><p>A miniature instance of combinatorial search with a predefined goal. When random paths connect two nodes/states, the distribution of moves can be biased toward optimality. Lef t: Suppose that during training, random moves {a, b, c} can occur at each node with an equal probability of 1/3 and a combination of these moves generates an unknown path between nodes G (Goal) and S (Scramble). Adding up the probabilities of all the possible paths at each edge, we find that moves appearing on shorter paths are more likely to comprise the path of interest. A DNN can internalize this distribution by learning the state-to-move mapping, assuming that every state has a unique state pattern. Right: At inference time, the DNN can find the optimal path from S to G by traversing back through the learned distribution, where optimal moves are more frequent than suboptimal ones. In this instance, b would be predicted as optimal over the other inverse moves a and c , both at S and its subsequent node.</p><p>paths consisting of at fewest N + 1 moves, Assumption 1 can be formulated as</p><formula xml:id="formula_4">p N +1,b ≤ p N,a . Provided that p N,a = kmax N +1 (C k|a /|M| k ) + (C N |a /|M| N ), it is equiva- lent to kmax k=N +1 C k|b |M| k ≤ kmax k=N +1 C k|a |M| k + C N |a |M| N (3)</formula><p>At this point, note that Eq. 3 cannot be proven always true. This is simply because there can be paths in which moves violate this, and also because that depends on the implicit graph of the problem at hand. Both C k|a and C k|b can be determined only through actual computation on specific paths of a specific problem, so the terms do not necessarily equal when paths start with different moves. However, we can still assume the rough equivalence of these terms and thus the tendency that Eq. 3 stands. For it to be false, there must be sufficiently more paths starting with the suboptimal move b than a to cumulatively cancel the remaining term C N |a /|M| N . Thus, when sampling a random move, we assume that it tends to be optimal as comprising a path to the resulting state.</p><p>For the performance of the trained DNN, the target problem should preferably satisfy Assumption 1 as much as possible. In Appendix A, we test Assumption 1 on 2×2×2 Rubik's Cube by exhausting all possible scramble paths and show that more optimal moves are sampled more often.</p><p>Assumption 2. God's Number, the smallest number of moves sufficient to solve any state, or its estimate is known.</p><p>The training data is generated by scrambling the problem from 1 to N times from its goal state. Let N G be God's Number for a given problem. If N &lt; N G , then the trained DNN would not generalize well to states of higher complexities that take N + 1 moves or more, leading to poor performance at inference. Conversely, overestimating N G may result in redundant moves being applied to the highest complexity states, likely adding unnecessary noise to the training data.</p><p>If this number is unknown or not even estimated, it may help to iteratively increase the scramble length as long as the DNN can learn to make predictions for maximally scrambled cases better than chance. Under Assumption 1, such predictability suggests N ≈ N G , where N is insufficient or just sufficient to fully scramble the problem within the diameter of its state space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>To evaluate our method against DeepCubeA <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>, we employ the same problem setting and representation, dataset, and model architecture. After solving test cases, we compare our result to the published result of DeepCubeA and its update provided on GitHub 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Rubik's Cube</head><p>Rubik's Cube is a cubic puzzle with 6 faces each having 9 color stickers. The goal is to move the stickers by rotating 6 faces so that each has stickers of only a single color. Including the goal state, the puzzle can have roughly 4.3 × 10 19 different states. As a combinatorial problem, solving the puzzle optimally is proven to be NP-complete <ref type="bibr" target="#b4">(Demaine et al., 2018)</ref>.</p><p>We represent Rubik's Cube as a 324-D vector by assigning an index to every color at every sticker location (6 colors ×54 sticker positions). Also, to manipulate states, we use the quarter-turn metric (a 90°turn of a face counts as one move, whereas a 180°turn counts as two), meaning 12 possible moves for any state. In the notation, U, D, L, R, B, and F respectively denote a 90°clockwise turn on Up, Down, Left, Right, Back, and Front faces on the puzzle; if followed by a prime ('), counterclockwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dataset</head><p>We use the DeepCubeA dataset released on Code Ocean 2 . The dataset contains 1, 000 test cases of Rubik's Cube, each scrambled 1, 000 to 10, 000 moves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model</head><p>The DNN first has two linear layers (5000-D and 1000-D), followed by four residual blocks <ref type="bibr" target="#b8">(He et al., 2016)</ref> each containing two 1000-D linear layers. To this point, all linear layers are followed by rectified linear unit activation <ref type="bibr" target="#b18">(Nair &amp; Hinton, 2010;</ref><ref type="bibr" target="#b6">Glorot et al., 2011)</ref> and batch normalization <ref type="bibr" target="#b9">(Ioffe &amp; Szegedy, 2015)</ref>. Finally, the model has a 12-D linear layer to return logits as prediction output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training</head><p>Following Algorithm 1, the DNN is self-supervised to predict the last moves of random scrambles from corresponding states. For each batch, we compute the categorical crossentropy loss between actual and predicted last moves by converting logits into probability distributions with the softmax function. To update the DNN parameters with the loss, we use Adam optimizer <ref type="bibr" target="#b11">(Kingma &amp; Ba, 2014)</ref> with an initial learning rate of 10 −3 . In this experiment, the maximum scramble length is set to 26, which is God's Number for Rubik's Cube in the quarter-turn metric <ref type="bibr" target="#b15">(Kunkle &amp; Cooperman, 2007)</ref>. Also, when generating random scrambles, we exclude obviously redundant/self-canceling permutations like R following R'. In total, we train the DNN for 1, 000, 000 steps with a fixed batch size of 26, 000 (26 moves per scramble ×1, 000 scrambles per batch), which is equivalent to 1 billion solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Inference</head><p>We use beam search, a simple heuristic search algorithm, to solve Rubik's Cube with the trained DNN. Although beam search is not guaranteed to reach the goal, it can efficiently search for solutions by pruning unpromising candidates. Starting from depth 1 with a given scrambled state, at every depth i, the DNN predicts the next moves for every candidate state. Let k be the beam width, we pass at most k candidate paths and corresponding states to the next depth i + 1, sorted by their predicted values. The search continues until any of the expanded candidate states is solved, at which point the search depth matches the solution length.</p><p>In this experiment, we sort those candidates by their output logits in order to prioritize higher-entropy predictions that are plausibly more confident. Also, we scale up the beam width in power of 2 from 2 0 to 2 18 , thereby examining the trade-off between the number of nodes and optimality, as well as whether our method expands more nodes than DeepCubeA to reach the same level of optimality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>With beam widths of 2 8 and above, our method successfully solved all the test cases. Figure <ref type="figure" target="#fig_1">3</ref> shows how our result com- Since the calculation time strongly depends on the environment (e.g., number and performance of GPUs, distributed processing, etc.), we normalize the temporal performance of our and DeepCubeA's paper result so that the average per-node time matches that of DeepCubeA's GitHub result. In Figure <ref type="figure" target="#fig_2">4</ref>, we plot solution length versus inference time for all the test cases.</p><p>The comparison of the different methods indicates the overall advantage of our method over DeepCubeA, albeit not as powerful as the optimal solver backed by 182 GB of memory. First, we observe that our solutions were on average shorter than DeepCubeA. When optimal solutions averaged 20.64 moves in length, our solutions averaged 21.27 moves long. Additionally, among our 1, 000 solutions, 696 were optimal.</p><p>In both metrics of optimality, our method outperformed DeepCubeA, solutions of which averaged 21.35 moves and were 65% optimal. Second, our solutions were also more efficient. For training, the DNN learned the equivalent of only 1 billion examples, while DeepCubeA did so on 10 billion examples <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>. When searching for solutions, DeepCubeA expanded an average of 8.19 × 10 6 nodes per solution, whereas ours expanded only 4.19 × 10 6 nodes. These show that our method reached higher optimality than DeepCubeA, also with higher efficiencies in both training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Focusing on goal-predefined combinatorial problems, we proposed a novel deep learning method to directly infer the solution path. Rather than guiding a search algorithm with distance estimation like IDA* and DeepCubeA, our method directly infers a sequence of moves leading to the goal by training a DNN merely on random scrambles. Evaluated on solving Rubik's Cube, our method produced solutions with high optimality and efficiency, outperforming DeepCubeA on both. The result also exhibits a smooth trade-off between compute and optimality (Figure <ref type="figure" target="#fig_1">3</ref>) and a stable temporal performance (Figure <ref type="figure" target="#fig_2">4</ref>). These results suggest that our training algorithm provides stable and effective supervision signals, indirectly supporting Assumption 1 for Rubik's Cube.</p><p>Note that, as a fundamental limitation, our method requires that the target problem has a predefined goal. For this reason, the proposed method would not directly apply to combinatorial optimization problems like Traveling Salesman Problem, which we mentioned in Introduction, as the task is to find the optimal combinatorial state itself. For this kind of problem, classic heuristic/approximation algorithms would remain the best approach <ref type="bibr" target="#b21">(Rego et al., 2011;</ref><ref type="bibr" target="#b23">van Bevern &amp; Slugina, 2020)</ref>, though there also are deep learning methods leveraging reinforcement learning and graph neural networks <ref type="bibr" target="#b16">(Mazyavkina et al., 2021;</ref><ref type="bibr" target="#b10">Joshi et al., 2022)</ref>.</p><p>Besides Assumption 1, because our method generates the training data backward from the goal, it also implicitly assumes the reversibility of moves. In other words, the implicit graph of the target problem must have bidirectional edges. If scrambles/solutions of the target problem do not follow such a reversible process, our method will not work; for example, if state transitions are non-deterministic and subject to randomness.</p><p>Nevertheless, under Assumption 1, our method is applicable to similar goal-predefined problems, such as 15 Puzzle and its variants, Lights Out, Sokoban, etc., which are also solved by DeepCubeA <ref type="bibr" target="#b0">(Agostinelli et al., 2019)</ref>. In Appendices, we provide example applications of our method on 15 Puzzle (Appendix B) and on Lights Out (Appendix C) using the same DeepCubeA dataset. Notably, our method was able to solve all of 500 test cases of 7 × 7 Lights Out optimally, expanding only the necessary nodes using the greedy search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a simple yet powerful deep learning method to solve a goal-predefined combinatorial problem like Rubik's Cube. Through the experiment, we demonstrated that a DNN can learn to solve the target problem simply from random scrambles. Despite the training data being random, interestingly, the resulting solutions also exhibited a high level of optimality and efficiency. In future research, we seek to extend the proposed method with fewer constraints, e.g., to problems with a weighted graph and/or continuous space, etc. We hope that our work provides useful perspectives on combinatorial search as well as adjacent machine learning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code &amp; Data</head><p>We release our code, models, and experimental results at github.com/kyo-takano/EfficientCube. A Assumption 1 on 2×2×2 Rubik's Cube</p><p>We test Assumption 1 on the 2×2×2 version of Rubik's Cube, which has a relatively small state space (3, 674, 160 cases). For this problem, God's Number is known to be 11 moves in the half-turn metric, which counts both 90°and 180°turns as one move. With one piece fixed, any state has three faces to rotate and 9 possible moves. Accordingly, by excluding self-canceling moves (e.g., R2 after R') to reduce the number of permutations, we were able to compute all the possible scramble paths from the goal.</p><p>We aggregated frequency ranks of optimal moves (i.e., the first move of optimal paths) to all the possible states. Since some states can have more than one optimal move, we counted for both highest-and lowest-rank optimal moves. Figure <ref type="figure" target="#fig_3">5</ref> summarizes the result. About 97.7% of the states (3, 591, 248 cases) have one or more optimal moves being the most frequent of all the possible moves. We also found a fairly strong bias in the same direction even for the least frequent optimal moves. This observation is largely consistent with Assumption 1, providing partial support for our proposed method to work on the same class of problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B 15 Puzzle</head><p>We additionally demonstrate our method on 15 Puzzle. 15 Puzzle is a sliding puzzle consisting of 15 numbered tiles and 1 empty slot on a 4×4 board. The goal is to align the tiles in numerical order by swapping the empty slot with its neighboring tiles multiple times. Including the goal, there are approximately 1.0 × 10 13 possible states, and God's Number is 80 moves <ref type="bibr" target="#b3">(Brüngger et al., 1999;</ref><ref type="bibr" target="#b14">Korf, 2008)</ref>.</p><p>We trained a DNN of the same architecture on the equivalent of 100, 000, 000 solutions (100, 000 batches ×1, 000 scrambles per batch) with the scramble length of  dundant moves like → after ←. On the other hand, unlike with Rubik's Cube, we sorted candidate moves by their probabilities computed through the softmax function.</p><p>Table <ref type="table" target="#tab_2">2</ref> summarizes the comparison of different models. Figure <ref type="figure" target="#fig_4">6</ref> shows the trade-off between solution length and number of nodes. Using the beam search, the trained DNN successfully solved all the cases with all beam widths from 2 0 to 2 18 . As depicted in Figure <ref type="figure" target="#fig_4">6</ref>, the resulting solutions are more optimal with increasing beam widths on average in a similar way as for Rubik's Cube. However, contrary to DeepCubeA, our method could not always produce optimal solutions, even with more nodes expanded. This comparative lack of success may suggest the lower degree to which 15 Puzzle satisfies Assumption 1, possibly because the number of possible moves depends on the location of the empty slot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C 7×7 Lights Out</head><p>Lights Out is a combinatorial puzzle consisting of multiple ON/OFF binary lights on a grid. In the 7×7 version, 49 lights are arranged in a square. Each light toggles the state of itself and its adjacent lights, and the goal is to turn all the lights off given a random state. As a goal-predefined combinatorial problem, it possesses a more relaxed setting  due to the following characteristics. First, because every move is binary, using the same move twice is clearly redundant. Also, the puzzle is commutative, meaning that the order of moves is irrelevant to the resulting state. All moves comprising a given scramble sequence can come to the end of that sequence with equal probability. Hence, for a DNN, the problem is a simple pattern recognition task to predict the combination of moves, rather than specifically the last one in the permutation. According to <ref type="bibr" target="#b0">Agostinelli et al. (2019)</ref>, a solution is optimal when it has no duplicate moves.</p><p>Since God's Number is unknown for this problem, we set the training scramble length to 49 moves, the upper bound for when you need to toggle every button. As a scramble progressed, we trained a DNN of the same architecture to predict all the moves applied to the problem up to that point. In total, the DNN learned the equivalent of 10, 000, 000 scrambles (10, 000 batches × 1, 000 scrambles/batch).</p><p>Tested on the DeepCubeA dataset containing 500 cases, our method successfully solved all of them optimally with greedy search, which expands the most promising node only at every step. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1</head><label>1</label><figDesc>The proposed algorithm to train a DNN using random scrambles. Input: G: Goal state M: Set of moves B : Number of scrambles in a batch N : Number of moves in a scramble f θ : DNN parameterized by θ Output:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Solution length versus number of nodes on solving Rubik's Cube, by different methods. Each dot represents the number of moves in a solution and the number of nodes visited during a search, and we plot cross markers at their mean coordinates. Frequency plots are presented separately for each axis. The pink line indicates the trajectory of our results scaling up along the beam widths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Calculation time versus solution length by three methods. The left scatterplot shows the actual time taken, and the right one shows the time normalized by per-node computation time. Similar to Figure 3, the mean coordinates are marked by a cross for all results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Frequency distribution of nodes by highest/lowest frequency rank of optimal moves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Solution length versus number of nodes on solving 15 Puzzle, by different methods. Each dot represents the number of moves in a solution and the number of nodes visited during a search, and we plot cross markers at their mean coordinates. Frequency plots are presented separately for each axis. The pink line indicates the trajectory of our results scaling up along the beam widths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performances of different methods on solving Rubik's Cube. Mean values are reported for solution length, number of nodes, and time taken to solve per test scramble. Optimal (%) indicates the percentage of optimal solutions. For our and DeepCubeA's paper results, we report the calculation time normalized to the per-node temporal performance of DeepCubeA (GitHub), followed by actual time taken in parentheses.</figDesc><table><row><cell>Method</cell><cell cols="2">Solution length Optimal (%)</cell><cell>No. of nodes</cell><cell>Time taken (s)</cell></row><row><cell>Optimal solver</cell><cell>20.64</cell><cell>100.0</cell><cell>2.05 × 10 6</cell><cell>2.20</cell></row><row><cell>Ours</cell><cell>21.27</cell><cell>69.6</cell><cell>4.19 × 10 6</cell><cell>38.73 (369.40)</cell></row><row><cell>DeepCubeA (GitHub)</cell><cell>21.35</cell><cell>65.0</cell><cell>8.19 × 10 6</cell><cell>75.61</cell></row><row><cell>DeepCubeA (Paper)</cell><cell>21.50</cell><cell>60.3</cell><cell>6.62 × 10 6</cell><cell>61.14 (24.22)</cell></row><row><cell cols="2">pares with that of DeepCubeA in terms of solution length</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">and number of nodes visited. Just for reference, we also</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">include the performance of an optimal solver by Agostinelli</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">et al. (2019), which extended Rokicki et al. (2014)'s IDA*</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">implementation further using 182 GB of memory. Below,</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">we report our result obtained with the beam width of 2 18 .</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Table 1 compares the test performances of the different</cell><cell></cell><cell></cell><cell></cell></row><row><cell>methods.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Performances of different methods on solving 15 Puzzle. Mean values are reported for solution length, number of nodes, and time taken to solve per test scramble. Optimal (%) indicates the percentage of optimal solutions. For our and DeepCubeA's paper results, we report the calculation time normalized to the per-node temporal performance of DeepCubeA (GitHub), followed by actual time taken in parentheses.</figDesc><table><row><cell>Method</cell><cell cols="2">Solution length Optimal (%)</cell><cell>No. of nodes</cell><cell>Time taken (s)</cell></row><row><cell>Optimal solver</cell><cell>52.02</cell><cell>100.0</cell><cell>3.22 × 10 4</cell><cell>0.0019</cell></row><row><cell>Ours</cell><cell>52.33</cell><cell>84.8</cell><cell>9.81 × 10 6</cell><cell>26.42 (626.13)</cell></row><row><cell>DeepCubeA (GitHub)</cell><cell>52.02</cell><cell>100.0</cell><cell>3.28 × 10 6</cell><cell>8.82</cell></row><row><cell>DeepCubeA (Paper)</cell><cell>52.03</cell><cell>99.4</cell><cell>3.85 × 10 6</cell><cell>10.37 (10.28)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Performances of different methods on solving Lights Out. Because both DeepCubeA and our method achieved the optimal solutions across all the cases, we only report mean values of the number of nodes expanded and the actual time taken to solve. We omit DeepCubeA's paper result here because both solution length and number of nodes are consistent with those of GitHub result.</figDesc><table><row><cell>Method</cell><cell cols="2">No. of nodes Time taken (s)</cell></row><row><cell>Ours</cell><cell>24.26</cell><cell>0.053</cell></row><row><cell>DeepCubeA</cell><cell>1.14 × 10 6</cell><cell>5.90</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table 3 compares both our and DeepCubeA results. Although DeepCubeA also solved all the test cases optimally, our method significantly outperformed it in terms of search efficiency, expanding nodes straight through optimal solutions. Note, however, that this flawless result does not indicate the completeness of the trained DNN as a search heuristic.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">github.com/forestagostinelli/DeepCubeA/ 2 doi.org/10.24433/CO.4958495.v1   </note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Solving the Rubik&apos;s Cube with deep reinforcement learning and search</title>
		<author>
			<persName><forename type="first">F</forename><surname>Agostinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shmakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="356" to="363" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The traveling salesman problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Applegate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bixby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chvátal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Traveling Salesman Problem</title>
				<imprint>
			<publisher>Princeton university press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning heuristic functions for large state spaces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Arfaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Holte</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2011.08.001</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2011.08.001" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2075" to="2098" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The parallel search bench ZRAM and its applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brüngger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marzetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nievergelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="45" to="63" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Solving the Rubik&apos;s Cube optimally is NP-complete</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eisenstat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudoy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06708v2</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weighted a* search-unifying view and application</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ebendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Drechsler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1310" to="1342" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v15/glorot11a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Dunson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dudík</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Fort Lauderdale, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04">Apr 2011</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="11" to="13" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A formal basis for the heuristic determination of minimum cost paths</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems Science and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="107" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning the travelling salesperson problem requires rethinking generalization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cappart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-M</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Laurent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Constraints</title>
		<imprint>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Depth-first iterative deepening: An optimal admissible tree search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Finding optimal solutions to Rubik&apos;s Cube using pattern databases</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="700" to="705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Linear-time disk-based implicit graph search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Twenty-six moves suffice for Rubik&apos;s Cube</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kunkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cooperman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 International Symposium on Symbolic and Algebraic Computation</title>
				<meeting>the 2007 International Symposium on Symbolic and Algebraic Computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="235" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reinforcement learning for combinatorial optimization: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mazyavkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sviridov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burnaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Solving the Rubik&apos;s Cube with approximate policy iteration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Agostinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shmakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Combinatorial Optimization: Algorithms and Complexity. Courier Corporation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steiglitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Heuristic search viewed as path finding in a graph</title>
		<author>
			<persName><forename type="first">I</forename><surname>Pohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="193" to="204" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Traveling salesman problem heuristics: Leading methods, implementations and latest advances</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gamboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osterman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">211</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="427" to="441" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The diameter of the Rubik&apos;s Cube group is twenty</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rokicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kociemba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dethridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="645" to="670" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A historical note on the 3/2-approximation algorithm for the metric traveling salesman problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Bevern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Slugina</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.hm.2020.04</idno>
		<ptr target="https://doi.org/10.1016/j.hm.2020.04" />
	</analytic>
	<monogr>
		<title level="j">Historia Mathematica</title>
		<idno type="ISSN">0315- 0860</idno>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="118" to="127" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Artificial Intelligence: A Modern Approach. 4th. Pearson, 2021</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning combinatorial optimization on graphs: A survey with applications to networking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vesselinova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steinert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Perez-Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boman</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3004964</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="120388" to="120416" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
