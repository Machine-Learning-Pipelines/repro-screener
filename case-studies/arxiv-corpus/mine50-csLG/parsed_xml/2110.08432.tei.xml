<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta-Learning with Adjoint Methods</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shibo</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Akil</forename><surname>Narayan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics, Scientific Computing and Imaging Institute</orgName>
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Kirby</surname></persName>
							<email>kirby@cs.utah.edu</email>
							<affiliation key="aff3">
								<orgName type="department">School of Computing, Scientific Computing and Imaging Institute</orgName>
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shandian</forename><surname>Zhe</surname></persName>
							<email>zhe@cs.utah.edu</email>
							<affiliation key="aff4">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Meta-Learning with Adjoint Methods</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B853AB4F59561DD0BBBDC7D49A9570D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-10-31T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model Agnostic Meta Learning (MAML) is widely used to find a good initialization for a family of tasks. Despite its success, a critical challenge in MAML is to calculate the gradient w.r.t. the initialization of a long training trajectory for the sampled tasks, because the computation graph can rapidly explode and the computational cost is very expensive. To address this problem, we propose Adjoint MAML (A-MAML). We view gradient descent in the inner optimization as the evolution of an Ordinary Differential Equation (ODE). To efficiently compute the gradient of the validation loss w.r.t. the initialization, we use the adjoint method to construct a companion, backward ODE. To obtain the gradient w.r.t. the initialization, we only need to run the standard ODE solver twice -one is forward in time that evolves a long trajectory of gradient flow for the sampled task; the other is backward and solves the adjoint ODE. We need not create or expand any intermediate computational graphs, adopt aggressive approximations, or impose proximal regularizers in the training loss. Our approach is cheap, accurate, and adaptable to different trajectory lengths. We demonstrate the advantage of our approach in both synthetic and real-world meta-learning tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Meta-learning paradigms <ref type="bibr" target="#b40">(Schmidhuber, 1987;</ref><ref type="bibr" target="#b44">Thrun and Pratt, 2012)</ref> intend to develop methods that can quickly adapt a learning model to new tasks or environments, like human learning. A prominent example is the recent model-agnostic meta-learning (MAML) algorithm <ref type="bibr" target="#b14">(Finn et al., 2017)</ref>, which is particularly successful in learning the model initialization for a family of tasks. MAML is a bi-level optimization approach. The inner level starts from the initialization, and optimizes the training loss of the sampled tasks via gradient descent. At the trained model parameters, the outer-level uses 1 arXiv:2110.08432v2 <ref type="bibr">[cs.</ref>LG] 23 Oct 2022 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u N Y I f N 5 J T k h C b o e a p B t P i K c k G y E = " &gt; A A A B + H i c b V D L S s N A F J 3 U V 6 2 P V l 2 6 C R b B V U l E 1 G X R j c s K 9 g F N K J P p T T t 0 M g k z N 0 I N / R I 3 L h R x 6 6 e 4 8 2 + c t F l o 6 4 G B w z n 3 c s + c I B F c o + N 8 W 6 W 1 9 Y 3 N r f J 2 Z W d 3 b 7 9 a O z j s 6 D h V D N o s F r H q B V S D 4 B L a y F F A L 1 F A o 0 B A N 5 j c 5 n 7 3 E Z T m s X z A a Q J + R E e S h 5 x R N N K g V v U i i u M g z D w c A 9 L Z o F Z 3 G s 4 c 9 i p x C 1 I n B V q D 2 p c 3 j F k a g U Q m q N Z 9 1 0 n Q z 6 h C z g T M K l 6 q I a F s Q k f Q N 1 T S C L S f z Y P P 7 F O j D O 0 w V u Z J t O f q 7 4 2 M R l p P o 8 B M 5 j H 1 s p e L / 3 n 9 F M N r P + M y S R E k W x w K U 2 F j b O c t 2 E O u g K G Y G k K Z 4 i a r z c Z U U Y a m q 4 o p w V 3 + 8 i r p n D f c y 8 b F / U W 9 e V P U U S b H 5 I S c E Z d c k S a 5 I y 3 S J o y k 5 J m 8 k j f r y X q x 3 q 2 P x W j J K n a O y B 9 Y n z 9 I a p O C &lt; / l a t e x i t &gt; ✓ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P 8 q O C o P p i G d N i + E q 3 Y D I a r K c W 9 g = " &gt; A A A B + H i c b V D L S s N A F L 2 p r 1 o f j b p 0 M 1 i E u i m J F H V Z d O O y Q l / Q h j K Z T t q h k 0 m Y m Q g 1 9 E v c u F D E r Z / i z r 9 x 0 m a h r Q c G D u f c y z 1 z / J g z p R 3 n 2 y p s b G 5 t 7 x R 3 S 3 v 7 B 4 d l + + i 4 o 6 J E E t o m E Y 9 k z 8 e K c i Z o W z P N a S + W F I c + p 1 1 / e p f 5 3 U c q F Y t E S 8 9 i 6 o V 4 L F j A C N Z G G t r l Q Y j 1 x A / S Z D 5 0 q 6 2 L o V 1 x a s 4 C a J 2 4 O a l A j u b Q / h q M I p K E V G j C s V J 9 1 4 m 1 l 2 K p G e F 0 X h o k i s a Y T P G Y 9 g 0 V O K T K S x f B 5 + j c K C M U R N I 8 o d F C / b 2 R 4 l C p W e i b y S y m W v U y 8 T + v n + j g x k u Z i B N N B V k e C h K O d I S y F t C I S U o 0 n x m C i W Q m K y I T L D H R p q u S K c F d / f I 6 6 V z W 3 K t a / a F e a d z m d R T h F M 6 g C i 5 c Q w P u o Q l t I J D A M 7 z C m / V k v V j v 1 s d y t G D l O y f w B 9 b n D x i Z k r o = &lt; / l a t e x i t &gt; u 1 (T )</p><p>Adjoint ODE Forward ODE Forward ODE Adjoint ODE &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K K J n 2 1 2 u L 8 J J p D L 2 C p J g L e j d c V 8 = " &gt; A A A C L n i c b V B L S w M x E M 7 W V 6 2 v V Y 9 e g k V o L 2 V X i n o s i i C e K v Q F 3 V K y a b Y N z T 5 I Z o W y 7 C / y 4 l / R g 6 A i X v 0 Z Z t u C 2 j o Q 8 s 3 3 z T A z n x s J r s C y X o 3 c y u r a + k Z + s 7 C 1 v b O 7 Z + 4 f t F Q Y S 8 q a N B S h 7 L h E M c E D 1 g Q O g n U i y Y j v C t Z 2 x 1 e Z 3 r 5 n U v E w a M A k Y j 2 f D A P u c U p A U 3 3 z 2 v E k o Y k T E Q m c C H z b t 0 u O T 2 D k e k m c 6 q R R L q c / c u K 4 o R i o i a 8 / 7 M C I A U n T Q q F v F q 2 K N Q 2 8 D O w 5 K K J 5 1 P v m s z M I a e y z A K g g S n V t K 4 J e k k 2 h g q U F J 1 Y s I n R M h q y r Y U B 8 p n r J 9 N w U n 2 h m g L 1 Q 6 h c A n r K / O x L i q 2 x F X Z l d o h a 1 j P x P 6 8 b g</p><formula xml:id="formula_0">X f Q S H k Q x s I D O B n m x w B D i z D s 8 4 J J R E B M N C J V c 7 4 r p i G j / Q D u c m W A v n r w M W q c V + 6 x S v a s W a 5 d z O / L o C B 2 j E r L R O a q h G 1 R H T U T R A 3 p C b + j d e D R e j A / j c 1 a a M + Y 9 h + h P G F / f r n a o 7 A = = &lt; / l a t e x i t &gt; @J 1 (u 1 (T )) @✓ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p e o v n F 6 H R 7 t l M i 0 o c l k z I j D a M B U = " &gt; A A A C 1 X i c j V J N T x s x E P V u a U v T r 7 Q 9 c r G I I s G h 0 S 5 C L Z d K K F y q n q A i B C l O V 1 6 v l 1 h 4 7 Z U 9 S x t Z e w C h X v v f e u M / 9 E f g T S I V S A 6 M Z P n 5 P Y / n e e y 0 l M J C F N 0 E 4 Z O 1 p 8 + e r 7 9 o v X z 1 + s 3 b 9 r v 3 J 1 Z X h v E B 0 1 K b 0 5 R a L o X i A x A g + W l p O C 1 S y Y f p + U G j D y + 4 s U K r Y 5 i W f F z Q M y V y w S h 4 K m n / 6 5 L c U O Z I S Q 0 I K v G 3 J N 4 i B Y V J m r u q 9 o v j 7 e 3 6 v + x I q m V m p 4 W f M I E J B 1 r X r e 5 K H h P J c 6 D G 6 J + r d f w R E w 8 w Y Z m G u Y + 4 d n 2 f a K s i c e p L X P / o 4 y W D 6 q 5 B 9 S i D R P o K N m l 3 o l 4 0 C 7 w M 4 g X o o E U c J u 2 / J N O s K r g C J q m 1 o z g q Y e y a U k x y f 2 x l e U n Z O T 3 j I w 8 V L b g d u 9 m r 1 L j r m Q z n 2 v i h A M / Y u x m O F r b x 6 X c 2 1 7 E P t Y Z c p Y 0 q y P f G T q i y A q 7 Y v F B e S Q w a N 0 + M M 2 E 4 A z n 1 g D I j v F f M J t Q 3 E f x H a P k m x A + v v A x O d n r x p 9 7 u 0 W 5 n v 7 9 o x z r a Q J t o C 8 X o M 9 p H X 9 E h G i A W f A 9 + B Z f B V T g M 6 / A 6 / D 3 f G g a L n A / o X o R / b g G i K + V n &lt; / l a t e x i t &gt; . . . &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o 1 2 G N B V 3 k 9 y r J F r R b + V n p 8 s v b v w = " &gt; A A A C 1 X i c r V L L b h M x F P V M C 5 T w S s u S j U V U q V 0 Q z a A K 2 C B V Y V O x K q h p K s V h 5 P F 4 G q s e e 2 T f o Y 0 s L 4 o q t v w b O / 6 h H 1 F P E o n S Z s m V L B + f c 6 / u y 3 k t h Y U k + R P F a + s P H j 7 a e N x 5 8 v T Z 8 x f d z a 1 j q x v D + J B p q c 1 J T i 2 X Q v E h C J D 8 p D a c V r n k o / z s U 6 u P v n N j h V Z H M K v 5 p K K n S p S C U Q h U 1 r 0 m p a H M k Z o a E F T i z 5 n a I R W F a V 6 6 x o f H 0 e 6 u / y s 7 k m t Z 2 F k V L k x g y o F 6 3 9 l e y W M i e Q n U G H 2 + W s d v M A k A E 1 Z o W N S R e j c I g b a p M q c + p v 7 b A P + X A o k M K W z W 7 S X 9 Z G 7 4 P k i X o I e W d p h 1 f 5 N C s 6 b i C p i k 1 o 7 T p I a J a 3 M x y X 2 H N J b X l J 3 R U z 4 O U N G K 2 4 m b b 8 X j 7 c A U u N Q m H A V 4 z t 6 O c L S y b a H B s + 3 H 3 t V a c p U 2 b q D 8 M H F C 1 Q 1 w x R a J y k Z i 0 L h d M S 6 E 4 Q z k L A D K j A i 1 Y j a l Y Y o Q P k I n D C G 9 2 / J 9 c P y 2 n 7 7 r 7 3 3 Z 6 + 0 P l u P Y Q K / Q a 7 S D U v Q e 7 a M D d I i G i E V f o 4 v o M v o R j 2 I f X 8 U / F 6 5 x t I x 5 i f 6 x + N c N 9 J / l 4 Q = = &lt; / l a t e x i t &gt; @J n (u n (T )) @✓</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P X 0 w e s i Y 6 o o b x x 1 I 3 j m g h h p B 5 q 8 = " &gt; A</p><formula xml:id="formula_1">A A C 5 n i c r V J N a x s x E N V u 0 z b Z f j n t s R d R Y 0 g O N b s l t L 0 E g n M p O S U Q J w H L X b R a b S y i l R Z p t s W I / Q G 9 9 J B S c s 1 v y q 0 / J h C t b W j q + N g B o c d 7 M 8 y b k b J K C g t x / C c I H 6 0 9 f v J 0 f S N 6 9 v z F y 1 e d z d c n V t e G 8 S H T U p u z j F o u h e J D E C D 5 W W U 4 L T P J T 7 O L / V Y / / c a N F V o d w 7 T i 4 5 K e K 1 E I R s F T a e e W l B Q m W e H q J l V b x 9 t R j x S G M k c q a k B Q i Q 8 8 v Z S z 3 f y V H c m 0 z O 2 0 9 B c m M O F A m y b q r e Q x k b w A a o z + v l r H 7 z H x A B O W a 5 j 7 S B o 3 8 I W 2 L l O n d p P m 6 w D / F 4 N E + h Y 2 7 X T j f j w L / B A k C 9 B F i z h M O z c k 1 6 w u u Q I m</formula><p>q b W j J K 5 g 7 N p e T P I m I r X l F W U X 9 J y P P F S 0 5 H b s Z s / U 4 J 5 n c l x o 4 4 8 C P G P v V z h a 2 t a o z 2 z n s c t a S 6 7 S R j U U n 8</p><formula xml:id="formula_2">d O q K o G r t i 8 U V F L D B q 3 b 4 5 z Y T g D O f W A M i O 8 V 8 w m 1 G 8 R / M + I / B K S 5 Z E f g p M P / e R j f + d o p 7 s 3 W K x j H b 1 F 7 9 A W S t A n t I e + o E M 0 R C x g w Y / g M v g V T s K f 4 e / w a p 4 a B o u a N + i f C K / v A A m L 7 G c = &lt; / l a t e x i t &gt;</formula><p>u n (T ) back-propagation to calculate the gradient of the validation loss w.r.t. the initialization, and optimizes the initialization accordingly.</p><p>While successful, a critical challenge of MAML is to back-propagate the gradient from a long training trajectory of the sampled tasks, because the resulting computation graph grows quickly, can easily explode, and is computationally expensive. To combat these issues, practical usage of MAML performs only one or a few steps of gradient descent in the inner optimization; unfortunately this propagates a trajectory only close to the initialization, and fails to reflect the longer-term learning performance of using that initialization. To bypass this issue, first-order MAML (FOMAML) <ref type="bibr" target="#b14">(Finn et al., 2017)</ref> and Reptile <ref type="bibr" target="#b32">(Nichol et al., 2018)</ref> employ dropout on the Jacobian to obtain an aggressive approximation. While this is efficient, the approach loses accurate gradient information. The recent iMAML approach <ref type="bibr" target="#b36">(Rajeswaran et al., 2019)</ref> uses an implicit method to calculate an accurate gradient w.r.t. the initialization. This approach is elegant and successful, but imposes several restrictions. First, an additional regularizer that encourages proximity of the model parameters and the initialization must be added into the training loss. Second, the gradient is accurate only when training reaches the optimum of the regularized loss.</p><p>In this paper, we propose A-MAML, an efficient and accurate approach to differentiate long paths of the inner-optimization in meta-learning. See Fig. <ref type="figure">1</ref> for an illustration. Our method does not require additional regularizers and can adapt to different trajectory lengths, hence it is well suited to commonly used training strategies, such as early stopping. Specifically, we view the inner optimization (training) as evolving a forward ordinary differential equation (ODE) system, where the states are the model parameters. The standard gradient descent is equivalent to solving this ODE with the forward Euler method. To calculate the gradient of the validation loss w.r.t. the model initialization, i.e., the initial state of the ODE, we use the adjoint method to construct a companion ODE. In effect, we only need to run the standard ODE solver twice: First, we solve the forward ODE to evolve a long training trajectory, based on which we compute the initial state of the adjoint ODE. Next, we solve the adjoint ODE backward to obtain the gradient w.r.t. the model initialization. To avoid divergence when solving backward, we use high-order solvers in the forward pass and track the states in the trajectory, based on which we use the modified Euler method (second-order) to solve backward. Throughout the procedure, we do not create and grow any intermediate computation graphs, nor do we apply any gradient approximation. The memory cost is linear in the number of model parameters. The accuracy is determined by the numerical precision of the ODE solver, which we can explicitly trade for speed.</p><p>For evaluation, we first examined A-MAML in two synthetic benchmark tests, regressing Alpine and Cosine mixture functions. In both task populations, we examined, starting from the given initialization, how the prediction error of the target model varies along with the increase of training epochs. A-MAML leads to much better prediction accuracy and training behavior compared against MAML, FOMAML, Reptile, and iMAML. Meanwhile, A-MAML dramatically reduces the memory usage and can easily scale to long training trajectories, compared with MAML which utilizes computation graphs. The running time of A-MAML is comparable to FOMAML, Reptile, and iMAML. We then applied A-MAML in three real-world applications of collaborative filtering and two image-classification tasks. In several few-shot learning settings, A-MAML nearly always provides the best initialization, which leads to smaller prediction errors than the competing approaches during the meta-tests. The improvement is often significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>Suppose we have a family of correlated learning tasks A. The size of A can be very large or even infinite. For each task, we use the same machine learning model M, which is parameterized by u ∈ R d , e.g., a deep neural network. Our goal is to learn an initialization θ for u, which can well adapt to all the tasks in A. To this end, we sample N tasks, S = {T 1 , . . . , T N }, from a task distribution p on A, and for each T n , we collect a dataset D n . We use the N datasets D = {D 1 , . . . , D N } to meta-learn θ. We expect that given any new task T * ∈ A, after initializing u with θ, the training of M on T * can achieve better performance with the same or fewer training epochs or iterations or examples.</p><p>A particularly successful meta-learning algorithm is model-agnostic meta-learning (MAML) <ref type="bibr" target="#b14">(Finn et al., 2017)</ref>, which uses a bi-level optimization approach to estimate θ. Specifically, each D n is partitioned into a meta-training dataset D tr n and a meta-validation dataset D val n . In the inner level, we start with θ and optimize the training loss L(u, D tr n ) for each task n. Let us denote the trained parameters by ψ n (θ). In the outer level, we evaluate these trained parameters on the validation loss, and optimize θ accordingly, i.e., θ * = min 1</p><formula xml:id="formula_3">N N j=1 L(ψ n (θ), D val n ).</formula><p>MAML obtains the gradient w.r.t. θ via automatic differentiation, which essentially computes dψn(θ) dθ via back-propagation on a computation graph. However, this is very challenging for long training trajectories to obtain ψ n (θ), since the computation graph can rapidly explode and become very expensive to compute. Therefore, in practice, MAML typically only conducts one or a few gradient descent steps in the inner optimization, e.g., with one step,</p><formula xml:id="formula_4">ψ n (θ) = θ − α∇L(θ, D tr n )</formula><p>, where α is the step size. However, with only one step the obtained parameters are frequently too close to the initialization, and inadequately reflect the actual longer-range training performance.</p><p>To bypass this issue, First-Order MAML (FOMAML) <ref type="bibr" target="#b14">(Finn et al., 2017)</ref> drops out the Jacobian dψn(θ) dθ and replaces it with the identity matrix I. In so doing, FOMAML can perform many gradient descent steps to obtain ψ n and update θ with</p><formula xml:id="formula_5">θ ← θ − η • 1 N N n=1 ∂L(ψ n , D val n ) ∂ψ n ,</formula><p>where η is the learning rate. With the same idea, Reptile <ref type="bibr" target="#b32">(Nichol et al., 2018)</ref> instead adjusts the updating direction to 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N N j=1</head><p>∂L(ψn,D val n ) ∂ψn − θ. Despite being efficient, these methods lack accurate gradient information about θ. To overcome this limitation, the recent work, iMAML <ref type="bibr" target="#b36">(Rajeswaran et al., 2019)</ref>, calculates the accurate gradient via an implicit gradient method. However, it needs to incorporate a proximity regularizer into the training loss to bind u and θ explicitly,</p><formula xml:id="formula_6">L(u, D tr n ) = L(u, D tr n ) + λ 2 u − θ 2 .</formula><p>The accurate gradient can be obtained (only) when the training reaches the optimum, i.e., ψ n = argmin u L(u, D tr n ), since we can derive the implicit gradient dψn dθ from the fact that ∂ L ∂ψn = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Adjoint MAML</head><p>In this paper, we propose A-MAML, which can accurately and efficiently compute the gradient of the meta loss w.r.t. the initialization for long training trajectories, without the need for aggressive approximations or additional regularization, and adapts to different trajectory lengths. Hence, our method can be easily integrated with common training strategies, e.g., early stopping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ODE View of Inner Optimization</head><p>Specifically, we first view the inner optimization as evolving an ODE system. In more detail, given task n, starting from θ, we run gradient descent for a long time to train the model. The training procedure can be in more general viewed as solving the following ODE,</p><formula xml:id="formula_7">u n (0) = θ, dun dt = − ∂L(un,D tr n ) ∂un</formula><p>, where the state u n (t) represents the model parameters at time t. Running gradient descent with a step size α essentially solves the ODE with the forward Euler method using temporal step size α, corresponding to the update u n (t + α) ← u n (t) − α ∂L(un,D tr n ) ∂un . However, the ODE view allows us to apply a variety of more efficient, high-order solvers to fulfill the training, e.g., the Runge-Kutta method <ref type="bibr" target="#b10">(Dormand and Prince, 1980</ref>). Suppose we stop at time T , then we evaluate the trained parameters u n (T ) on the validation dataset via L(u n (T ), D val n ). Therefore, the meta loss is given by</p><formula xml:id="formula_8">J(θ) = 1 N N n=1 L(u n (T ), D val n ).<label>(1)</label></formula><p>Note that the stopping time T is not necessarily the same for all the tasks; it can vary for different tasks as determined, say, by an early stopping criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Efficient Back-Propagation via Solving Adjoint ODEs</head><p>To optimize θ in (1) (in the outer loop), we need to be able to compute the gradient of the validation loss for each task n, i.e., dJn dθ , where J n = L(u n (T ), D val n ). We seek to compute this gradient efficiently for large T without creating and growing a computation graph. To this end, we use the adjoint method <ref type="bibr" target="#b35">(Pontryagin, 1987)</ref>. To simplify the notation, we first define</p><formula xml:id="formula_9">J n (u n (T )) = L(u n (T ), D val n ), f (u n , D tr n ) = − ∂L(u n , D tr n ) ∂u n .<label>(2)</label></formula><p>Note that we use the row vector representation of the gradient, i.e., ∂L ∂un is a 1 × d vector. This is consistent with the shape of Jacobian matrix, and the chain rule can be expressed as the matrix multiplication from left to right, which is natural and convenient. Accordingly, the ODE for u n (t) can be written as</p><formula xml:id="formula_10">u n (0) = θ, dun dt = f (u n , D tr n ).</formula><p>(3)</p><p>Next, to construct an adjoint ODE for efficient gradient computation, we augment the validation loss,</p><formula xml:id="formula_11">J n = J n (u n (T )) + T 0 λ(t) f (u n , D tr n ) − du n dt dt,<label>(4)</label></formula><p>where λ(t) is a Lagrange multiplier and a d × 1 vector. According to the ODE constraint (3), the extra integral in ( <ref type="formula" target="#formula_11">4</ref>) is 0 and J n = J n . Hence, we have</p><formula xml:id="formula_12">dJ n dθ = d J n dθ = ∂J n ∂u n (T ) du n dθ (T ) + T 0 λ ∂f ∂u n du n dθ − d dun dt dθ dt. (<label>5</label></formula><formula xml:id="formula_13">)</formula><p>For the second term in the integral, we switch the derivative order and apply integration by parts, Substituting the above into (5), we obtain</p><formula xml:id="formula_14">dJ n dθ = ∂J n ∂u n (T ) du n dθ (T ) − λ(T ) du n dθ (T ) + λ(0) du n dθ (0) + T 0 λ ∂f ∂u n du n dθ + dλ dt du n dθ dt.</formula><p>The computationally expensive term is the Jacobian dun dθ (marked as blue), which we efficiently handle by constructing an adjoint ODE for the Lagrange multiplier λ,</p><formula xml:id="formula_15">   λ(T ) = ∂Jn ∂un(T ) , dλ dt = −λ(t) ∂f ∂un .<label>(6)</label></formula><p>Note that the ODE (6) runs backward in time starting at the terminal time T . If we can solve (6), the Jacobian terms (blue) will cancel, and the full gradient becomes</p><formula xml:id="formula_16">dJ n dθ = λ(0) du n dθ (0) = λ(0) ,<label>(7)</label></formula><p>where we have used dun dθ (0) = I. We see that the gradient is simply the state of λ at time 0. To confirm the feasibility of solving (6), we can see from ( <ref type="formula" target="#formula_15">6</ref>) and ( <ref type="formula" target="#formula_9">2</ref></p><formula xml:id="formula_17">) that ∂f ∂un = H(u n ) = − ∂ 2 L(un,D tr n ) ∂u 2 n</formula><p>is the Hessian matrix of the model parameters. While it seems extremely costly to calculate the Hessian, when we substitute the above Hessian into (6) and take the transpose, we find,</p><formula xml:id="formula_18">   λ(T ) = ∂Jn ∂un(T ) , dλ dt = −H(u n )λ(t). (<label>8</label></formula><formula xml:id="formula_19">)</formula><p>Now it is clear that the dynamics of λ is a Hessian-vector product. It is known that we never need to explicitly compute the Hessian matrix. We can first compute the gradient g = ∂L ∂un , then the dot product s = v g, and take the gradient of the scalar s again, which gives exactly Hλ. The complexity is the same as computing the gradient.</p><p>Therefore, to calculate dJn dθ , we only need to run standard ODE solvers twice. First, we run a solver to evolve (3) from time 0 to time T . Note that even a small T can correspond to many gradient descent steps. For example, T = 10 corresponds to running 1000 gradient descent steps where the step size is set to 0.01 (a common choice). We can apply high-order methods, like RK45 <ref type="bibr" target="#b10">(Dormand and Prince, 1980)</ref> to further improve the speed and accuracy. Next, at the trained parameters u(T ), we jointly solve ( <ref type="formula" target="#formula_18">8</ref>) and ( <ref type="formula">3</ref>) backward (note that dynamics of λ needs u n ). For solving both ODEs, we never need to create and/or grow new computation graphs. All we need is to compute the dynamics in ( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_18">8</ref>), and the computational complexity is the same as computing the gradient of the training loss w.r.t the model parameters. The memory cost only involves storage of u n and λ, which is proportional to the number of model parameters. We never need to maintain or calculate any Jacobian matrix. The accuracy is determined by the numerical precision of the ODE solvers, which have been developed for decades, are mature, and can easily effect tradeoffs between precision and speed. Note that our method does not need to add extra regularization into the training loss, although our framework can be easily adjusted to support such regularization.</p><p>Empirically, we found that back-solving can diverge when T is very large, say, 100. This might be because a larger T increases the chance that different forward trajectories (i.e., starting from different initial states) intersect or even overlap. This is not uncommon for gradient-based trainingeven with different initializations, it might still arrive at or explore the same area. If so, when we solve the ODEs backward, it is easy to diverge at the intersection points. To promote robustness, we track the state u n in the training trajectory with a given step size during the forward solve. This can be automatically done via the ODE solver. Then based on the list of states {u n,j } j , we solve the adjoint ODE backward with the modified Euler method (Ascher and Petzold, 1998) whose global accuracy is O(h 2 ) where h is the ODE solver step size. Specifically, at each step j, we first calculate an intermediate value λ j and then the state λ j via,</p><formula xml:id="formula_20">λ j = λ j+1 + hH(u n,j+1 )λ j+1 , λ j = λ j+1 + h 2 H(u n,j+1 )λ j+1 + H(u n,j ) λ j .</formula><p>While this increases memory requirements, it is still linear with the number of parameters, O( T h d), and much cheaper than building a computational graph. The experiments show that our method can scale to long training trajectories very economically (see Sec. 5.2). Our method is summarized in Algorithm 1.</p><p>Algorithm 1 A-MAML (p(T ), T , η, G, ξ) 1: Randomly initialize θ. 2: repeat 3: Sample a mini-batch of tasks {T n } B n=1 from p(T ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>for each task T n do 5:</p><p>Calculate ∂Jn ∂θ with Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>end for 7:</p><formula xml:id="formula_21">θ ← θ − η • 1 B B n=1</formula><p>∂Jn ∂θ (or use ADAM). 8: until G iterations are done or the change of θ is less than ξ 9: Return θ.</p><p>Algorithm 2 Adjoint Gradient Computation (θ, J n , T , h)</p><formula xml:id="formula_22">1: u n (0) ← θ.</formula><p>2: Solve forward ODE (3) to time T with RK45, and track the states {u n,j } j in the trajectory with step size h. 3: λ(T ) ← ∂Jn ∂un(T ) . 4: Solve the adjoint ODE (8) to time 0 with modified Euler method based on the state list {u n,j }. 5: Return λ(0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Meta-learning <ref type="bibr" target="#b40">(Schmidhuber, 1987;</ref><ref type="bibr" target="#b44">Thrun and Pratt, 2012;</ref><ref type="bibr" target="#b31">Naik and Mammone, 1992</ref>) can be (roughly) classified into three categories: (1) metric-learning methods that learn a metric space (in the outer lever), where the tasks (in the inner level) make predictions by simply matching the training points, e.g., nonparametric nearest neighbors <ref type="bibr" target="#b23">(Koch et al., 2015;</ref><ref type="bibr" target="#b46">Vinyals et al., 2016;</ref><ref type="bibr" target="#b41">Snell et al., 2017;</ref><ref type="bibr" target="#b33">Oreshkin et al., 2018;</ref><ref type="bibr" target="#b0">Allen et al., 2019)</ref>, (2) black-box methods that train feed-forward or recurrent NNs to take the hyperparameters and task dataset as the input and outright predict the optimal model parameters or parameter updating rules <ref type="bibr" target="#b19">(Hochreiter et al., 2001;</ref><ref type="bibr" target="#b1">Andrychowicz et al., 2016;</ref><ref type="bibr" target="#b26">Li and Malik, 2016;</ref><ref type="bibr" target="#b37">Ravi and Larochelle, 2017;</ref><ref type="bibr" target="#b39">Santoro et al., 2016;</ref><ref type="bibr" target="#b11">Duan et al., 2016;</ref><ref type="bibr" target="#b47">Wang et al., 2016;</ref><ref type="bibr" target="#b30">Munkhdalai and Yu, 2017;</ref><ref type="bibr" target="#b29">Mishra et al., 2017)</ref>, and (3) optimization-based methods that conduct a bi-level optimization, where the inner level is to estimate the model parameters given the hyperparameters (in each task) and the outer level is to optimize the hyperparameters via a meta-loss <ref type="bibr" target="#b14">(Finn et al., 2017;</ref><ref type="bibr" target="#b13">Finn, 2018;</ref><ref type="bibr" target="#b5">Bertinetto et al., 2018;</ref><ref type="bibr" target="#b25">Lee et al., 2019;</ref><ref type="bibr" target="#b52">Zintgraf et al., 2019;</ref><ref type="bibr" target="#b27">Li et al., 2017;</ref><ref type="bibr">Finn et al., 2018;</ref><ref type="bibr" target="#b51">Zhou et al., 2018;</ref><ref type="bibr" target="#b18">Harrison et al., 2018)</ref>. Other approaches include <ref type="bibr" target="#b38">(Rusu et al., 2018;</ref><ref type="bibr" target="#b45">Triantafillou et al., 2019)</ref>, etc. A successful application of meta-learning is few-shot learning, for which important models include <ref type="bibr" target="#b24">(Lake et al., 2011;</ref><ref type="bibr" target="#b46">Vinyals et al., 2016;</ref><ref type="bibr" target="#b41">Snell et al., 2017;</ref><ref type="bibr" target="#b43">Sung et al., 2018)</ref>, to name a few. An excellent survey about meta-learning for neural networks is given in <ref type="bibr" target="#b20">(Hospedales et al., 2020)</ref>.</p><p>MAML <ref type="bibr" target="#b14">(Finn et al., 2017</ref>) is a popular optimization-based meta-learning method. In addition to FOMAML and Reptile, there are many variants, such as probabilistic versions <ref type="bibr" target="#b17">(Grant et al., 2018;</ref><ref type="bibr" target="#b50">Yoon et al., 2018;</ref><ref type="bibr">Finn et al., 2018)</ref>, and ones improving reinforcement learning <ref type="bibr" target="#b42">(Song et al., 2020;</ref><ref type="bibr" target="#b28">Liu et al., 2019)</ref>. Recently, <ref type="bibr" target="#b7">Denevi et al. (2020)</ref>; <ref type="bibr" target="#b48">Wang et al. (2020)</ref>; <ref type="bibr" target="#b8">Denevi et al. (2021)</ref> proposed conditional meta learning to leverage side information (when available) to learn taskspecific initializations. The recent work of <ref type="bibr" target="#b21">(Im et al., 2019;</ref><ref type="bibr" target="#b49">Xu et al., 2021)</ref> also introduces an ODE view for MAML. However, they use the ODE theory and methods to analyze/improve the outer level optimization, where the inner level still performs one step gradient descent as in standard MAML. They do not consider long training trajectories in the inner level. Im et al. ( <ref type="formula">2019</ref>) pointed out the MAML update is a special case of (second-order) Runge-Kutta gradients, and suggested using more refined nodes, weights and even higher-order updates. <ref type="bibr" target="#b49">Xu et al. (2021)</ref> showed that if the outer-level optimization of MAML is considered as solving an ODE, it enjoys a linear convergence rate for strongly convex task losses. Based on their analysis, they proposed a bi-phase algorithm to further reduce the cost and improve efficiency. Our work uses the ODE view for inner-level optimization. The adjoint method is a classical and popular framework to estimate the parameters of ODE or dynamic control models <ref type="bibr" target="#b6">(Chen et al., 2018;</ref><ref type="bibr">Eichmeir et al., 2021)</ref>. If we use Euler method to solve the adjoint ODE, it reduces to the reverse mode differentiation method <ref type="bibr" target="#b4">(Bengio, 2000;</ref><ref type="bibr" target="#b3">Baydin and Pearlmutter, 2014</ref>), yet leaving first-order global accuracy (O(h)). Another excellent related work is <ref type="bibr" target="#b9">(Domke, 2012</ref>) that provides a general bi-level optimization framework. It can optimize hyper-parameters that explicitly show up in the loss (e.g., regularization strength, yet not including the parameter initialization) with the inner-optimization procedure taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">2D regression</head><p>For evaluation, we first examined the proposed approach in two synthetic benchmark tests, namely, meta learning of CosMixture and Alpine functions (http://infinity77.net/global_ optimization/test_functions.html), both of which are 2D regression tasks. We considered two families of tasks. In the first family, each task aims to learn a specific CosMixture function of the following form, </p><formula xml:id="formula_23">f 1 (x) = −0.1 d i=1 A cos(ωx i + φ) − d i=1 x 2 i ,<label>(9)</label></formula><formula xml:id="formula_24">f 2 (x) = d i=1 |x i sin(x i + φ i ) + 0.1x i |,<label>(10)</label></formula><p>where x ∈ [10, 10] 2 , d = 2, φ 1 ∈ [− 5 12 π, 5 12 π], and φ 2 ∈ [− 5 12 π, 5 12 π]. An instance of each function is shown in Fig. <ref type="figure" target="#fig_2">2a and 2d</ref>. The learning model for both task populations is a neural network with two hidden layers, each consisting of 32 neurons with Tanh activation. To conduct meta-learning for each task population, we randomly sampled 100 tasks, where for each task, the parameters of the target function, i.e., {A, ω, φ} in CosMixture and {φ 1 , φ 2 } in Alpine, are uniformly sampled from their ranges. We considered two meta-learning settings: 50shot-50val, where we used 50 examples for meta-training and 50 another examples in meta-validation, and 100shot-100val, where both the meta-training and meta-validation losses employed 100 examples. These examples are non-overlapping and generated by uniformly sampling from the input domain. Given the learned initialization, we tested on 100 new tasks, where the task training data were generated in the same way as in the meta-training and 100 another examples were sampled to evaluate the prediction accuracy. Competing Methods. To examine the effectiveness of our method A-MAML, we tested the following MAML based approaches for an apples-to-apples comparison: (1) the original MAML <ref type="bibr" target="#b14">(Finn et al., 2017)</ref>, (2) First-order MAML (FOMAML) <ref type="bibr" target="#b14">(Finn et al., 2017)</ref>, which ignores the Jacobian in the gradient computation and uses the gradient w.r.t. the trained parameters to update the initialization, (3) Reptile <ref type="bibr" target="#b32">(Nichol et al., 2018)</ref>, which subtracts the gradient w.r.t. the trained parameter by the current initialization as the updating direction, (4) Implicit MAML (iMAML) <ref type="bibr" target="#b36">(Rajeswaran et al., 2019)</ref>, which introduces a proximal regularizer in the meta-training loss, and uses conjugate gradient to compute the gradient w.r.t. the initialization.</p><p>All the methods were implemented with PyTorch <ref type="bibr" target="#b34">(Paszke et al., 2019)</ref>. For MAML, we used a high-quality open source implementation (https://github.com/dragen1860/MAML-Pytorch); for iMAML, we used the implementation of the original authors (https://github.com/ aravindr93/imaml_dev). For our approach A-MAML, we used the Torchdiffeq library (https://github.com/rtqichen/torchdiffeq) to accomplish ODE solving with RK45. In the inner optimization, all the competing methods used the standard gradient descent (GD) with step size α = 0.01. For iMAML, the strength of the proximal regularizer was chosen as λ = 1 and 5 CG steps were conducted for Newton-CG optimization. For our method, we used the same step size (i.e., 0.01) to run modified Euler's method <ref type="bibr" target="#b2">(Ascher and Petzold, 1998)</ref> for solving the adjoint ODE. In the outer optimization, all the methods used the ADAM algorithm (Kingma and Ba, 2014), and the learning rate was set to 10 −3 . Each time, a mini-batch of five tasks were sampled to conduct inner-optimization, and then update the initialization in the outer-level. We ran 5, 000 meta-epochs for each method. For the 50shot-50val setting, we ran 200 GD steps for FOMAML, Reptile, iMAML, and for our method A-MAML, set T = 2 (that corresponds to 200 GD steps with α = 0.01). For the 100shot-100val setting, we ran 500 GD steps for FOMAML, Reptile, iMAML, and set T = 5 for A-MAML accordingly. By contrast, MAML ran 20 and 50 GD steps, respectively. Note that MAML cannot run too many GD steps without exhausting computational memory (see Section 5.2). We also evaluated MAML with only one GD step (the most common choice) for both settings; we denote such results by MAML-1. At the adaptation stage (meta-test), we ran the same number of GD steps with the initialization learned by every method: 200 steps for 50shot-50val and 500 steps for 100shot-100val, with the same step size as in the meta training. We executed all the algorithms on a Linux workstation with an NVIDIA GeForce RTX 3090 GPU card that includes 24 GB of G6X memory.</p><p>In Fig. <ref type="figure" target="#fig_2">2b,c</ref>, e and f, we show that starting with the learned initialization of each method, how the prediction error of the NN model on the test tasks varies along with the increase of training epochs. The prediction error for each task is computed as the normalized root-mean-square error (nRMSE). We averaged the nRMSE over the 100 test tasks and report the standard deviation. As we can see, in all the cases, our approach, A-MAML, always finds the initialization that leads to the best learning progress and performance -the NN models exhibit smaller prediction error throughout the training, as compared with using the initialization from the competing methods. MAML-1 is in general worse than MAML; the discrepancy is particularly evident for learning Alpine functions with the 100shot-100val setting (see Fig. <ref type="figure" target="#fig_2">2f</ref>). It implies that only performing one step GD in the inner-optimization might not properly reflect the quality of the initialization in training. Although FOMAML and Reptile can run many GD steps, their performance is often worse than MAML, especially Reptile, which is nearly always inferior to MAML. Such relatively poor performance might be attributed to the use of incorrect gradient information to update the initialization in these approaches. iMAML performed the second best at the beginning, but it was often surpassed by MAML or FOMAML after considerable training epochs. This might be due to (1) the proximity regularizer in the meta-training was not used in the actual training, which introduces some inconsistency, and (2) the inner optimization (though with 200/500 GD steps) has yet to achieve the optimum, and so the obtained gradient w.r.t. the initialization is still inaccurate. Note that the nRMSE for 100shot-100val seems a bit higher than 50shot-50val at the early stage, which might because the former involves a double quantity of examples, hence needs more epochs to train better and exhibits slower learning progress. Together these results have demonstrated the advantage of our method in being able to accurately compute the gradient for long inner-optimization trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Memory Consumption and Running Time</head><p>Next we examined the efficiency of our method in terms of memory usage and computational speed. To this end, we tested the 100shot-100validation setting in the meta learning of CosMinxture functions. We varied the number of inner GD steps (with the step size α = 0.01) for the competing approaches and the corresponding time ranges [0, T ] for ODEs in A-MAML. The average memory usage and running time are reported in Fig. <ref type="figure" target="#fig_5">3 and 4</ref>, respectively.</p><p>As shown in Fig. <ref type="figure" target="#fig_4">3</ref>, MAML always occupies the most memory. With the increase of GD steps, its memory consumption grows exponentially. When MAML runs 200 inner GD steps, the memory is completely exhausted. The result shows the creation and expansion of the computation graphs is very costly. By contrast, A-MAML can accurately compute the gradient in a much more economical way. A-MAML needs to track the states in the training trajectory to robustly solve the adjoint ODE   so the memory usage also grows with the number of GD steps, but this growth is much slower (linear) and more affordable than MAML. A-MAML effortlessly supports 500 steps with less than 25% memory usage.</p><p>Fig. <ref type="figure" target="#fig_5">4</ref> shows that the running time of A-MAML (per update in the outer-optimization) is comparable to iMAML, FOMAML and Reptile, and much smaller than MAML. This shows that our method is computationally efficient. On the other hand, the running time of MAML indicates that growing the computation graph for more GD steps also incurs a dramatic increase in the computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Few-Shot Learning in Collaborative Filtering</head><p>Third, we examined our approach in three real-world applications of collaborative filtering. To this end, we used the following datasets. (1) Jester-1(https://goldberg.berkeley.edu/ jester-data/) <ref type="bibr" target="#b16">(Goldberg et al., 2001)</ref>, which are about joke ratings. There are 100 jokes, rated by 24, 983 users. Each user has rated at least 36 jokes. The ratings are between -10 and 10.</p><p>(2) MovieLens-100K and (3) MovieLens-1M (https://grouplens.org/datasets/ movielens/), movie rating datasets, where the former includes 10K ratings from 1K users on 1.7K movies, and the latter one million movie ratings from 6K users on 4K movies. The ratings are ranged from 0 to 5. Following <ref type="bibr" target="#b7">(Denevi et al., 2020</ref><ref type="bibr" target="#b8">(Denevi et al., , 2021))</ref>, we considered predicting the ratings of a given user (on different jokes or movies) as one task. Different users correspond to different tasks. For each user, we learned a neural network (NN) to predict the rating on a specific joke or movie. The input to the NN is the one-hot encoding of the joke or movie. The NN has two hidden layers, and each layer includes 40 neurons with Tanh activation. We conducted meta learning on each dataset to estimate a good initialization for the corresponding rate prediction model. To prevent scarcity of the task data points, we selected the most frequently rated 100 movies in MovieLens-100K and MovieLens-1M, and only considered users who had rated at least 20 of them. This gives 489 and 4,985 tasks on MovieLens-100K and MovieLens-1M, respectively. For Jester-1, we used all 24, 983 tasks. For each dataset, we sampled 100 tasks for testing and used the remaining tasks for meta learning. We examined two few-shot settings: 15shot-20val, where 15 examples were used in   For all the methods, the step size of the inner training was set to α = 0.01, and a mini-batch of 5 tasks were sampled each time to conduct the inner training. We tested two choices of GD steps. First, we performed 50 GD steps for iMAML, FOMAML and Reptile, and set T = 0.5 for A-MAML to solve the forward and adjoint ODEs (corresponding to 50 steps). Second, we performed 100 GD steps for iMAML, FOMAML and Reptile, and accordingly set T = 1.0 for A-MAML. In each case, we ran MAML with one tenth of the corresponding steps, i.e., 5 and 10 steps respectively. In the outer-level, all the methods used ADAM optimization with learning rate 10 −3 . We ran 5000 meta epochs for each method. We computed the average nRMSE and its standard deviation of using the initialization estimated by each method for training and then testing on new tasks.</p><p>As shown in Tables <ref type="table" target="#tab_2">1 and 2</ref>, A-MAML achieved the best performance in all the cases -the learned initializations always result in the smallest test error after training (p &lt; 0.05), as compared with the competing methods. Consistent with the results in synthetic data (Sec. 5.1), FOMAML and Reptile are still worse than MAML, implying that their updates with inaccurate gradient information do not help improve the performance in these collaborative filtering applications. The results further confirm the advantage of the proposed method A-MAML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Few-Shot Learning in Images Classification</head><p>Finally, we evaluated A-MAML on popular benchmark datasets in few-shot image classification tasks, Mini-ImageNet and Omniglot. We followed the standard training and evaluation protocol as in iMAML paper and the prior works <ref type="bibr" target="#b39">(Santoro et al., 2016;</ref><ref type="bibr" target="#b46">Vinyals et al., 2016;</ref><ref type="bibr" target="#b14">Finn et al., 2017)</ref>, including data splits, NN architecture, etc. We tested 5-way 1-shot learning on Mini-ImageNet and 20-way 1-shot in Omniglot, because these two settings are more challenging to all the methods. We ran A-MAML with two settings, T = 0.1 and T = 0.3. During the adaptation stage, we ran the same number of GD steps with iMAML. The results are reported in Table <ref type="table" target="#tab_4">3</ref>. As we can see, with longer trajectory length, i.e., T = 0.3, our method gave the best performance on Omiglot and the second best on Mini-ImageNet. With shorter length (T = 0.1), the performance decreases, but is comparable to or better than the competing methods. This is reasonable and again shows the advantage of being able to carry out longer trajectories during the meta training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented A-MAML, a novel meta learning approach of model initializations. We view the inner-optimization as solving a forward ODE, and use the adjoint method to compute the gradient of the meta-loss w.r.t. the initialization in an efficient and accurate way. We plan to extend our work to conditional meta learning <ref type="bibr" target="#b8">(Denevi et al., 2021;</ref><ref type="bibr" target="#b48">Wang et al., 2020</ref>) so as to further leverage side information to estimate task-specific initializations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where x ∈ [−1, 1] 2 , d = 2, A ∈ [0.1, 1.0], ω ∈ [0.5π, 2.0π], and φ ∈ [3.0, 6.0]. The second family of tasks learn instances of the Alpine function,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Prediction error of the neural network in learning CosMixture and Alpine function families, starting from the initialization provided by different meta-learning approaches. (a,d) are the instances of the two types of functions. 50shot-50val means 50 examples were used for meta-training and another 50 examples for meta-validation. 100shot-100val means both the meta-training and meta-validation used 100 examples. The results were averaged over 100 test tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Normalized GPU usage in meta learning of CosMixutre with 100shot-100validation. The dashed line indicates the capacity of available GPU memory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Running time of the inner gradient descent for CosMixutre.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>meta-training and 20 examples in meta-validation, and 20shot-30val  where 20 examples were used in meta-training and 30 example in meta-validation. During the meta learning, when the data points of a sampled task are less than the required meta training and validation set size, we re-sample a new task. At the test stage, the training for each task used the same number of examples for few-shot learning and the remaining were used for evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 1: Illustration of A-MAML, where θ is the initialization, J n is the validation loss for task n (n = 1, 2, . . .), u n are the model parameters for task n, and also the state of the corresponding forward ODE. A-MAML solves the forward ODE to optimize the meta-training loss, and then solves the adjoint ODE backward to obtain the gradient of the meta-validation loss w.r.t. θ.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Meta-test error (nRMSE)  with 50 inner GD steps (MAML used 5 GD steps). The results were averaged over 100 tasks.</figDesc><table><row><cell></cell><cell cols="2">Jester-1</cell><cell cols="2">MovieLens100K</cell><cell cols="2">MovieLens1M</cell></row><row><cell></cell><cell>10shot-15val</cell><cell>20shot-30val</cell><cell>10shot-15val</cell><cell>20shot-30val</cell><cell>10shot-15val</cell><cell>20shot-30val</cell></row><row><cell cols="7">A-MAML 0.074±0.005 0.027±0.002 0.053±0.005 0.023±0.003 0.094±0.008 0.035±0.004</cell></row><row><cell>iMAML</cell><cell cols="6">0.114±0.007 0.050±0.003 0.082±0.004 0.033±0.002 0.138±0.010 0.052±0.004</cell></row><row><cell>MAML</cell><cell cols="6">0.120±0.001 0.036±0.000 0.123±0.001 0.050±0.003 0.140±0.002 0.059±0.001</cell></row><row><cell cols="7">FOMAML 0.292±0.012 0.115±0.004 0.174±0.008 0.068±0.004 0.270±0.011 0.104±0.006</cell></row><row><cell>Reptile</cell><cell cols="6">0.270±0.012 0.106±0.004 0.166±0.008 0.063±0.003 0.266±0.011 0.101±0.006</cell></row><row><cell></cell><cell cols="2">Jester-1</cell><cell cols="2">MovieLens100K</cell><cell cols="2">MovieLens1M</cell></row><row><cell></cell><cell>10shot-15val</cell><cell>20shot-30val</cell><cell>10shot-15val</cell><cell>20shot-30val</cell><cell>10shot-15val</cell><cell>20shot-30val</cell></row><row><cell cols="7">A-MAML 0.069±0.005 0.044±0.003 0.057±0.006 0.021±0.002 0.105±0.009 0.035±0.004</cell></row><row><cell>iMAML</cell><cell cols="6">0.190±0.010 0.103±0.005 0.168±0.007 0.046±0.002 0.130±0.007 0.045±0.004</cell></row><row><cell>MAML</cell><cell cols="6">0.154±0.001 0.061±0.002 0.123±0.001 0.050±0.002 0.197±0.002 0.083±0.001</cell></row><row><cell cols="7">FOMAML 0.273±0.012 0.077±0.004 0.191±0.007 0.071±0.004 0.395±0.010 0.119±0.005</cell></row><row><cell>Reptile</cell><cell cols="6">0.290±0.012 0.100±0.004 0.171±0.008 0.066±0.004 0.408±0.011 0.128±0.006</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Meta-test error (nRMSE)  with 100 inner GD steps (MAML used 10 GD steps). The results were averaged over 100 tasks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Meta-test accuracy for 20-way 1-shot on Omniglot and 5-way 1-shot on Mini-ImageNet.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName><forename type="first">Kelsey</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanul</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nando De</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName><surname>Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04474</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Computer methods for ordinary differential equations and differential-algebraic equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><forename type="middle">R</forename><surname>Ascher</surname></persName>
		</author>
		<author>
			<persName><surname>Petzold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">61</biblScope>
			<pubPlace>Siam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic differentiation of algorithms for machine learning</title>
		<author>
			<persName><forename type="first">Atilim</forename><surname>Gunes Baydin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><surname>Pearlmutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.7456</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gradient-based optimization of hyperparameters</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1889" to="1900" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08136</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The advantage of conditional meta-learning for biased regularization and fine tuning</title>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Denevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Ciliberto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Denevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Ciliberto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16277</idno>
		<title level="m">Conditional meta-learning of linear representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generic methods for optimization-based modeling</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="318" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A family of embedded runge-kutta formulae</title>
		<author>
			<persName><forename type="first">R</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Dormand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="26" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Rl2: Fast reinforcement learning via slow reinforcement learning</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02779</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The adjoint method for time-optimal control problems</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Eichmeir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lauß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Oberpeilsteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karin</forename><surname>Nachbagauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Steiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Nonlinear Dynamics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning to learn with gradients</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>UC Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02817</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Eigentaste: A constant time collaborative filtering algorithm</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">information retrieval</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="151" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical Bayes</title>
		<author>
			<persName><forename type="first">Erin</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Meta-learning priors for efficient online bayesian regression</title>
		<author>
			<persName><forename type="first">James</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorva</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on the Algorithmic Foundations of Robotics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="318" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Younger</surname></persName>
		</author>
		<author>
			<persName><surname>Peter R Conwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05439</idno>
		<title level="m">Meta-learning in neural networks: A survey</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning using runge-kutta methods</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Daniel Jiwoong Im</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nakul</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><surname>Verma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07368</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML deep learning workshop</title>
				<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName><forename type="first">Brenden</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
				<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to optimize</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01885</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><forename type="middle">Li</forename><surname>Meta-Sgd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09835</idno>
		<title level="m">Learning to learn quickly for few-shot learning</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Taming maml: Efficient unbiased meta-reinforcement learning</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4061" to="4071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03141</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Meta-neural networks that learn by learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Devang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">J</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><surname>Mammone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1992] IJCNN International Joint Conference on Neural Networks</title>
				<meeting>1992] IJCNN International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="437" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName><forename type="first">Pau</forename><surname>Boris N Oreshkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><surname>Lacoste</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10123</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01703</idno>
		<title level="m">An imperative style, high-performance deep learning library</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Mathematical theory of optimal processes</title>
		<author>
			<persName><forename type="first">Lev</forename><surname>Semenovich Pontryagin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Meta-learning with implicit gradients</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sham</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding optimization</title>
		<author>
			<persName><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Pascanu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05960</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Metalearning with memory-augmented neural networks</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook. PhD thesis</title>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Es-maml: Simple hessian-free meta learning</title>
		<author>
			<persName><forename type="first">Xingyou</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Pacchiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carles</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03096</idno>
		<title level="m">Meta-dataset: A dataset of datasets for learning to learn from few examples</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04080</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Jane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeb</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruva</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><surname>Blundell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05763</idno>
		<title level="m">Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Structured prediction for conditional metalearning</title>
		<author>
			<persName><forename type="first">Ruohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiannis</forename><surname>Demiris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Ciliberto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Meta learning in the continuous time limit</title>
		<author>
			<persName><forename type="first">Ruitu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Karbasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3052" to="3060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bayesian model-agnostic meta-learning</title>
		<author>
			<persName><forename type="first">Jaesik</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ousmane</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
				<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7343" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Deep meta-learning: Learning to learn in the concept space</title>
		<author>
			<persName><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03596</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fast context adaptation via meta-learning</title>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Zintgraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyriacos</forename><surname>Shiarli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Kurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>Whiteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7693" to="7702" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
