\documentclass{article}

\usepackage{iclr2022_conference,times}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

\iclrfinalcopy
\usepackage{tikz}
\usepackage{comment}
\usepackage{amsmath,amssymb} 
\usepackage{color}
\usepackage{booktabs}
\input{math_commands.tex}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{wrapfig}
\setcitestyle{numbers,square,citesep={,},aysep={,},yysep={;}}

\input{custom_commands}
\usepackage{paralist}

\usepackage[frozencache=true, cachedir=minted-cache]{minted} 
\title{Learning to Compose Soft Prompts for\\ Compositional Zero-Shot Learning}


\author{Nihal V. Nayak$^{*}$,\ \ Peilin Yu\thanks{Equal contribution}\ ,\ \  Stephen H. Bach\\
Department of Computer Science\\
Brown University\\
Providence, RI 02906, USA \\
\texttt{\{nnayak2, pyu12, sbach\}@cs.brown.edu} \\
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}


\maketitle
\begin{abstract}
We introduce compositional soft prompting (\cspnamenospace), a parameter-efficient learning technique to improve the zero-shot compositionality of large-scale pretrained vision-language models (VLMs) without the overhead of fine-tuning the entire model.
VLMs can represent arbitrary classes as natural language prompts in their flexible text encoders but they underperform state-of-the-art methods on compositional zero-shot benchmark tasks.
To improve VLMs, we propose a novel form of soft prompting.
We treat the attributes and objects that are composed to define classes as learnable tokens of vocabulary and tune them on multiple prompt compositions.
During inference, we recompose the learned attribute-object vocabulary in new combinations and show that \cspname outperforms the original VLM on benchmark datasets by an average of 14.7 percentage points of accuracy.
\cspname also achieves new state-of-the-art accuracies on two out of three benchmark datasets, while only fine-tuning a small number of parameters.
Further, we show that \cspname improves generalization to higher-order attribute-attribute-object compositions and combinations of pretrained attributes and fine-tuned objects.
The code is available at \href{https://github.com/BatsResearch/csp}{https://github.com/BatsResearch/csp}.
\end{abstract}
\input{sections/introduction}
\input{sections/related_work}
\input{sections/prelim}
\input{sections/method}
\input{sections/experiment}
\input{sections/attribute_attribute_object}
\input{sections/pretrained_finetune_vocab}
\input{sections/conclusion}


\textbf{Authors’ Note.} The first two authors contributed equally. 
Co-first authors can prioritize their names when adding this paper’s reference to their resumes.


\section*{Acknowledgments}
We thank Andrew Delworth and Elise Carman for helping us annotate the AAO-MIT-States dataset.
We appreciate the comments and advice from Cristina Menghini, Wasu Piriyakulkij and  Zheng-Xin Yong on our drafts. 
This material is based on research sponsored by Defense Advanced Research Projects Agency (DARPA)
and Air Force Research Laboratory (AFRL) under
agreement number FA8750-19-2-1006. The U.S. Government is authorized to reproduce and distribute
reprints for Governmental purposes notwithstanding
any copyright notation thereon. The views and conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing
the official policies or endorsements, either expressed or implied, of Defense Advanced Research Projects Agency (DARPA) and Air Force Research Laboratory
(AFRL) or the U.S. Government. We gratefully acknowledge support from Google and Cisco. Disclosure:
Stephen Bach is an advisor to Snorkel AI, a company that provides software and services for weakly supervised machine learning.


\bibliographystyle{abbrvnat}
\bibliography{egbib}
\clearpage
\appendix
\input{appendices/appendices_list}
\end{document}